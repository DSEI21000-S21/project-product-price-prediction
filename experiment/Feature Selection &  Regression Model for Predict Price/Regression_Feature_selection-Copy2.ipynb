{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the copy based on copy1, to conduct PCA before regression.** <br>\n",
    "Due to large dimension and computing capacity, must reduce dimension before doing regression.<br>\n",
    "Last version, failed to run RFE for feature selection. RFE is better when choosing a few features from a relatively small feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:29.354318Z",
     "start_time": "2021-05-03T20:23:29.347354Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\lzowe\\OneDrive - The City College of New York\\CCNY_Course\\Applied_Machine_Learning_and_Data_Mining\\codes\\project-product-price-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:31.368826Z",
     "start_time": "2021-05-03T20:23:29.974442Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from final.feature_extraction.vectorization import text_vectorizaion\n",
    "from final.dimension_reduction.feature_reduction import dimension_reduction\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.rcParams['figure.constrained_layout.use'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data processed using Tokenizing and tf-idf algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:39.142791Z",
     "start_time": "2021-05-03T20:23:32.092574Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/DSEI21000-S21/project-product-price-prediction/main/data/random_samples/stratified_sampling_clean_text_data_by_price_whigh_sz50000_1619835594.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:39.204672Z",
     "start_time": "2021-05-03T20:23:39.191661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 34)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:39.373341Z",
     "start_time": "2021-05-03T20:23:39.255521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_upper_char_count</th>\n",
       "      <th>item_name_stopword_count</th>\n",
       "      <th>item_name_punctuation_count</th>\n",
       "      <th>item_name_number_count</th>\n",
       "      <th>item_name_after_word_count</th>\n",
       "      <th>item_name_after_char_count</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.373508e+05</td>\n",
       "      <td>26.583180</td>\n",
       "      <td>150.390920</td>\n",
       "      <td>5.667798</td>\n",
       "      <td>1.876040</td>\n",
       "      <td>12.577260</td>\n",
       "      <td>7.67970</td>\n",
       "      <td>5.850200</td>\n",
       "      <td>0.499880</td>\n",
       "      <td>18.323300</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794540</td>\n",
       "      <td>0.192960</td>\n",
       "      <td>0.414340</td>\n",
       "      <td>0.177680</td>\n",
       "      <td>4.236300</td>\n",
       "      <td>24.381740</td>\n",
       "      <td>5.845573</td>\n",
       "      <td>1.991820</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>108.41749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.251891e+05</td>\n",
       "      <td>28.205148</td>\n",
       "      <td>161.300927</td>\n",
       "      <td>0.782677</td>\n",
       "      <td>5.826971</td>\n",
       "      <td>28.114883</td>\n",
       "      <td>10.36772</td>\n",
       "      <td>8.336725</td>\n",
       "      <td>1.229061</td>\n",
       "      <td>18.691275</td>\n",
       "      <td>...</td>\n",
       "      <td>5.226287</td>\n",
       "      <td>0.463088</td>\n",
       "      <td>0.828128</td>\n",
       "      <td>0.422508</td>\n",
       "      <td>1.535705</td>\n",
       "      <td>8.740065</td>\n",
       "      <td>1.210724</td>\n",
       "      <td>0.896911</td>\n",
       "      <td>0.484564</td>\n",
       "      <td>198.75487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.726685e+05</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>5.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.353620e+05</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>5.642857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.102881e+06</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>6.020944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482519e+06</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>761.000000</td>\n",
       "      <td>104.00000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_id  item_description_bef_word_count  \\\n",
       "count  5.000000e+04                     50000.000000   \n",
       "mean   7.373508e+05                        26.583180   \n",
       "std    4.251891e+05                        28.205148   \n",
       "min    1.900000e+01                         1.000000   \n",
       "25%    3.726685e+05                         8.000000   \n",
       "50%    7.353620e+05                        17.000000   \n",
       "75%    1.102881e+06                        34.000000   \n",
       "max    1.482519e+06                       206.000000   \n",
       "\n",
       "       item_description_bef_char_count  item_description_bef_avg_word_len  \\\n",
       "count                     50000.000000                       50000.000000   \n",
       "mean                        150.390920                           5.667798   \n",
       "std                         161.300927                           0.782677   \n",
       "min                           1.000000                           1.000000   \n",
       "25%                          46.000000                           5.210526   \n",
       "50%                          97.000000                           5.642857   \n",
       "75%                         191.000000                           6.020944   \n",
       "max                        1007.000000                          19.600000   \n",
       "\n",
       "       item_description_upper_word_count  item_description_upper_char_count  \\\n",
       "count                       50000.000000                       50000.000000   \n",
       "mean                            1.876040                          12.577260   \n",
       "std                             5.826971                          28.114883   \n",
       "min                             0.000000                           0.000000   \n",
       "25%                             0.000000                           2.000000   \n",
       "50%                             0.000000                           5.000000   \n",
       "75%                             1.000000                          12.000000   \n",
       "max                           178.000000                         761.000000   \n",
       "\n",
       "       item_description_stopword_count  item_description_punctuation_count  \\\n",
       "count                      50000.00000                        50000.000000   \n",
       "mean                           7.67970                            5.850200   \n",
       "std                           10.36772                            8.336725   \n",
       "min                            0.00000                            0.000000   \n",
       "25%                            1.00000                            1.000000   \n",
       "50%                            4.00000                            3.000000   \n",
       "75%                           10.00000                            8.000000   \n",
       "max                          104.00000                          308.000000   \n",
       "\n",
       "       item_description_number_count  item_description_after_word_count  ...  \\\n",
       "count                   50000.000000                       50000.000000  ...   \n",
       "mean                        0.499880                          18.323300  ...   \n",
       "std                         1.229061                          18.691275  ...   \n",
       "min                         0.000000                           1.000000  ...   \n",
       "25%                         0.000000                           7.000000  ...   \n",
       "50%                         0.000000                          12.000000  ...   \n",
       "75%                         1.000000                          23.000000  ...   \n",
       "max                        57.000000                         175.000000  ...   \n",
       "\n",
       "       item_name_upper_char_count  item_name_stopword_count  \\\n",
       "count                50000.000000              50000.000000   \n",
       "mean                     4.794540                  0.192960   \n",
       "std                      5.226287                  0.463088   \n",
       "min                      0.000000                  0.000000   \n",
       "25%                      2.000000                  0.000000   \n",
       "50%                      3.000000                  0.000000   \n",
       "75%                      6.000000                  0.000000   \n",
       "max                     37.000000                  6.000000   \n",
       "\n",
       "       item_name_punctuation_count  item_name_number_count  \\\n",
       "count                 50000.000000            50000.000000   \n",
       "mean                      0.414340                0.177680   \n",
       "std                       0.828128                0.422508   \n",
       "min                       0.000000                0.000000   \n",
       "25%                       0.000000                0.000000   \n",
       "50%                       0.000000                0.000000   \n",
       "75%                       1.000000                0.000000   \n",
       "max                      12.000000                9.000000   \n",
       "\n",
       "       item_name_after_word_count  item_name_after_char_count  \\\n",
       "count                50000.000000                50000.000000   \n",
       "mean                     4.236300                   24.381740   \n",
       "std                      1.535705                    8.740065   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      3.000000                   18.000000   \n",
       "50%                      4.000000                   25.000000   \n",
       "75%                      5.000000                   32.000000   \n",
       "max                     13.000000                   42.000000   \n",
       "\n",
       "       item_name_after_avg_word_len  item_condition_id      shipping  \\\n",
       "count                  50000.000000       50000.000000  50000.000000   \n",
       "mean                       5.845573           1.991820      0.376700   \n",
       "std                        1.210724           0.896911      0.484564   \n",
       "min                        1.000000           1.000000      0.000000   \n",
       "25%                        5.000000           1.000000      0.000000   \n",
       "50%                        5.750000           2.000000      0.000000   \n",
       "75%                        6.500000           3.000000      1.000000   \n",
       "max                       26.000000           5.000000      1.000000   \n",
       "\n",
       "             price  \n",
       "count  50000.00000  \n",
       "mean     108.41749  \n",
       "std      198.75487  \n",
       "min        3.00000  \n",
       "25%       20.00000  \n",
       "50%       50.00000  \n",
       "75%       90.00000  \n",
       "max     2009.00000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:39.469089Z",
     "start_time": "2021-05-03T20:23:39.424210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 34 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   train_id                             50000 non-null  int64  \n",
      " 1   clean_item_description               50000 non-null  object \n",
      " 2   item_description_bef_word_count      50000 non-null  float64\n",
      " 3   item_description_bef_char_count      50000 non-null  float64\n",
      " 4   item_description_bef_avg_word_len    50000 non-null  float64\n",
      " 5   item_description_upper_word_count    50000 non-null  float64\n",
      " 6   item_description_upper_char_count    50000 non-null  float64\n",
      " 7   item_description_stopword_count      50000 non-null  float64\n",
      " 8   item_description_punctuation_count   50000 non-null  float64\n",
      " 9   item_description_number_count        50000 non-null  float64\n",
      " 10  item_description_after_word_count    50000 non-null  float64\n",
      " 11  item_description_after_char_count    50000 non-null  float64\n",
      " 12  item_description_after_avg_word_len  50000 non-null  float64\n",
      " 13  clean_item_name                      50000 non-null  object \n",
      " 14  item_name_bef_word_count             50000 non-null  float64\n",
      " 15  item_name_bef_char_count             50000 non-null  float64\n",
      " 16  item_name_bef_avg_word_len           50000 non-null  float64\n",
      " 17  item_name_upper_word_count           50000 non-null  float64\n",
      " 18  item_name_upper_char_count           50000 non-null  float64\n",
      " 19  item_name_stopword_count             50000 non-null  float64\n",
      " 20  item_name_punctuation_count          50000 non-null  float64\n",
      " 21  item_name_number_count               50000 non-null  float64\n",
      " 22  item_name_after_word_count           50000 non-null  float64\n",
      " 23  item_name_after_char_count           50000 non-null  float64\n",
      " 24  item_name_after_avg_word_len         50000 non-null  float64\n",
      " 25  item_condition_id                    50000 non-null  int64  \n",
      " 26  category_name                        50000 non-null  object \n",
      " 27  brand_name                           50000 non-null  object \n",
      " 28  shipping                             50000 non-null  int64  \n",
      " 29  price                                50000 non-null  float64\n",
      " 30  c1                                   50000 non-null  object \n",
      " 31  c2                                   50000 non-null  object \n",
      " 32  c3                                   50000 non-null  object \n",
      " 33  price_bin                            50000 non-null  object \n",
      "dtypes: float64(23), int64(3), object(8)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:39.548322Z",
     "start_time": "2021-05-03T20:23:39.519953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42039,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean_item_name.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:39.626901Z",
     "start_time": "2021-05-03T20:23:39.597980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>clean_item_description</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>new tags</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Athletic Apparel/Shirts &amp; Tops</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>women</td>\n",
       "      <td>athletic apparel</td>\n",
       "      <td>shirts &amp; tops</td>\n",
       "      <td>(10, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>nastasya every hills lipstick fashion</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Lips</td>\n",
       "      <td>Anastasia Beverly Hills</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>beauty</td>\n",
       "      <td>makeup</td>\n",
       "      <td>lips</td>\n",
       "      <td>(20, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>brand new tags taken bag pictures</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jeans/Leggings</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>women</td>\n",
       "      <td>jeans</td>\n",
       "      <td>leggings</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>bought calves bit large frowned good condition...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>boots</td>\n",
       "      <td>(80, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>brand new box size 7youth859womens</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>athletic</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                             clean_item_description  \\\n",
       "0    806824                                           new tags   \n",
       "1    772820              nastasya every hills lipstick fashion   \n",
       "2   1423115                  brand new tags taken bag pictures   \n",
       "3    405853  bought calves bit large frowned good condition...   \n",
       "4   1172086                 brand new box size 7youth859womens   \n",
       "\n",
       "   item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0                              3.0                             13.0   \n",
       "1                              6.0                             42.0   \n",
       "2                             11.0                             54.0   \n",
       "3                             35.0                            188.0   \n",
       "4                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  ...  \\\n",
       "0                                 0.0                            0.0  ...   \n",
       "1                                 0.0                            0.0  ...   \n",
       "2                                 0.0                            0.0  ...   \n",
       "3                                 7.0                            1.0  ...   \n",
       "4                                 3.0                            0.0  ...   \n",
       "\n",
       "   item_name_after_avg_word_len  item_condition_id  \\\n",
       "0                      5.250000                  1   \n",
       "1                     10.000000                  1   \n",
       "2                      6.166667                  1   \n",
       "3                      5.333333                  3   \n",
       "4                      4.000000                  1   \n",
       "\n",
       "                          category_name               brand_name  shipping  \\\n",
       "0  Women/Athletic Apparel/Shirts & Tops                     Nike         1   \n",
       "1                    Beauty/Makeup/Lips  Anastasia Beverly Hills         0   \n",
       "2                  Women/Jeans/Leggings                  LuLaRoe         0   \n",
       "3                     Women/Shoes/Boots                   Hunter         0   \n",
       "4                  Women/Shoes/Athletic                     Nike         0   \n",
       "\n",
       "   price      c1                c2             c3  price_bin  \n",
       "0   15.0   women  athletic apparel  shirts & tops   (10, 15]  \n",
       "1   22.0  beauty            makeup           lips   (20, 25]  \n",
       "2   54.0   women             jeans       leggings   (50, 60]  \n",
       "3   84.0   women             shoes          boots   (80, 90]  \n",
       "4   56.0   women             shoes       athletic   (50, 60]  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Feature extraction and dimension selection\n",
    " \n",
    " For Item-discription feature: <br>\n",
    " using Jin's function to, firstly, do feature-extraction, increasing up to 14230 new few features <br>\n",
    " secondly, do dimenstion-reduction <br>\n",
    " finally, left 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:39.689269Z",
     "start_time": "2021-05-03T20:23:39.674818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corners bottom great shape lips smells markings inside cleanthere small water mark indicated third photo comes dusting'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean_item_description[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:41.810300Z",
     "start_time": "2021-05-03T20:23:39.737506Z"
    }
   },
   "outputs": [],
   "source": [
    "description_feature,  description_feature_name = text_vectorizaion(df, text_col = \"clean_item_description\", \n",
    "                                                                   tfidf = True, min_df=10, max_features=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:23:41.887833Z",
     "start_time": "2021-05-03T20:23:41.874866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 14230)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:12.637332Z",
     "start_time": "2021-05-03T20:23:41.952483Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dimension_reduction(description_feature.toarray(), method = 'SVD', n_comp = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:13.068182Z",
     "start_time": "2021-05-03T20:24:13.054218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:13.175918Z",
     "start_time": "2021-05-03T20:24:13.134004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.316579</td>\n",
       "      <td>0.226464</td>\n",
       "      <td>-0.093895</td>\n",
       "      <td>-0.145724</td>\n",
       "      <td>-0.160601</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>-0.018078</td>\n",
       "      <td>0.090894</td>\n",
       "      <td>0.191935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-0.001334</td>\n",
       "      <td>-0.002025</td>\n",
       "      <td>-0.007014</td>\n",
       "      <td>-0.008020</td>\n",
       "      <td>0.009870</td>\n",
       "      <td>0.010357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>-0.001485</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.003073</td>\n",
       "      <td>0.008709</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>-0.001268</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-0.012320</td>\n",
       "      <td>0.029981</td>\n",
       "      <td>-0.011197</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.009679</td>\n",
       "      <td>-0.009161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.282559</td>\n",
       "      <td>0.198734</td>\n",
       "      <td>-0.108194</td>\n",
       "      <td>-0.022312</td>\n",
       "      <td>-0.049010</td>\n",
       "      <td>-0.093214</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>-0.023772</td>\n",
       "      <td>0.027221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.019248</td>\n",
       "      <td>0.017355</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.027450</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0.036572</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.026407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.087350</td>\n",
       "      <td>-0.138583</td>\n",
       "      <td>-0.028884</td>\n",
       "      <td>-0.007241</td>\n",
       "      <td>-0.041194</td>\n",
       "      <td>-0.030514</td>\n",
       "      <td>0.157935</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007530</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>-0.015024</td>\n",
       "      <td>-0.001424</td>\n",
       "      <td>-0.033341</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>-0.045089</td>\n",
       "      <td>-0.005682</td>\n",
       "      <td>-0.003724</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.407447</td>\n",
       "      <td>0.230953</td>\n",
       "      <td>-0.090665</td>\n",
       "      <td>-0.028016</td>\n",
       "      <td>-0.120192</td>\n",
       "      <td>-0.079092</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>-0.152950</td>\n",
       "      <td>-0.178806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006526</td>\n",
       "      <td>-0.016268</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.012338</td>\n",
       "      <td>0.012810</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>0.024485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000323  0.316579  0.226464 -0.093895 -0.145724 -0.160601 -0.003327   \n",
       "1  0.000036  0.006363 -0.001485 -0.000307 -0.003073  0.008709  0.000232   \n",
       "2  0.000307  0.282559  0.198734 -0.108194 -0.022312 -0.049010 -0.093214   \n",
       "3  0.000196  0.087350 -0.138583 -0.028884 -0.007241 -0.041194 -0.030514   \n",
       "4  0.000409  0.407447  0.230953 -0.090665 -0.028016 -0.120192 -0.079092   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0 -0.018078  0.090894  0.191935  ...  0.002638  0.006700  0.005712 -0.000512   \n",
       "1 -0.001268 -0.002304  0.001756  ...  0.001377  0.015823  0.000063 -0.012320   \n",
       "2  0.013352 -0.023772  0.027221  ... -0.008231  0.019248  0.017355  0.000174   \n",
       "3  0.157935  0.007513  0.001806  ... -0.007530  0.000919 -0.015024 -0.001424   \n",
       "4  0.052900 -0.152950 -0.178806  ...  0.006526 -0.016268  0.005182  0.002841   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.001334 -0.002025 -0.007014 -0.008020  0.009870  0.010357  \n",
       "1  0.029981 -0.011197  0.001984  0.000641  0.009679 -0.009161  \n",
       "2  0.027450  0.014739  0.036572 -0.010762  0.020620  0.026407  \n",
       "3 -0.033341 -0.001557 -0.045089 -0.005682 -0.003724  0.000257  \n",
       "4  0.005126  0.012338  0.012810  0.001393  0.010066  0.024485  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cid = pd.DataFrame(data.copy()) #df for cleaned item description transforming to new features\n",
    "df_cid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating new features df_cid and previous df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:13.347432Z",
     "start_time": "2021-05-03T20:24:13.271635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Athletic Apparel/Shirts &amp; Tops</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>women</td>\n",
       "      <td>athletic apparel</td>\n",
       "      <td>shirts &amp; tops</td>\n",
       "      <td>(10, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Lips</td>\n",
       "      <td>Anastasia Beverly Hills</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>beauty</td>\n",
       "      <td>makeup</td>\n",
       "      <td>lips</td>\n",
       "      <td>(20, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jeans/Leggings</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>women</td>\n",
       "      <td>jeans</td>\n",
       "      <td>leggings</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>boots</td>\n",
       "      <td>(80, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>athletic</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0    806824                              3.0                             13.0   \n",
       "1    772820                              6.0                             42.0   \n",
       "2   1423115                             11.0                             54.0   \n",
       "3    405853                             35.0                            188.0   \n",
       "4   1172086                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  \\\n",
       "0                                 0.0                            0.0   \n",
       "1                                 0.0                            0.0   \n",
       "2                                 0.0                            0.0   \n",
       "3                                 7.0                            1.0   \n",
       "4                                 3.0                            0.0   \n",
       "\n",
       "   item_description_after_word_count  ...  item_name_after_avg_word_len  \\\n",
       "0                                2.0  ...                      5.250000   \n",
       "1                                5.0  ...                     10.000000   \n",
       "2                                6.0  ...                      6.166667   \n",
       "3                               17.0  ...                      5.333333   \n",
       "4                                5.0  ...                      4.000000   \n",
       "\n",
       "   item_condition_id                         category_name  \\\n",
       "0                  1  Women/Athletic Apparel/Shirts & Tops   \n",
       "1                  1                    Beauty/Makeup/Lips   \n",
       "2                  1                  Women/Jeans/Leggings   \n",
       "3                  3                     Women/Shoes/Boots   \n",
       "4                  1                  Women/Shoes/Athletic   \n",
       "\n",
       "                brand_name  shipping  price      c1                c2  \\\n",
       "0                     Nike         1   15.0   women  athletic apparel   \n",
       "1  Anastasia Beverly Hills         0   22.0  beauty            makeup   \n",
       "2                  LuLaRoe         0   54.0   women             jeans   \n",
       "3                   Hunter         0   84.0   women             shoes   \n",
       "4                     Nike         0   56.0   women             shoes   \n",
       "\n",
       "              c3  price_bin  \n",
       "0  shirts & tops   (10, 15]  \n",
       "1           lips   (20, 25]  \n",
       "2       leggings   (50, 60]  \n",
       "3          boots   (80, 90]  \n",
       "4       athletic   (50, 60]  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.copy()\n",
    "df1.drop(\"clean_item_description\", inplace=True,axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:13.489303Z",
     "start_time": "2021-05-03T20:24:13.444174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 33 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   train_id                             50000 non-null  int64  \n",
      " 1   item_description_bef_word_count      50000 non-null  float64\n",
      " 2   item_description_bef_char_count      50000 non-null  float64\n",
      " 3   item_description_bef_avg_word_len    50000 non-null  float64\n",
      " 4   item_description_upper_word_count    50000 non-null  float64\n",
      " 5   item_description_upper_char_count    50000 non-null  float64\n",
      " 6   item_description_stopword_count      50000 non-null  float64\n",
      " 7   item_description_punctuation_count   50000 non-null  float64\n",
      " 8   item_description_number_count        50000 non-null  float64\n",
      " 9   item_description_after_word_count    50000 non-null  float64\n",
      " 10  item_description_after_char_count    50000 non-null  float64\n",
      " 11  item_description_after_avg_word_len  50000 non-null  float64\n",
      " 12  clean_item_name                      50000 non-null  object \n",
      " 13  item_name_bef_word_count             50000 non-null  float64\n",
      " 14  item_name_bef_char_count             50000 non-null  float64\n",
      " 15  item_name_bef_avg_word_len           50000 non-null  float64\n",
      " 16  item_name_upper_word_count           50000 non-null  float64\n",
      " 17  item_name_upper_char_count           50000 non-null  float64\n",
      " 18  item_name_stopword_count             50000 non-null  float64\n",
      " 19  item_name_punctuation_count          50000 non-null  float64\n",
      " 20  item_name_number_count               50000 non-null  float64\n",
      " 21  item_name_after_word_count           50000 non-null  float64\n",
      " 22  item_name_after_char_count           50000 non-null  float64\n",
      " 23  item_name_after_avg_word_len         50000 non-null  float64\n",
      " 24  item_condition_id                    50000 non-null  int64  \n",
      " 25  category_name                        50000 non-null  object \n",
      " 26  brand_name                           50000 non-null  object \n",
      " 27  shipping                             50000 non-null  int64  \n",
      " 28  price                                50000 non-null  float64\n",
      " 29  c1                                   50000 non-null  object \n",
      " 30  c2                                   50000 non-null  object \n",
      " 31  c3                                   50000 non-null  object \n",
      " 32  price_bin                            50000 non-null  object \n",
      "dtypes: float64(23), int64(3), object(7)\n",
      "memory usage: 12.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:13.612108Z",
     "start_time": "2021-05-03T20:24:13.600140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 33), (50000, 100))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape,df_cid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:13.769865Z",
     "start_time": "2021-05-03T20:24:13.709383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 133)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat=pd.concat([df1,df_cid],axis=1)\n",
    "df_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using one-hot encoding for category and nominal features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete price bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:13.911557Z",
     "start_time": "2021-05-03T20:24:13.903547Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_catNnom = ['category_name','brand_name', 'c1', 'c2', 'c3'] # columns of category and nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:16.186214Z",
     "start_time": "2021-05-03T20:24:14.024439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3028)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from final.feature_encoding.one_hot_encoding import one_hot_encode_feature\n",
    "df_encode = df_concat\n",
    "for col in cols_catNnom:\n",
    "    df_encode, col_encode = one_hot_encode_feature(df_encode, encode_column=col,drop_first=False)\n",
    "df_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:16.904462Z",
     "start_time": "2021-05-03T20:24:16.875618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 3028 entries, train_id to c3_yoga & pilates\n",
      "dtypes: float64(123), int64(3), object(2), uint8(2900)\n",
      "memory usage: 187.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_encode.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:17.073320Z",
     "start_time": "2021-05-03T20:24:17.044003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>c3_window treatments</th>\n",
       "      <th>c3_wine, beer &amp; beverage coolers</th>\n",
       "      <th>c3_wipes &amp; holders</th>\n",
       "      <th>c3_women</th>\n",
       "      <th>c3_women's golf clubs</th>\n",
       "      <th>c3_wool</th>\n",
       "      <th>c3_work &amp; safety</th>\n",
       "      <th>c3_wrap</th>\n",
       "      <th>c3_writing</th>\n",
       "      <th>c3_yoga &amp; pilates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0    806824                              3.0                             13.0   \n",
       "1    772820                              6.0                             42.0   \n",
       "2   1423115                             11.0                             54.0   \n",
       "3    405853                             35.0                            188.0   \n",
       "4   1172086                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  \\\n",
       "0                                 0.0                            0.0   \n",
       "1                                 0.0                            0.0   \n",
       "2                                 0.0                            0.0   \n",
       "3                                 7.0                            1.0   \n",
       "4                                 3.0                            0.0   \n",
       "\n",
       "   item_description_after_word_count  ...  c3_window treatments  \\\n",
       "0                                2.0  ...                     0   \n",
       "1                                5.0  ...                     0   \n",
       "2                                6.0  ...                     0   \n",
       "3                               17.0  ...                     0   \n",
       "4                                5.0  ...                     0   \n",
       "\n",
       "   c3_wine, beer & beverage coolers c3_wipes & holders  c3_women  \\\n",
       "0                                 0                  0         0   \n",
       "1                                 0                  0         0   \n",
       "2                                 0                  0         0   \n",
       "3                                 0                  0         0   \n",
       "4                                 0                  0         0   \n",
       "\n",
       "   c3_women's golf clubs  c3_wool  c3_work & safety  c3_wrap  c3_writing  \\\n",
       "0                      0        0                 0        0           0   \n",
       "1                      0        0                 0        0           0   \n",
       "2                      0        0                 0        0           0   \n",
       "3                      0        0                 0        0           0   \n",
       "4                      0        0                 0        0           0   \n",
       "\n",
       "   c3_yoga & pilates  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 3028 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:17.248782Z",
     "start_time": "2021-05-03T20:24:17.218860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price\n",
       "0        15.0\n",
       "1        22.0\n",
       "2        54.0\n",
       "3        84.0\n",
       "4        56.0\n",
       "...       ...\n",
       "49995  1609.0\n",
       "49996   205.0\n",
       "49997    36.0\n",
       "49998    20.0\n",
       "49999    72.0\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encode[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:17.620872Z",
     "start_time": "2021-05-03T20:24:17.403412Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare input X, y\n",
    "X, y = df_encode.copy().drop([\"clean_item_name\",\"train_id\",\"price\",\"price_bin\"],axis=1), df_encode[[\"price\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:24:17.870116Z",
     "start_time": "2021-05-03T20:24:17.841816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 3024 entries, item_description_bef_word_count to c3_yoga & pilates\n",
      "dtypes: float64(122), int64(2), uint8(2900)\n",
      "memory usage: 185.6 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:33:15.799455Z",
     "start_time": "2021-05-03T20:33:15.378237Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct dimension reduction on the dateframe processed by one-hot encoding\n",
    "skip this step in the first place. <br>\n",
    "let us see how the regression result looks like. and then determine if the dimension reduction on whole dataset needed, or if use other techniques to avoid overfitting(e.g. adding penalty, using RobustScaler, conducting cross validation).<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 1: actually can't skip this step, the dimension is too large to run, Exception was raised: MemoryError: Unable to allocate 11.8 GiB for an array with shape (45079, 35000) and data type float64.\n",
    "Therefore, try conduct PCA again before regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 2: even can't not run PCA due to the large number of features. Try drop clean_item_name instead of encoding it, as it is has very less duplicated items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 3: Since log2 works, skip this step( e.i. 1.5) for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 4: features are too much later, have to reduce dimension at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:33:21.828715Z",
     "start_time": "2021-05-03T20:33:18.665484Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:37:52.140567Z",
     "start_time": "2021-05-03T20:37:35.484170Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00290486, 0.0022789 , 0.00214285, 0.00197305, 0.00188288,\n",
       "       0.00186249, 0.00180662, 0.00178066, 0.00174815, 0.0016754 ,\n",
       "       0.00162334, 0.0016063 , 0.00155175, 0.00154981, 0.00147137,\n",
       "       0.00146217, 0.00145709, 0.00145545, 0.0014492 , 0.00144028,\n",
       "       0.00143402, 0.00142974, 0.00142609, 0.00142109, 0.00141807,\n",
       "       0.00141246, 0.00141036, 0.00140121, 0.00139544, 0.00139292,\n",
       "       0.0013886 , 0.00138174, 0.00138119, 0.00136717, 0.00136214,\n",
       "       0.00135612, 0.00134181, 0.00133579, 0.00132456, 0.0013219 ,\n",
       "       0.00130613, 0.00130098, 0.0012937 , 0.00129239, 0.00128503,\n",
       "       0.00128127, 0.00127723, 0.00126964, 0.0012677 , 0.00126545,\n",
       "       0.00125469, 0.0012481 , 0.00124392, 0.00123624, 0.00121776,\n",
       "       0.00120707, 0.00120143, 0.00119584, 0.00119393, 0.00119201,\n",
       "       0.00118449, 0.00117942, 0.00117763, 0.00116285, 0.00115652,\n",
       "       0.00115441, 0.00115194, 0.00115066, 0.0011489 , 0.00113124,\n",
       "       0.00112673, 0.00112621, 0.00112206, 0.00111204, 0.0011057 ,\n",
       "       0.00110063, 0.00109938, 0.00109859, 0.00109758, 0.00109679,\n",
       "       0.00109639, 0.00109604, 0.00109594, 0.00109568, 0.00109554,\n",
       "       0.00109538, 0.00109513, 0.00109477, 0.00109463, 0.00109457,\n",
       "       0.0010941 , 0.00109347, 0.00109274, 0.00109203, 0.00109122,\n",
       "       0.00109099, 0.00108969, 0.00108891, 0.00108754, 0.00108571,\n",
       "       0.00108226, 0.00108114, 0.00107803, 0.00107506, 0.00107097,\n",
       "       0.00106601, 0.00105978, 0.00105483, 0.00105245, 0.00104898,\n",
       "       0.00104678, 0.00104561, 0.00104112, 0.00103884, 0.00103744,\n",
       "       0.00103525, 0.00102962, 0.00101969, 0.00101899, 0.00101684,\n",
       "       0.00101378, 0.00101172, 0.00100835, 0.00100677, 0.00100527,\n",
       "       0.00100365, 0.00100244, 0.00099898, 0.00099811, 0.00099582,\n",
       "       0.00099315, 0.00099198, 0.00099108, 0.00098858, 0.00098561,\n",
       "       0.00098424, 0.00098135, 0.00098057, 0.00097919, 0.00097875,\n",
       "       0.00097647, 0.0009761 , 0.00097492, 0.00097367, 0.00097293,\n",
       "       0.00097158, 0.00096852, 0.00096807, 0.00096618, 0.00096203,\n",
       "       0.00096014, 0.00095946, 0.00095519, 0.00095387, 0.00095328,\n",
       "       0.00095237, 0.00095202, 0.00095058, 0.00094803, 0.00094716,\n",
       "       0.00094555, 0.00094076, 0.00093936, 0.00093812, 0.00093702,\n",
       "       0.00093469, 0.00093156, 0.00092955, 0.00092753, 0.00092617,\n",
       "       0.00092503, 0.00092246, 0.00091864, 0.00091445, 0.00091239,\n",
       "       0.00091104, 0.00090987, 0.00090671, 0.00090577, 0.00090509,\n",
       "       0.00090353, 0.00090026, 0.00089973, 0.0008974 , 0.00089464,\n",
       "       0.00089289, 0.000891  , 0.00088981, 0.00088825, 0.00088719,\n",
       "       0.00088441, 0.00088191, 0.00088049, 0.000879  , 0.00087838,\n",
       "       0.00087764, 0.00087653, 0.0008754 , 0.00087301, 0.0008706 ,\n",
       "       0.00086932, 0.00086856, 0.00086765, 0.00086707, 0.00086603,\n",
       "       0.00086449, 0.00086425, 0.00086308, 0.00086268, 0.00086194,\n",
       "       0.00086063, 0.00085981, 0.0008594 , 0.00085797, 0.0008566 ,\n",
       "       0.00085508, 0.00085454, 0.0008539 , 0.00085226, 0.00085051,\n",
       "       0.00084977, 0.00084739, 0.00084656, 0.00084575, 0.0008446 ,\n",
       "       0.00084448, 0.00084301, 0.00084174, 0.00084075, 0.00083966,\n",
       "       0.0008371 , 0.00083576, 0.00083354, 0.00083248, 0.00083236,\n",
       "       0.00082946, 0.00082891, 0.00082646, 0.00082538, 0.00082479,\n",
       "       0.00082253, 0.00082208, 0.0008207 , 0.00081982, 0.00081945,\n",
       "       0.00081889, 0.00081761, 0.00081652, 0.00081615, 0.00081498,\n",
       "       0.00081405, 0.00081226, 0.0008116 , 0.00081073, 0.00080856,\n",
       "       0.00080724, 0.00080636, 0.00080591, 0.00080494, 0.00080427,\n",
       "       0.0008029 , 0.00080196, 0.00080113, 0.00080085, 0.0008003 ,\n",
       "       0.00079971, 0.00079826, 0.0007976 , 0.00079688, 0.00079669,\n",
       "       0.00079576, 0.00079537, 0.00079432, 0.0007928 , 0.0007918 ,\n",
       "       0.00079128, 0.00078971, 0.00078942, 0.00078903, 0.00078871,\n",
       "       0.00078775, 0.00078706, 0.00078611, 0.00078538, 0.00078467,\n",
       "       0.00078367, 0.00078307, 0.00078259, 0.00078107, 0.0007809 ,\n",
       "       0.00078041, 0.00077981, 0.00077925, 0.00077866, 0.00077788,\n",
       "       0.00077587, 0.00077512, 0.00077486, 0.00077423, 0.00077307,\n",
       "       0.00077228, 0.00077152, 0.00077083, 0.00077036, 0.00076972,\n",
       "       0.00076841, 0.00076828, 0.00076682, 0.00076592, 0.0007655 ,\n",
       "       0.00076448, 0.00076395, 0.00076311, 0.00076285, 0.00076183,\n",
       "       0.00076125, 0.00076062, 0.00075914, 0.00075836, 0.00075794,\n",
       "       0.00075764, 0.00075676, 0.00075573, 0.00075519, 0.00075481,\n",
       "       0.00075426, 0.00075421, 0.00075357, 0.00075268, 0.00075179,\n",
       "       0.00075133, 0.00075047, 0.00075027, 0.0007499 , 0.0007495 ,\n",
       "       0.00074883, 0.00074862, 0.00074725, 0.00074692, 0.0007462 ,\n",
       "       0.0007461 , 0.00074517, 0.00074497, 0.00074419, 0.00074384,\n",
       "       0.00074351, 0.00074317, 0.00074188, 0.00074172, 0.00074108,\n",
       "       0.00074075, 0.00074061, 0.00074052, 0.00073973, 0.00073927,\n",
       "       0.00073893, 0.00073872, 0.00073818, 0.00073796, 0.00073715,\n",
       "       0.00073659, 0.00073604, 0.00073557, 0.00073535, 0.00073472,\n",
       "       0.00073404, 0.00073396, 0.00073332, 0.00073302, 0.00073255,\n",
       "       0.00073245, 0.00073181, 0.0007313 , 0.00073112, 0.00073087,\n",
       "       0.00073073, 0.00073054, 0.00073003, 0.00072981, 0.00072929,\n",
       "       0.00072887, 0.00072869, 0.00072819, 0.0007279 , 0.00072733,\n",
       "       0.00072717, 0.00072707, 0.00072665, 0.00072651, 0.00072595,\n",
       "       0.0007258 , 0.000725  , 0.00072478, 0.00072449, 0.00072436,\n",
       "       0.00072392, 0.00072355, 0.00072285, 0.00072259, 0.00072216,\n",
       "       0.00072206, 0.00072155, 0.0007208 , 0.00072024, 0.00072018,\n",
       "       0.00071989, 0.00071976, 0.00071916, 0.00071835, 0.00071661,\n",
       "       0.00071573, 0.00071505, 0.00071457, 0.00071405, 0.00071317,\n",
       "       0.00071128, 0.00071084, 0.00070985, 0.0007094 , 0.00070842,\n",
       "       0.00070719, 0.00070621, 0.00070433, 0.00070367, 0.00070296,\n",
       "       0.00070143, 0.00070021, 0.00069572, 0.000695  , 0.00069388,\n",
       "       0.00069041, 0.00068883, 0.00068504, 0.0006834 , 0.00067809,\n",
       "       0.00067654, 0.0006738 , 0.00067105, 0.00066716, 0.00066523,\n",
       "       0.00066499, 0.00065792, 0.0006525 , 0.00065058, 0.00064528,\n",
       "       0.00064107, 0.00063659, 0.00062892, 0.00061925, 0.00061143,\n",
       "       0.0006066 , 0.00059653, 0.00059221, 0.0005878 , 0.00058188,\n",
       "       0.00058021, 0.00057575, 0.0005641 , 0.00056226, 0.00055449,\n",
       "       0.00054236, 0.0005339 , 0.00053237, 0.00052184, 0.00051797,\n",
       "       0.00051325, 0.00051242, 0.00050386, 0.00048189, 0.00047674,\n",
       "       0.00047241, 0.00046741, 0.00046664, 0.00046025, 0.00045868,\n",
       "       0.00045437, 0.00044949, 0.00044586, 0.0004434 , 0.00044083,\n",
       "       0.00043915, 0.0004336 , 0.00043286, 0.00043037, 0.00042852,\n",
       "       0.00042424, 0.00042266, 0.00042028, 0.00041779, 0.00041508,\n",
       "       0.00041319, 0.00041261, 0.0004116 , 0.00040917, 0.00040816,\n",
       "       0.00040574, 0.00040347, 0.00040169, 0.00039925, 0.00039621])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=500)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:37:56.448791Z",
     "start_time": "2021-05-03T20:37:56.428846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 500), (15000, 500))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape, X_test_pca.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Selection\n",
    "Proposal:\n",
    "1. try different regression techniques, and select the best one;\n",
    "      - DT regressor\n",
    "      * Ensemble method\n",
    "      - Adding polynomial items to multiple linear regression? \n",
    "      - Tensorflow.Keras\n",
    "2. focus on the selected one and tuning modelling.(Guessing propably would use Ensemble learning or Keras in the end)<br>\n",
    "**Based on the our previous experiment so far, our results have both large bias and variance.** Probably need to use more powerful algorithm to improve the bias, and then considering solve overfitting issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:39:19.411094Z",
     "start_time": "2021-05-03T20:39:19.388157Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score,r2_score \n",
    "def evaluate_dt_regressor(X_train, X_test, y_train, y_test,n_iter,max_depth):\n",
    "    # the maximum depth of the tree. If None, then nodes are expanded until all leaves are pure\n",
    "    MSE_test=[]\n",
    "    EVS_test=[]\n",
    "    R2_test=[]\n",
    "    MSE_train=[]\n",
    "    EVS_train=[]\n",
    "    R2_train=[]\n",
    "    for i in range(n_iter):\n",
    "        rg = tree.DecisionTreeRegressor(max_depth=max_depth)\n",
    "        rg.fit(X_train, y_train)\n",
    "        y_train_pred = rg.predict(X_train)\n",
    "        y_pred = rg.predict(X_test)\n",
    "        MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "        EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "        R2_train.append(r2_score(y_train, y_train_pred))\n",
    "        \n",
    "        MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "        EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "        R2_test.append(r2_score(y_test, y_pred))\n",
    "    print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "    print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:40:03.143348Z",
     "start_time": "2021-05-03T20:39:20.729423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 1.4285714285714285e-05 EVS: 0.9999999996453222 R2: 0.9999999996453222\n",
      "Test score: MSE: 20444.605316666668 EVS: 0.4576498018365237 R2: 0.45757297223371407\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca, y_train, y_test,1,max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:41:10.337050Z",
     "start_time": "2021-05-03T20:41:04.250048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 27414.984394562318 EVS: 0.3193558770393383 R2: 0.3193558770393383\n",
      "Test score: MSE: 24911.631535077548 EVS: 0.3390785961873015 R2: 0.3390558516008496\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,y_train, y_test,1,max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:41:20.191480Z",
     "start_time": "2021-05-03T20:41:10.575341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 21470.693098680924 EVS: 0.46693746517660495 R2: 0.46693746517660484\n",
      "Test score: MSE: 21338.688174806877 EVS: 0.4338543263328638 R2: 0.4338515699466069\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,  y_train, y_test,1,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:49:18.705841Z",
     "start_time": "2021-05-03T20:41:20.408001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 1.4285714285714289e-05 EVS: 0.9999999996453222 R2: 0.9999999996453222\n",
      "Test score: MSE: 20796.324884999998 EVS: 0.4483532295694417 R2: 0.4482413076159205\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,  y_train, y_test,10,max_depth=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T22:14:37.631305Z",
     "start_time": "2021-05-03T20:48:55.890Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train_pca, y_train)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why linear regression is so slow. after 1 and harf hour, not completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T14:12:29.083725Z",
     "start_time": "2021-05-04T14:12:29.077777Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, explained_variance_score,r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T14:19:36.571581Z",
     "start_time": "2021-05-04T14:19:34.144670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'MSE': 990.2144264683332, 'EVS': 0.9762126689873514, 'R2': 0.9754155019697835}\n",
      "test: {'MSE': 22210.446474589295, 'EVS': 0.4107919615689941, 'R2': 0.4107224727516572}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train_pca, y_train)\n",
    "y_train_pred = rg.predict(X_train_pca)\n",
    "y_pred = reg.predict(X_test_pca)\n",
    "\n",
    "print(\"train:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_train, y_train_pred), \n",
    "    \"EVS\": explained_variance_score(y_train, y_train_pred), \n",
    "    \"R2\": r2_score(y_train, y_train_pred)\n",
    "})\n",
    "\n",
    "print(\"test:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred), \n",
    "    \"EVS\": explained_variance_score(y_test, y_pred), \n",
    "    \"R2\": r2_score(y_test, y_pred)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T14:10:35.414957Z",
     "start_time": "2021-05-04T14:10:35.177522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.01661616e+01,  3.57170497e+00, -1.21743025e+01,\n",
       "         1.03850638e-01, -5.37371805e+00,  1.19993145e+01,\n",
       "        -8.29245020e-01,  6.77126180e+00, -2.36707161e+01,\n",
       "        -6.22912942e+00,  3.10004496e+00, -8.60990629e+00,\n",
       "         1.39351526e+00, -2.92582226e+00, -5.66847894e+00,\n",
       "        -4.99938439e-02,  2.48445259e-01,  4.03682124e+00,\n",
       "        -2.77682057e-03,  1.11183677e+00, -1.30465959e+00,\n",
       "         5.06837600e+00,  2.08765704e+00, -2.11372111e+00,\n",
       "         1.46605907e+01,  4.56182235e-01,  2.85324042e+00,\n",
       "        -1.33500733e+00,  1.53469833e+00, -4.18507276e+00,\n",
       "        -7.30598243e+00, -3.74429088e+00,  3.58974449e+00,\n",
       "        -6.73590742e+00,  1.25521492e+01,  3.13108578e+00,\n",
       "        -1.92969608e+00, -3.13510119e+00,  1.27897515e+00,\n",
       "        -3.28727765e-02, -8.42735875e-01, -6.53110713e+00,\n",
       "         4.47492400e+00, -1.39037208e+00, -7.69727479e-01,\n",
       "         4.62334193e-01, -4.22307302e+00, -2.02309253e+00,\n",
       "        -2.64448708e+00,  9.42640916e+00,  8.84463204e+00,\n",
       "        -1.67100852e+00,  6.01858663e+00, -1.38872322e+00,\n",
       "         1.19088718e-01, -3.59899943e+00, -1.11389091e+00,\n",
       "         8.04010203e-01, -4.16308138e-01, -6.72419343e-01,\n",
       "        -7.97695416e-01, -1.19924302e+00, -2.27510016e+00,\n",
       "         4.11317962e-01,  1.41960515e+00, -1.71348967e+00,\n",
       "        -3.09160576e+00, -1.58244021e+00, -2.41052262e+00,\n",
       "        -2.47247788e+00,  3.13360857e+00, -4.28024287e+00,\n",
       "         3.81022551e+00,  8.71987055e-01, -7.56631167e-01,\n",
       "         1.76403302e-01, -1.26852523e+00, -3.85518869e-03,\n",
       "        -2.39807120e-01, -8.54983961e-02, -8.34587762e-01,\n",
       "        -1.62236776e-01,  1.72754772e-01, -2.60036848e-01,\n",
       "         1.84611156e-02, -3.73655098e-01,  1.02959693e-01,\n",
       "         3.71742887e-01, -1.50575797e-01, -1.34996660e+00,\n",
       "         4.15366278e-01, -3.54827321e-01,  1.58251534e-02,\n",
       "        -6.15189824e-01, -3.59055568e-01, -6.72474988e-01,\n",
       "         1.05391017e+00, -3.42541868e-01, -5.16772226e-01,\n",
       "        -1.12739641e+00, -7.95114237e-01,  2.65854900e+00,\n",
       "        -7.11794488e-02, -2.95969086e-01, -1.98325805e+00,\n",
       "         2.72998342e+00, -1.56063691e+00,  2.07579822e-01,\n",
       "        -6.95246985e-01, -1.35549426e+00,  1.58441289e+00,\n",
       "         3.19483462e+00,  2.92426544e-01,  2.17053235e+00,\n",
       "         3.84406577e+00, -2.44187592e+00,  3.92699289e+00,\n",
       "         8.14960318e-01, -3.07512325e-01,  1.34636866e+00,\n",
       "         4.00900423e-01, -9.50048730e-01, -5.28365088e-01,\n",
       "        -6.78120199e-01,  1.09224707e+00, -5.47667561e-01,\n",
       "         7.10854712e-01,  9.15417195e-02, -1.33368174e-01,\n",
       "        -3.73914648e+00,  1.83979182e+00, -7.92373272e-02,\n",
       "        -3.26641092e+00, -8.61915001e-01, -8.22686063e-03,\n",
       "         5.06015672e-01, -3.03994171e+00,  7.72758702e-01,\n",
       "        -2.49594546e+00,  1.09745027e+00, -1.38087307e+00,\n",
       "         1.60439327e+00, -2.52736765e-02, -3.15106455e+00,\n",
       "        -2.70631641e+00,  5.34304674e-01,  3.81466301e+00,\n",
       "         6.46656971e-01, -2.36711509e-02,  1.84776270e-01,\n",
       "         3.07853488e-01,  3.21427642e-01,  5.67302762e-01,\n",
       "        -1.55025530e+00,  1.87158635e+00, -2.69702557e-01,\n",
       "         1.00935565e+00,  1.94033163e+00,  1.43132234e+00,\n",
       "        -3.00284274e+00,  1.37812749e-01, -2.04248125e+00,\n",
       "         5.01170161e-01, -8.66032625e-01, -1.18160479e+00,\n",
       "        -2.79451871e+00, -2.17620290e+00,  3.07370475e+00,\n",
       "        -3.13693947e-01,  5.68333967e-01, -3.36702897e+00,\n",
       "        -1.14599590e+00,  7.56273299e-01, -3.18156638e+00,\n",
       "        -2.92815775e+00,  2.88637558e+00,  1.12832226e+00,\n",
       "         2.70765774e+00, -4.98231871e-01,  1.74880078e+00,\n",
       "        -1.39456148e+00, -2.51216995e-01,  2.45153104e+00,\n",
       "         7.14560548e-01, -7.59337954e-01, -2.29667186e+00,\n",
       "        -4.13292713e+00, -6.18878359e-02, -1.09801587e+00,\n",
       "        -1.93155769e+00,  3.24893146e+00,  9.76975786e-01,\n",
       "        -4.28766051e+00,  1.06086690e+00, -7.95583583e-01,\n",
       "        -3.48352619e+00, -7.52929134e-01, -1.11889381e+00,\n",
       "        -2.95980499e+00,  7.52509796e-02,  8.09672328e-01,\n",
       "        -4.86555162e-01,  2.21066142e+00, -1.75772635e+00,\n",
       "        -1.41428810e+00,  3.85372417e+00,  4.53439254e+00,\n",
       "        -2.94751413e+00,  1.57859774e+00,  2.43449758e-01,\n",
       "        -1.98367219e+00, -5.55102364e-01,  1.67922036e+00,\n",
       "        -3.22442861e-01,  2.44371386e+00,  2.66175803e+00,\n",
       "        -8.17717247e-01,  1.91309403e+00, -6.80409340e-02,\n",
       "        -2.10487532e+00,  1.76134603e-01, -2.04341996e+00,\n",
       "        -3.29424655e+00,  1.33604213e+00,  2.28639832e-01,\n",
       "         1.97896533e+00,  4.02335444e-01, -2.61621722e+00,\n",
       "         4.05057727e-01, -5.59627726e-03, -1.55845775e+00,\n",
       "         3.76661801e+00,  5.41346555e-01, -3.88790479e+00,\n",
       "         2.62576485e-01,  2.56089887e+00, -2.87188225e+00,\n",
       "        -1.17140475e+00,  6.02495162e-02,  1.08711164e+00,\n",
       "        -2.60549571e+00,  1.99279594e+00, -4.04264102e+00,\n",
       "         1.95445934e+00, -4.14599939e+00, -1.06140160e+00,\n",
       "         1.97337901e+00, -2.64103075e+00,  2.43856774e+00,\n",
       "        -1.75678844e+00, -1.23240188e+00, -3.70867315e-02,\n",
       "        -3.96676465e+00,  5.03709214e-02,  6.87222601e-01,\n",
       "        -1.24196598e-02,  6.18205497e-01, -1.44824215e+00,\n",
       "        -1.15287859e+00, -1.41568012e+00, -4.42389613e+00,\n",
       "        -2.28281257e+00,  5.22670603e+00, -1.89993669e+00,\n",
       "        -1.58178417e+00,  1.42178166e-01, -8.22929545e-01,\n",
       "         3.14406880e+00,  6.95128335e-01, -3.94178839e+00,\n",
       "         1.58603391e+00,  2.13092682e+00,  2.01864586e+00,\n",
       "         4.12092795e+00, -3.76124341e+00,  3.02808386e+00,\n",
       "         3.70965992e+00, -6.72153281e+00,  1.42277535e+00,\n",
       "         4.60220680e+00, -2.21677544e-01,  3.27378667e+00,\n",
       "        -1.61507492e+00,  2.22639314e+00, -1.97443485e-02,\n",
       "         3.18150137e+00,  3.04573415e+00,  2.07463187e+00,\n",
       "        -6.54725513e+00, -4.86326644e+00,  2.43968497e+00,\n",
       "        -2.14151671e+00,  8.20627815e-01, -1.17057569e+00,\n",
       "         3.92923550e-01,  1.33928909e+00, -3.87054010e+00,\n",
       "         1.38003923e+00, -1.31604393e+00, -5.63642676e-01,\n",
       "         2.04754132e+00,  8.74168024e-01,  2.80833319e+00,\n",
       "        -3.02774683e+00, -1.65167723e+00,  1.94622255e+00,\n",
       "        -2.73039454e+00,  1.07145730e+00,  4.57290662e-01,\n",
       "        -3.13890188e-01, -1.78697151e-01, -1.66517266e+00,\n",
       "        -8.63740391e-01, -1.10737382e+00,  1.95384251e+00,\n",
       "        -3.76142386e+00,  3.87993485e+00, -2.11010427e+00,\n",
       "        -2.73329704e+00,  1.94349160e+00,  4.74840338e+00,\n",
       "         2.92936388e+00, -2.30777488e-01,  4.82252409e-01,\n",
       "         1.57224491e+00,  4.03586513e+00, -9.93519843e-01,\n",
       "        -1.83148316e+00,  1.18729926e+00,  6.54397444e-02,\n",
       "         7.87690400e-01,  1.17308893e-01,  5.99832637e-01,\n",
       "        -2.56889719e+00,  6.57118238e-01,  4.40628599e+00,\n",
       "        -1.05398660e+00, -1.71990641e+00, -1.04776164e+00,\n",
       "        -3.33588538e-01, -7.36455585e-01,  2.30104773e+00,\n",
       "         2.79672995e-01, -3.68041332e-01,  1.96071449e+00,\n",
       "         7.25709910e-01, -6.22082339e-01, -1.14657284e+00,\n",
       "        -1.03659780e+00, -4.78883935e-01, -3.29647748e-02,\n",
       "        -1.79368919e+00,  1.75140336e+00,  6.92871835e-01,\n",
       "        -1.11971492e-02,  5.66525810e-01,  1.50540909e+00,\n",
       "         3.02289625e-01,  2.17369110e-01, -8.96703074e-01,\n",
       "         7.58481759e-01,  7.49144071e-01, -2.61202735e-01,\n",
       "         7.50619446e-01,  5.16124928e-01, -3.84855943e-01,\n",
       "         5.17088914e-01, -8.00042520e-01, -5.05620057e-01,\n",
       "        -5.86721810e-01, -9.62174946e-01, -3.72700303e-01,\n",
       "         8.95132848e-01, -4.71459419e-02, -9.34658289e-02,\n",
       "        -2.45644719e-01, -1.59127484e-01, -9.47495178e-01,\n",
       "         9.90246112e-01, -3.80536406e-01,  4.08143037e-01,\n",
       "         4.45754846e-01,  1.12565925e+00,  4.03192600e-01,\n",
       "        -1.04424712e-01,  2.90739329e-01,  3.94847688e-02,\n",
       "        -8.96474532e-01,  2.62176935e-01, -1.26793108e+00,\n",
       "        -1.04821694e+00, -6.22942185e-01, -2.44147563e+00,\n",
       "        -7.83705709e-01, -1.11761049e+00,  3.71254389e-01,\n",
       "        -7.52047459e-01,  4.61428645e-01, -1.26248017e+00,\n",
       "         1.46071181e+00,  7.66732105e-01, -1.78153665e+00,\n",
       "        -9.52649981e-01, -1.05716689e+00,  5.01146868e-01,\n",
       "         3.11729180e-01, -7.13714883e-01,  4.77706854e-02,\n",
       "         7.16816585e-01, -1.47690121e+00, -7.83536545e-01,\n",
       "         1.17407455e+00,  2.44290055e-01, -1.14252050e-01,\n",
       "         2.69604900e+00, -8.04173673e-01, -4.72988110e-01,\n",
       "        -1.88873387e+00,  6.93062988e-01, -2.27888583e+00,\n",
       "        -1.40186601e+00, -8.42056514e-01, -1.57684956e+00,\n",
       "        -4.26688217e-01,  1.04645173e+00,  2.50671086e-01,\n",
       "         1.53154911e+00, -4.75409972e-01,  1.94882297e+00,\n",
       "        -1.64022495e+00,  3.74641521e-01, -1.03124597e+00,\n",
       "        -7.47686866e-01, -1.15793436e+00, -4.61451698e-01,\n",
       "         9.41061601e-01, -2.10493100e+00,  2.30154077e+00,\n",
       "        -1.09994511e-01, -1.85584513e+00, -3.17280352e-01,\n",
       "         1.86910974e+00, -3.91757360e-02,  2.37341604e+00,\n",
       "         2.76492076e+00, -1.20035264e+00,  3.12688741e+00,\n",
       "        -1.20028008e+00,  3.65742825e+00, -1.50253956e+00,\n",
       "        -2.63380214e+00,  4.20982298e-01,  7.74456347e+00,\n",
       "        -4.29044409e-01,  5.31396756e-01, -2.03798688e+00,\n",
       "         2.52158747e+00, -1.78161194e+00, -3.25150045e+00,\n",
       "         1.41828076e+00,  2.33990841e+00, -2.53383479e+00,\n",
       "         3.71308958e+00, -2.64985175e+00, -1.17874847e+00,\n",
       "        -1.22681028e+00, -3.83436527e-01,  6.29439625e+00,\n",
       "         1.45613443e+00,  6.84095837e+00,  5.73164864e-01,\n",
       "         2.64621824e+00,  6.33619950e+00,  1.05557649e-01,\n",
       "        -3.81920745e+00, -4.29976507e+00,  2.29911939e+00,\n",
       "        -2.98381488e+00,  2.99634381e-01,  4.37333073e+00,\n",
       "        -2.65741209e+00,  5.37679371e+00,  1.34971115e+00,\n",
       "         5.67938828e+00, -6.53162126e+00,  2.18280823e+00,\n",
       "         1.97179599e-02, -1.47538723e+00,  2.22685842e-01,\n",
       "        -3.41014394e+00,  3.02203911e+00, -2.22725487e+00,\n",
       "        -5.06164338e+00, -3.31246870e+00, -3.39078643e+00,\n",
       "         9.55549572e+00,  2.38383825e+00,  2.28971709e-01,\n",
       "         2.13039947e+00,  2.39623309e+00]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha=.5)\n",
    "reg.fit(X_train_pca, y_train)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Bagging) for classification, also for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T22:48:00.633659Z",
     "start_time": "2021-05-03T22:48:00.608699Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def evaluate_rf_regressor(X_train, X_test, y_train, y_test,n_iter,max_depth,random_state):\n",
    "    MSE_test=[]\n",
    "    EVS_test=[]\n",
    "    R2_test=[]\n",
    "    MSE_train=[]\n",
    "    EVS_train=[]\n",
    "    R2_train=[]\n",
    "    for i in range(n_iter):\n",
    "        rg = RandomForestRegressor(max_depth=max_depth, random_state=random_state)\n",
    "        rg.fit(X_train, y_train)\n",
    "        y_train_pred = rg.predict(X_train)\n",
    "        y_pred = rg.predict(X_test)\n",
    "        MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "        EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "        R2_train.append(r2_score(y_train, y_train_pred))\n",
    "        \n",
    "        MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "        EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "        R2_test.append(r2_score(y_test, y_pred))\n",
    "    print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "    print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_regressor turns out very very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:33:56.941889Z",
     "start_time": "2021-05-03T22:48:03.015776Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-ffee7f25d399>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rg.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 990.2144264683332 EVS: 0.9762126689873514 R2: 0.9754155019697835\n",
      "Test score: MSE: 8995.427674365284 EVS: 0.7621419387473207 R2: 0.7613373786719745\n"
     ]
    }
   ],
   "source": [
    "evaluate_rf_regressor(X_train_pca, X_test_pca, y_train, y_test,1,max_depth=None,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T00:15:53.531190Z",
     "start_time": "2021-05-03T23:33:57.194172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-558030b727bd>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rg.fit(X_train_pca, y_train)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MSE_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-558030b727bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mMSE_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mEVS_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexplained_variance_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mR2_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MSE_train' is not defined"
     ]
    }
   ],
   "source": [
    "rg = RandomForestRegressor(max_depth=None, random_state=42)\n",
    "rg.fit(X_train_pca, y_train)\n",
    "y_train_pred = rg.predict(X_train_pca)\n",
    "y_pred = rg.predict(X_test_pca)\n",
    "MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "R2_train.append(r2_score(y_train, y_train_pred))\n",
    "\n",
    "MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "R2_test.append(r2_score(y_test, y_pred))\n",
    "print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:09:48.005739Z",
     "start_time": "2021-05-04T13:09:47.465304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rg.feature_importances_\n",
    "importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:09:49.846589Z",
     "start_time": "2021-05-04T13:09:49.835306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3024)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:14:07.663612Z",
     "start_time": "2021-05-04T13:14:07.573550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 7                              0.105877\n",
      " 2) 24                             0.063736\n",
      " 3) 33                             0.055135\n",
      " 4) 288                            0.033101\n",
      " 5) 1                              0.030501\n",
      " 6) 10                             0.025732\n",
      " 7) 316                            0.017765\n",
      " 8) 89                             0.014740\n",
      " 9) 48                             0.012854\n",
      "10) 469                            0.012297\n",
      "11) 11                             0.010544\n",
      "12) 262                            0.009389\n",
      "13) 2                              0.008283\n",
      "14) 0                              0.007948\n",
      "15) 14                             0.007850\n",
      "16) 491                            0.007349\n",
      "17) 57                             0.006804\n",
      "18) 6                              0.006769\n",
      "19) 34                             0.006605\n",
      "20) 46                             0.006498\n",
      "21) 261                            0.005871\n",
      "22) 476                            0.005158\n",
      "23) 483                            0.004931\n",
      "24) 192                            0.004860\n",
      "25) 252                            0.004593\n",
      "26) 8                              0.004519\n",
      "27) 285                            0.004433\n",
      "28) 273                            0.004364\n",
      "29) 216                            0.004305\n",
      "30) 467                            0.004116\n",
      "31) 116                            0.003915\n",
      "32) 27                             0.003776\n",
      "33) 323                            0.003739\n",
      "34) 175                            0.003534\n",
      "35) 242                            0.003235\n",
      "36) 299                            0.003226\n",
      "37) 399                            0.003218\n",
      "38) 32                             0.003109\n",
      "39) 470                            0.002954\n",
      "40) 25                             0.002944\n",
      "41) 70                             0.002937\n",
      "42) 167                            0.002923\n",
      "43) 455                            0.002843\n",
      "44) 5                              0.002751\n",
      "45) 235                            0.002579\n",
      "46) 477                            0.002554\n",
      "47) 3                              0.002538\n",
      "48) 20                             0.002510\n",
      "49) 39                             0.002465\n",
      "50) 208                            0.002452\n",
      "51) 493                            0.002441\n",
      "52) 269                            0.002374\n",
      "53) 80                             0.002358\n",
      "54) 170                            0.002353\n",
      "55) 321                            0.002326\n",
      "56) 120                            0.002315\n",
      "57) 174                            0.002315\n",
      "58) 484                            0.002294\n",
      "59) 318                            0.002258\n",
      "60) 472                            0.002208\n",
      "61) 26                             0.002193\n",
      "62) 125                            0.002192\n",
      "63) 495                            0.002172\n",
      "64) 274                            0.002160\n",
      "65) 103                            0.002083\n",
      "66) 38                             0.002052\n",
      "67) 222                            0.002014\n",
      "68) 437                            0.001982\n",
      "69) 129                            0.001977\n",
      "70) 15                             0.001932\n",
      "71) 489                            0.001922\n",
      "72) 180                            0.001899\n",
      "73) 390                            0.001878\n",
      "74) 259                            0.001860\n",
      "75) 209                            0.001827\n",
      "76) 91                             0.001807\n",
      "77) 99                             0.001794\n",
      "78) 84                             0.001762\n",
      "79) 479                            0.001747\n",
      "80) 492                            0.001742\n",
      "81) 376                            0.001733\n",
      "82) 12                             0.001718\n",
      "83) 402                            0.001680\n",
      "84) 189                            0.001679\n",
      "85) 355                            0.001668\n",
      "86) 218                            0.001644\n",
      "87) 104                            0.001614\n",
      "88) 71                             0.001593\n",
      "89) 113                            0.001578\n",
      "90) 450                            0.001569\n",
      "91) 409                            0.001556\n",
      "92) 223                            0.001526\n",
      "93) 72                             0.001523\n",
      "94) 298                            0.001514\n",
      "95) 217                            0.001507\n",
      "96) 327                            0.001496\n",
      "97) 154                            0.001495\n",
      "98) 244                            0.001493\n",
      "99) 40                             0.001477\n",
      "100) 162                            0.001472\n",
      "101) 443                            0.001471\n",
      "102) 254                            0.001451\n",
      "103) 258                            0.001448\n",
      "104) 58                             0.001448\n",
      "105) 419                            0.001445\n",
      "106) 311                            0.001441\n",
      "107) 90                             0.001437\n",
      "108) 148                            0.001434\n",
      "109) 291                            0.001429\n",
      "110) 434                            0.001424\n",
      "111) 105                            0.001421\n",
      "112) 28                             0.001421\n",
      "113) 9                              0.001420\n",
      "114) 485                            0.001408\n",
      "115) 52                             0.001407\n",
      "116) 315                            0.001406\n",
      "117) 94                             0.001392\n",
      "118) 13                             0.001392\n",
      "119) 23                             0.001391\n",
      "120) 176                            0.001376\n",
      "121) 418                            0.001368\n",
      "122) 386                            0.001367\n",
      "123) 303                            0.001366\n",
      "124) 268                            0.001365\n",
      "125) 30                             0.001357\n",
      "126) 119                            0.001347\n",
      "127) 356                            0.001347\n",
      "128) 87                             0.001345\n",
      "129) 49                             0.001341\n",
      "130) 73                             0.001339\n",
      "131) 276                            0.001336\n",
      "132) 481                            0.001335\n",
      "133) 42                             0.001318\n",
      "134) 461                            0.001309\n",
      "135) 230                            0.001309\n",
      "136) 100                            0.001309\n",
      "137) 111                            0.001304\n",
      "138) 494                            0.001299\n",
      "139) 382                            0.001298\n",
      "140) 295                            0.001288\n",
      "141) 92                             0.001279\n",
      "142) 83                             0.001278\n",
      "143) 385                            0.001275\n",
      "144) 248                            0.001273\n",
      "145) 465                            0.001262\n",
      "146) 499                            0.001251\n",
      "147) 131                            0.001248\n",
      "148) 183                            0.001246\n",
      "149) 279                            0.001242\n",
      "150) 50                             0.001236\n",
      "151) 246                            0.001232\n",
      "152) 79                             0.001230\n",
      "153) 220                            0.001230\n",
      "154) 411                            0.001228\n",
      "155) 159                            0.001227\n",
      "156) 96                             0.001226\n",
      "157) 497                            0.001223\n",
      "158) 294                            0.001212\n",
      "159) 236                            0.001210\n",
      "160) 102                            0.001204\n",
      "161) 460                            0.001184\n",
      "162) 77                             0.001182\n",
      "163) 18                             0.001176\n",
      "164) 41                             0.001174\n",
      "165) 47                             0.001172\n",
      "166) 452                            0.001158\n",
      "167) 212                            0.001147\n",
      "168) 283                            0.001138\n",
      "169) 496                            0.001135\n",
      "170) 108                            0.001127\n",
      "171) 107                            0.001126\n",
      "172) 146                            0.001125\n",
      "173) 381                            0.001123\n",
      "174) 449                            0.001115\n",
      "175) 413                            0.001109\n",
      "176) 51                             0.001106\n",
      "177) 158                            0.001103\n",
      "178) 98                             0.001100\n",
      "179) 426                            0.001099\n",
      "180) 31                             0.001098\n",
      "181) 63                             0.001096\n",
      "182) 150                            0.001091\n",
      "183) 439                            0.001089\n",
      "184) 21                             0.001088\n",
      "185) 344                            0.001086\n",
      "186) 482                            0.001083\n",
      "187) 458                            0.001081\n",
      "188) 78                             0.001080\n",
      "189) 332                            0.001070\n",
      "190) 16                             0.001064\n",
      "191) 238                            0.001063\n",
      "192) 416                            0.001059\n",
      "193) 322                            0.001058\n",
      "194) 290                            0.001055\n",
      "195) 320                            0.001054\n",
      "196) 287                            0.001052\n",
      "197) 374                            0.001044\n",
      "198) 166                            0.001040\n",
      "199) 474                            0.001031\n",
      "200) 66                             0.001031\n",
      "201) 369                            0.001027\n",
      "202) 312                            0.001026\n",
      "203) 463                            0.001023\n",
      "204) 251                            0.001019\n",
      "205) 114                            0.001019\n",
      "206) 112                            0.001017\n",
      "207) 4                              0.001013\n",
      "208) 420                            0.001012\n",
      "209) 35                             0.001010\n",
      "210) 117                            0.001004\n",
      "211) 227                            0.001004\n",
      "212) 115                            0.001001\n",
      "213) 490                            0.001000\n",
      "214) 86                             0.000999\n",
      "215) 234                            0.000995\n",
      "216) 328                            0.000995\n",
      "217) 68                             0.000992\n",
      "218) 186                            0.000990\n",
      "219) 53                             0.000989\n",
      "220) 142                            0.000986\n",
      "221) 178                            0.000986\n",
      "222) 448                            0.000985\n",
      "223) 237                            0.000982\n",
      "224) 301                            0.000982\n",
      "225) 256                            0.000979\n",
      "226) 267                            0.000969\n",
      "227) 309                            0.000968\n",
      "228) 128                            0.000967\n",
      "229) 67                             0.000964\n",
      "230) 134                            0.000962\n",
      "231) 480                            0.000959\n",
      "232) 181                            0.000957\n",
      "233) 36                             0.000957\n",
      "234) 135                            0.000954\n",
      "235) 253                            0.000953\n",
      "236) 410                            0.000951\n",
      "237) 471                            0.000945\n",
      "238) 106                            0.000945\n",
      "239) 165                            0.000942\n",
      "240) 200                            0.000942\n",
      "241) 468                            0.000942\n",
      "242) 171                            0.000941\n",
      "243) 398                            0.000941\n",
      "244) 286                            0.000940\n",
      "245) 475                            0.000940\n",
      "246) 144                            0.000939\n",
      "247) 199                            0.000938\n",
      "248) 407                            0.000936\n",
      "249) 93                             0.000934\n",
      "250) 394                            0.000934\n",
      "251) 447                            0.000930\n",
      "252) 488                            0.000929\n",
      "253) 423                            0.000928\n",
      "254) 61                             0.000924\n",
      "255) 330                            0.000923\n",
      "256) 215                            0.000921\n",
      "257) 155                            0.000920\n",
      "258) 55                             0.000913\n",
      "259) 457                            0.000909\n",
      "260) 352                            0.000909\n",
      "261) 179                            0.000906\n",
      "262) 388                            0.000905\n",
      "263) 335                            0.000904\n",
      "264) 319                            0.000899\n",
      "265) 195                            0.000898\n",
      "266) 459                            0.000897\n",
      "267) 76                             0.000894\n",
      "268) 44                             0.000891\n",
      "269) 375                            0.000890\n",
      "270) 438                            0.000890\n",
      "271) 453                            0.000887\n",
      "272) 313                            0.000886\n",
      "273) 22                             0.000885\n",
      "274) 271                            0.000883\n",
      "275) 266                            0.000882\n",
      "276) 451                            0.000881\n",
      "277) 60                             0.000881\n",
      "278) 349                            0.000881\n",
      "279) 264                            0.000880\n",
      "280) 121                            0.000877\n",
      "281) 370                            0.000876\n",
      "282) 153                            0.000876\n",
      "283) 314                            0.000868\n",
      "284) 280                            0.000867\n",
      "285) 401                            0.000867\n",
      "286) 29                             0.000866\n",
      "287) 184                            0.000860\n",
      "288) 387                            0.000860\n",
      "289) 126                            0.000859\n",
      "290) 19                             0.000853\n",
      "291) 211                            0.000852\n",
      "292) 110                            0.000852\n",
      "293) 431                            0.000851\n",
      "294) 182                            0.000847\n",
      "295) 289                            0.000843\n",
      "296) 446                            0.000841\n",
      "297) 62                             0.000837\n",
      "298) 337                            0.000835\n",
      "299) 462                            0.000835\n",
      "300) 417                            0.000833\n",
      "301) 231                            0.000831\n",
      "302) 270                            0.000827\n",
      "303) 168                            0.000826\n",
      "304) 338                            0.000826\n",
      "305) 172                            0.000825\n",
      "306) 308                            0.000823\n",
      "307) 132                            0.000821\n",
      "308) 265                            0.000818\n",
      "309) 421                            0.000817\n",
      "310) 45                             0.000817\n",
      "311) 487                            0.000815\n",
      "312) 198                            0.000809\n",
      "313) 436                            0.000808\n",
      "314) 228                            0.000807\n",
      "315) 341                            0.000806\n",
      "316) 161                            0.000805\n",
      "317) 428                            0.000802\n",
      "318) 293                            0.000802\n",
      "319) 151                            0.000801\n",
      "320) 361                            0.000799\n",
      "321) 359                            0.000798\n",
      "322) 464                            0.000794\n",
      "323) 353                            0.000791\n",
      "324) 367                            0.000791\n",
      "325) 284                            0.000790\n",
      "326) 122                            0.000789\n",
      "327) 37                             0.000788\n",
      "328) 194                            0.000787\n",
      "329) 240                            0.000783\n",
      "330) 354                            0.000778\n",
      "331) 221                            0.000776\n",
      "332) 430                            0.000776\n",
      "333) 101                            0.000776\n",
      "334) 203                            0.000775\n",
      "335) 404                            0.000772\n",
      "336) 249                            0.000772\n",
      "337) 81                             0.000769\n",
      "338) 56                             0.000765\n",
      "339) 396                            0.000765\n",
      "340) 444                            0.000763\n",
      "341) 331                            0.000760\n",
      "342) 445                            0.000760\n",
      "343) 325                            0.000757\n",
      "344) 306                            0.000756\n",
      "345) 435                            0.000755\n",
      "346) 362                            0.000754\n",
      "347) 219                            0.000753\n",
      "348) 351                            0.000753\n",
      "349) 124                            0.000750\n",
      "350) 422                            0.000748\n",
      "351) 17                             0.000748\n",
      "352) 147                            0.000746\n",
      "353) 282                            0.000746\n",
      "354) 160                            0.000746\n",
      "355) 202                            0.000745\n",
      "356) 272                            0.000744\n",
      "357) 406                            0.000740\n",
      "358) 43                             0.000738\n",
      "359) 281                            0.000738\n",
      "360) 123                            0.000737\n",
      "361) 345                            0.000735\n",
      "362) 185                            0.000733\n",
      "363) 74                             0.000733\n",
      "364) 133                            0.000731\n",
      "365) 145                            0.000730\n",
      "366) 383                            0.000726\n",
      "367) 339                            0.000726\n",
      "368) 310                            0.000722\n",
      "369) 486                            0.000721\n",
      "370) 164                            0.000717\n",
      "371) 454                            0.000714\n",
      "372) 173                            0.000711\n",
      "373) 75                             0.000708\n",
      "374) 317                            0.000706\n",
      "375) 141                            0.000705\n",
      "376) 427                            0.000704\n",
      "377) 363                            0.000703\n",
      "378) 278                            0.000702\n",
      "379) 69                             0.000702\n",
      "380) 263                            0.000701\n",
      "381) 229                            0.000701\n",
      "382) 54                             0.000698\n",
      "383) 210                            0.000698\n",
      "384) 441                            0.000693\n",
      "385) 241                            0.000691\n",
      "386) 243                            0.000689\n",
      "387) 478                            0.000686\n",
      "388) 473                            0.000683\n",
      "389) 204                            0.000682\n",
      "390) 371                            0.000681\n",
      "391) 187                            0.000679\n",
      "392) 257                            0.000676\n",
      "393) 225                            0.000674\n",
      "394) 296                            0.000672\n",
      "395) 350                            0.000671\n",
      "396) 156                            0.000670\n",
      "397) 95                             0.000670\n",
      "398) 177                            0.000670\n",
      "399) 82                             0.000669\n",
      "400) 336                            0.000666\n",
      "401) 429                            0.000665\n",
      "402) 307                            0.000665\n",
      "403) 346                            0.000663\n",
      "404) 233                            0.000663\n",
      "405) 140                            0.000662\n",
      "406) 403                            0.000660\n",
      "407) 456                            0.000659\n",
      "408) 188                            0.000658\n",
      "409) 127                            0.000657\n",
      "410) 405                            0.000656\n",
      "411) 152                            0.000654\n",
      "412) 466                            0.000652\n",
      "413) 138                            0.000648\n",
      "414) 373                            0.000648\n",
      "415) 224                            0.000647\n",
      "416) 408                            0.000643\n",
      "417) 232                            0.000639\n",
      "418) 137                            0.000637\n",
      "419) 326                            0.000635\n",
      "420) 143                            0.000632\n",
      "421) 292                            0.000631\n",
      "422) 277                            0.000629\n",
      "423) 136                            0.000627\n",
      "424) 85                             0.000624\n",
      "425) 88                             0.000624\n",
      "426) 414                            0.000623\n",
      "427) 364                            0.000622\n",
      "428) 365                            0.000620\n",
      "429) 226                            0.000619\n",
      "430) 360                            0.000617\n",
      "431) 300                            0.000616\n",
      "432) 118                            0.000612\n",
      "433) 206                            0.000612\n",
      "434) 302                            0.000612\n",
      "435) 368                            0.000607\n",
      "436) 432                            0.000604\n",
      "437) 149                            0.000603\n",
      "438) 329                            0.000594\n",
      "439) 297                            0.000593\n",
      "440) 348                            0.000593\n",
      "441) 392                            0.000592\n",
      "442) 377                            0.000592\n",
      "443) 415                            0.000590\n",
      "444) 139                            0.000589\n",
      "445) 190                            0.000588\n",
      "446) 201                            0.000586\n",
      "447) 498                            0.000586\n",
      "448) 191                            0.000584\n",
      "449) 340                            0.000582\n",
      "450) 197                            0.000580\n",
      "451) 247                            0.000580\n",
      "452) 333                            0.000580\n",
      "453) 347                            0.000577\n",
      "454) 260                            0.000577\n",
      "455) 59                             0.000576\n",
      "456) 130                            0.000573\n",
      "457) 196                            0.000571\n",
      "458) 357                            0.000567\n",
      "459) 245                            0.000565\n",
      "460) 433                            0.000563\n",
      "461) 275                            0.000561\n",
      "462) 412                            0.000561\n",
      "463) 255                            0.000561\n",
      "464) 97                             0.000559\n",
      "465) 442                            0.000554\n",
      "466) 372                            0.000553\n",
      "467) 378                            0.000551\n",
      "468) 250                            0.000550\n",
      "469) 64                             0.000550\n",
      "470) 109                            0.000548\n",
      "471) 393                            0.000548\n",
      "472) 213                            0.000547\n",
      "473) 440                            0.000539\n",
      "474) 343                            0.000538\n",
      "475) 395                            0.000537\n",
      "476) 305                            0.000536\n",
      "477) 342                            0.000533\n",
      "478) 324                            0.000531\n",
      "479) 397                            0.000526\n",
      "480) 214                            0.000522\n",
      "481) 205                            0.000521\n",
      "482) 379                            0.000520\n",
      "483) 391                            0.000517\n",
      "484) 65                             0.000515\n",
      "485) 389                            0.000515\n",
      "486) 384                            0.000515\n",
      "487) 163                            0.000507\n",
      "488) 304                            0.000497\n",
      "489) 366                            0.000495\n",
      "490) 424                            0.000494\n",
      "491) 193                            0.000486\n",
      "492) 207                            0.000483\n",
      "493) 358                            0.000476\n",
      "494) 169                            0.000476\n",
      "495) 425                            0.000473\n",
      "496) 239                            0.000469\n",
      "497) 334                            0.000453\n",
      "498) 157                            0.000446\n",
      "499) 380                            0.000433\n",
      "500) 400                            0.000413\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 500 is out of bounds for axis 0 with size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-665614754bd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     print(\"%2d) %-*s %f\" % (f + 1, 30, \n\u001b[1;32m----> 6\u001b[1;33m                             \u001b[0mfeat_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                             importances[indices[f]]))\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 500 is out of bounds for axis 0 with size 500"
     ]
    }
   ],
   "source": [
    "feat_labels = range(X_train_pca.shape[1])\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train_pca.shape[1]), \n",
    "        importances[indices],\n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train_pca.shape[1]), \n",
    "           feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train_pca.shape[1]])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/04_09.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning multiple linear regression with polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T15:08:08.617648Z",
     "start_time": "2021-05-03T15:08:00.706902Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T15:38:44.751225Z",
     "start_time": "2021-05-03T15:38:43.577557Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"sigmoid\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"sigmoid\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation curve vs learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make it pipeline and apply to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
