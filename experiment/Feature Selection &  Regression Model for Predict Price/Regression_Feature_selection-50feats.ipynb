{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the copy based on copy1, to conduct PCA before regression.** <br>\n",
    "Due to large dimension and computing capacity, must reduce dimension before doing regression.<br>\n",
    "Last version, failed to run RFE for feature selection. RFE is better when choosing a few features from a relatively small feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:13.655776Z",
     "start_time": "2021-05-10T22:55:13.649792Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\lzowe\\OneDrive - The City College of New York\\CCNY_Course\\Applied_Machine_Learning_and_Data_Mining\\codes\\project-product-price-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:15.442980Z",
     "start_time": "2021-05-10T22:55:13.982090Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from final.feature_extraction.vectorization import text_vectorizaion\n",
    "from final.dimension_reduction.feature_reduction import dimension_reduction\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.rcParams['figure.constrained_layout.use'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data processed using Tokenizing and tf-idf algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:25.896724Z",
     "start_time": "2021-05-10T22:55:18.343105Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/DSEI21000-S21/project-product-price-prediction/main/data/random_samples/stratified_sampling_clean_text_data_by_price_whigh_sz50000_1619835594.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:25.960604Z",
     "start_time": "2021-05-10T22:55:25.947595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 34)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:26.114192Z",
     "start_time": "2021-05-10T22:55:26.007430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_upper_char_count</th>\n",
       "      <th>item_name_stopword_count</th>\n",
       "      <th>item_name_punctuation_count</th>\n",
       "      <th>item_name_number_count</th>\n",
       "      <th>item_name_after_word_count</th>\n",
       "      <th>item_name_after_char_count</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.373508e+05</td>\n",
       "      <td>26.583180</td>\n",
       "      <td>150.390920</td>\n",
       "      <td>5.667798</td>\n",
       "      <td>1.876040</td>\n",
       "      <td>12.577260</td>\n",
       "      <td>7.67970</td>\n",
       "      <td>5.850200</td>\n",
       "      <td>0.499880</td>\n",
       "      <td>18.323300</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794540</td>\n",
       "      <td>0.192960</td>\n",
       "      <td>0.414340</td>\n",
       "      <td>0.177680</td>\n",
       "      <td>4.236300</td>\n",
       "      <td>24.381740</td>\n",
       "      <td>5.845573</td>\n",
       "      <td>1.991820</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>108.41749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.251891e+05</td>\n",
       "      <td>28.205148</td>\n",
       "      <td>161.300927</td>\n",
       "      <td>0.782677</td>\n",
       "      <td>5.826971</td>\n",
       "      <td>28.114883</td>\n",
       "      <td>10.36772</td>\n",
       "      <td>8.336725</td>\n",
       "      <td>1.229061</td>\n",
       "      <td>18.691275</td>\n",
       "      <td>...</td>\n",
       "      <td>5.226287</td>\n",
       "      <td>0.463088</td>\n",
       "      <td>0.828128</td>\n",
       "      <td>0.422508</td>\n",
       "      <td>1.535705</td>\n",
       "      <td>8.740065</td>\n",
       "      <td>1.210724</td>\n",
       "      <td>0.896911</td>\n",
       "      <td>0.484564</td>\n",
       "      <td>198.75487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.726685e+05</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>5.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.353620e+05</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>5.642857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.102881e+06</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>6.020944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482519e+06</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>761.000000</td>\n",
       "      <td>104.00000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_id  item_description_bef_word_count  \\\n",
       "count  5.000000e+04                     50000.000000   \n",
       "mean   7.373508e+05                        26.583180   \n",
       "std    4.251891e+05                        28.205148   \n",
       "min    1.900000e+01                         1.000000   \n",
       "25%    3.726685e+05                         8.000000   \n",
       "50%    7.353620e+05                        17.000000   \n",
       "75%    1.102881e+06                        34.000000   \n",
       "max    1.482519e+06                       206.000000   \n",
       "\n",
       "       item_description_bef_char_count  item_description_bef_avg_word_len  \\\n",
       "count                     50000.000000                       50000.000000   \n",
       "mean                        150.390920                           5.667798   \n",
       "std                         161.300927                           0.782677   \n",
       "min                           1.000000                           1.000000   \n",
       "25%                          46.000000                           5.210526   \n",
       "50%                          97.000000                           5.642857   \n",
       "75%                         191.000000                           6.020944   \n",
       "max                        1007.000000                          19.600000   \n",
       "\n",
       "       item_description_upper_word_count  item_description_upper_char_count  \\\n",
       "count                       50000.000000                       50000.000000   \n",
       "mean                            1.876040                          12.577260   \n",
       "std                             5.826971                          28.114883   \n",
       "min                             0.000000                           0.000000   \n",
       "25%                             0.000000                           2.000000   \n",
       "50%                             0.000000                           5.000000   \n",
       "75%                             1.000000                          12.000000   \n",
       "max                           178.000000                         761.000000   \n",
       "\n",
       "       item_description_stopword_count  item_description_punctuation_count  \\\n",
       "count                      50000.00000                        50000.000000   \n",
       "mean                           7.67970                            5.850200   \n",
       "std                           10.36772                            8.336725   \n",
       "min                            0.00000                            0.000000   \n",
       "25%                            1.00000                            1.000000   \n",
       "50%                            4.00000                            3.000000   \n",
       "75%                           10.00000                            8.000000   \n",
       "max                          104.00000                          308.000000   \n",
       "\n",
       "       item_description_number_count  item_description_after_word_count  ...  \\\n",
       "count                   50000.000000                       50000.000000  ...   \n",
       "mean                        0.499880                          18.323300  ...   \n",
       "std                         1.229061                          18.691275  ...   \n",
       "min                         0.000000                           1.000000  ...   \n",
       "25%                         0.000000                           7.000000  ...   \n",
       "50%                         0.000000                          12.000000  ...   \n",
       "75%                         1.000000                          23.000000  ...   \n",
       "max                        57.000000                         175.000000  ...   \n",
       "\n",
       "       item_name_upper_char_count  item_name_stopword_count  \\\n",
       "count                50000.000000              50000.000000   \n",
       "mean                     4.794540                  0.192960   \n",
       "std                      5.226287                  0.463088   \n",
       "min                      0.000000                  0.000000   \n",
       "25%                      2.000000                  0.000000   \n",
       "50%                      3.000000                  0.000000   \n",
       "75%                      6.000000                  0.000000   \n",
       "max                     37.000000                  6.000000   \n",
       "\n",
       "       item_name_punctuation_count  item_name_number_count  \\\n",
       "count                 50000.000000            50000.000000   \n",
       "mean                      0.414340                0.177680   \n",
       "std                       0.828128                0.422508   \n",
       "min                       0.000000                0.000000   \n",
       "25%                       0.000000                0.000000   \n",
       "50%                       0.000000                0.000000   \n",
       "75%                       1.000000                0.000000   \n",
       "max                      12.000000                9.000000   \n",
       "\n",
       "       item_name_after_word_count  item_name_after_char_count  \\\n",
       "count                50000.000000                50000.000000   \n",
       "mean                     4.236300                   24.381740   \n",
       "std                      1.535705                    8.740065   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      3.000000                   18.000000   \n",
       "50%                      4.000000                   25.000000   \n",
       "75%                      5.000000                   32.000000   \n",
       "max                     13.000000                   42.000000   \n",
       "\n",
       "       item_name_after_avg_word_len  item_condition_id      shipping  \\\n",
       "count                  50000.000000       50000.000000  50000.000000   \n",
       "mean                       5.845573           1.991820      0.376700   \n",
       "std                        1.210724           0.896911      0.484564   \n",
       "min                        1.000000           1.000000      0.000000   \n",
       "25%                        5.000000           1.000000      0.000000   \n",
       "50%                        5.750000           2.000000      0.000000   \n",
       "75%                        6.500000           3.000000      1.000000   \n",
       "max                       26.000000           5.000000      1.000000   \n",
       "\n",
       "             price  \n",
       "count  50000.00000  \n",
       "mean     108.41749  \n",
       "std      198.75487  \n",
       "min        3.00000  \n",
       "25%       20.00000  \n",
       "50%       50.00000  \n",
       "75%       90.00000  \n",
       "max     2009.00000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:26.208962Z",
     "start_time": "2021-05-10T22:55:26.165009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 34 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   train_id                             50000 non-null  int64  \n",
      " 1   clean_item_description               50000 non-null  object \n",
      " 2   item_description_bef_word_count      50000 non-null  float64\n",
      " 3   item_description_bef_char_count      50000 non-null  float64\n",
      " 4   item_description_bef_avg_word_len    50000 non-null  float64\n",
      " 5   item_description_upper_word_count    50000 non-null  float64\n",
      " 6   item_description_upper_char_count    50000 non-null  float64\n",
      " 7   item_description_stopword_count      50000 non-null  float64\n",
      " 8   item_description_punctuation_count   50000 non-null  float64\n",
      " 9   item_description_number_count        50000 non-null  float64\n",
      " 10  item_description_after_word_count    50000 non-null  float64\n",
      " 11  item_description_after_char_count    50000 non-null  float64\n",
      " 12  item_description_after_avg_word_len  50000 non-null  float64\n",
      " 13  clean_item_name                      50000 non-null  object \n",
      " 14  item_name_bef_word_count             50000 non-null  float64\n",
      " 15  item_name_bef_char_count             50000 non-null  float64\n",
      " 16  item_name_bef_avg_word_len           50000 non-null  float64\n",
      " 17  item_name_upper_word_count           50000 non-null  float64\n",
      " 18  item_name_upper_char_count           50000 non-null  float64\n",
      " 19  item_name_stopword_count             50000 non-null  float64\n",
      " 20  item_name_punctuation_count          50000 non-null  float64\n",
      " 21  item_name_number_count               50000 non-null  float64\n",
      " 22  item_name_after_word_count           50000 non-null  float64\n",
      " 23  item_name_after_char_count           50000 non-null  float64\n",
      " 24  item_name_after_avg_word_len         50000 non-null  float64\n",
      " 25  item_condition_id                    50000 non-null  int64  \n",
      " 26  category_name                        50000 non-null  object \n",
      " 27  brand_name                           50000 non-null  object \n",
      " 28  shipping                             50000 non-null  int64  \n",
      " 29  price                                50000 non-null  float64\n",
      " 30  c1                                   50000 non-null  object \n",
      " 31  c2                                   50000 non-null  object \n",
      " 32  c3                                   50000 non-null  object \n",
      " 33  price_bin                            50000 non-null  object \n",
      "dtypes: float64(23), int64(3), object(8)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:26.271760Z",
     "start_time": "2021-05-10T22:55:26.257761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42039,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean_item_name.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:26.333561Z",
     "start_time": "2021-05-10T22:55:26.306633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>clean_item_description</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>new tags</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Athletic Apparel/Shirts &amp; Tops</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>women</td>\n",
       "      <td>athletic apparel</td>\n",
       "      <td>shirts &amp; tops</td>\n",
       "      <td>(10, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>nastasya every hills lipstick fashion</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Lips</td>\n",
       "      <td>Anastasia Beverly Hills</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>beauty</td>\n",
       "      <td>makeup</td>\n",
       "      <td>lips</td>\n",
       "      <td>(20, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>brand new tags taken bag pictures</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jeans/Leggings</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>women</td>\n",
       "      <td>jeans</td>\n",
       "      <td>leggings</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>bought calves bit large frowned good condition...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>boots</td>\n",
       "      <td>(80, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>brand new box size 7youth859womens</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>athletic</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                             clean_item_description  \\\n",
       "0    806824                                           new tags   \n",
       "1    772820              nastasya every hills lipstick fashion   \n",
       "2   1423115                  brand new tags taken bag pictures   \n",
       "3    405853  bought calves bit large frowned good condition...   \n",
       "4   1172086                 brand new box size 7youth859womens   \n",
       "\n",
       "   item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0                              3.0                             13.0   \n",
       "1                              6.0                             42.0   \n",
       "2                             11.0                             54.0   \n",
       "3                             35.0                            188.0   \n",
       "4                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  ...  \\\n",
       "0                                 0.0                            0.0  ...   \n",
       "1                                 0.0                            0.0  ...   \n",
       "2                                 0.0                            0.0  ...   \n",
       "3                                 7.0                            1.0  ...   \n",
       "4                                 3.0                            0.0  ...   \n",
       "\n",
       "   item_name_after_avg_word_len  item_condition_id  \\\n",
       "0                      5.250000                  1   \n",
       "1                     10.000000                  1   \n",
       "2                      6.166667                  1   \n",
       "3                      5.333333                  3   \n",
       "4                      4.000000                  1   \n",
       "\n",
       "                          category_name               brand_name  shipping  \\\n",
       "0  Women/Athletic Apparel/Shirts & Tops                     Nike         1   \n",
       "1                    Beauty/Makeup/Lips  Anastasia Beverly Hills         0   \n",
       "2                  Women/Jeans/Leggings                  LuLaRoe         0   \n",
       "3                     Women/Shoes/Boots                   Hunter         0   \n",
       "4                  Women/Shoes/Athletic                     Nike         0   \n",
       "\n",
       "   price      c1                c2             c3  price_bin  \n",
       "0   15.0   women  athletic apparel  shirts & tops   (10, 15]  \n",
       "1   22.0  beauty            makeup           lips   (20, 25]  \n",
       "2   54.0   women             jeans       leggings   (50, 60]  \n",
       "3   84.0   women             shoes          boots   (80, 90]  \n",
       "4   56.0   women             shoes       athletic   (50, 60]  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Feature extraction and dimension selection\n",
    " \n",
    " For Item-discription feature: <br>\n",
    " using Jin's function to, firstly, do feature-extraction, increasing up to 14230 new few features <br>\n",
    " secondly, do dimenstion-reduction <br>\n",
    " finally, left 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:26.395393Z",
     "start_time": "2021-05-10T22:55:26.383454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corners bottom great shape lips smells markings inside cleanthere small water mark indicated third photo comes dusting'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean_item_description[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:28.438872Z",
     "start_time": "2021-05-10T22:55:26.459222Z"
    }
   },
   "outputs": [],
   "source": [
    "description_feature,  description_feature_name = text_vectorizaion(df, text_col = \"clean_item_description\", \n",
    "                                                                   tfidf = True, min_df=10, max_features=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:28.628255Z",
     "start_time": "2021-05-10T22:55:28.617327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 14230)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:11.265703Z",
     "start_time": "2021-05-10T23:13:33.374083Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dimension_reduction(description_feature.toarray(), method = 'SVD', n_comp = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:11.846208Z",
     "start_time": "2021-05-10T23:14:11.817233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:11.969822Z",
     "start_time": "2021-05-10T23:14:11.923945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.316579</td>\n",
       "      <td>0.226464</td>\n",
       "      <td>-0.093895</td>\n",
       "      <td>-0.145724</td>\n",
       "      <td>-0.160602</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>-0.018079</td>\n",
       "      <td>0.090897</td>\n",
       "      <td>0.191936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>-0.001485</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.003074</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>-0.002302</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004530</td>\n",
       "      <td>-0.028973</td>\n",
       "      <td>-0.005179</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>-0.009895</td>\n",
       "      <td>-0.007188</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>-0.015531</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>-0.014289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.282559</td>\n",
       "      <td>0.198734</td>\n",
       "      <td>-0.108191</td>\n",
       "      <td>-0.022313</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>-0.093215</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>-0.023777</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015969</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>-0.018547</td>\n",
       "      <td>-0.024160</td>\n",
       "      <td>-0.009791</td>\n",
       "      <td>-0.001747</td>\n",
       "      <td>-0.040102</td>\n",
       "      <td>-0.014540</td>\n",
       "      <td>-0.014426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.087350</td>\n",
       "      <td>-0.138583</td>\n",
       "      <td>-0.028884</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>-0.041196</td>\n",
       "      <td>-0.030511</td>\n",
       "      <td>0.157942</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.034407</td>\n",
       "      <td>-0.004016</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>-0.017683</td>\n",
       "      <td>0.013241</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.037753</td>\n",
       "      <td>0.027355</td>\n",
       "      <td>0.001946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.407447</td>\n",
       "      <td>0.230953</td>\n",
       "      <td>-0.090664</td>\n",
       "      <td>-0.028016</td>\n",
       "      <td>-0.120191</td>\n",
       "      <td>-0.079091</td>\n",
       "      <td>0.052895</td>\n",
       "      <td>-0.152945</td>\n",
       "      <td>-0.178799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017753</td>\n",
       "      <td>-0.004733</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>-0.006419</td>\n",
       "      <td>-0.024270</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.011555</td>\n",
       "      <td>-0.009351</td>\n",
       "      <td>0.008839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000323  0.316579  0.226464 -0.093895 -0.145724 -0.160602 -0.003326   \n",
       "1  0.000036  0.006363 -0.001485 -0.000307 -0.003074  0.008711  0.000234   \n",
       "2  0.000307  0.282559  0.198734 -0.108191 -0.022313 -0.049015 -0.093215   \n",
       "3  0.000196  0.087350 -0.138583 -0.028884 -0.007236 -0.041196 -0.030511   \n",
       "4  0.000409  0.407447  0.230953 -0.090664 -0.028016 -0.120191 -0.079091   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0 -0.018079  0.090897  0.191936  ...  0.001181 -0.000930  0.002708 -0.008270   \n",
       "1 -0.001263 -0.002302  0.001763  ... -0.004530 -0.028973 -0.005179  0.011471   \n",
       "2  0.013357 -0.023777  0.027220  ... -0.015969  0.005385  0.000088 -0.018547   \n",
       "3  0.157942  0.007499  0.001800  ...  0.011864  0.034407 -0.004016  0.005074   \n",
       "4  0.052895 -0.152945 -0.178799  ... -0.017753 -0.004733  0.017481 -0.006419   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.001943  0.007046  0.001599  0.009947  0.004283  0.001286  \n",
       "1 -0.009895 -0.007188 -0.006494 -0.015531  0.010362 -0.014289  \n",
       "2 -0.024160 -0.009791 -0.001747 -0.040102 -0.014540 -0.014426  \n",
       "3 -0.017683  0.013241  0.002016  0.037753  0.027355  0.001946  \n",
       "4 -0.024270  0.015141  0.005037  0.011555 -0.009351  0.008839  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cid = pd.DataFrame(data.copy()) #df for cleaned item description transforming to new features\n",
    "df_cid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating new features df_cid and previous df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:12.129397Z",
     "start_time": "2021-05-10T23:14:12.050607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Athletic Apparel/Shirts &amp; Tops</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>women</td>\n",
       "      <td>athletic apparel</td>\n",
       "      <td>shirts &amp; tops</td>\n",
       "      <td>(10, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Lips</td>\n",
       "      <td>Anastasia Beverly Hills</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>beauty</td>\n",
       "      <td>makeup</td>\n",
       "      <td>lips</td>\n",
       "      <td>(20, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jeans/Leggings</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>women</td>\n",
       "      <td>jeans</td>\n",
       "      <td>leggings</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>boots</td>\n",
       "      <td>(80, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>athletic</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0    806824                              3.0                             13.0   \n",
       "1    772820                              6.0                             42.0   \n",
       "2   1423115                             11.0                             54.0   \n",
       "3    405853                             35.0                            188.0   \n",
       "4   1172086                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  \\\n",
       "0                                 0.0                            0.0   \n",
       "1                                 0.0                            0.0   \n",
       "2                                 0.0                            0.0   \n",
       "3                                 7.0                            1.0   \n",
       "4                                 3.0                            0.0   \n",
       "\n",
       "   item_description_after_word_count  ...  item_name_after_avg_word_len  \\\n",
       "0                                2.0  ...                      5.250000   \n",
       "1                                5.0  ...                     10.000000   \n",
       "2                                6.0  ...                      6.166667   \n",
       "3                               17.0  ...                      5.333333   \n",
       "4                                5.0  ...                      4.000000   \n",
       "\n",
       "   item_condition_id                         category_name  \\\n",
       "0                  1  Women/Athletic Apparel/Shirts & Tops   \n",
       "1                  1                    Beauty/Makeup/Lips   \n",
       "2                  1                  Women/Jeans/Leggings   \n",
       "3                  3                     Women/Shoes/Boots   \n",
       "4                  1                  Women/Shoes/Athletic   \n",
       "\n",
       "                brand_name  shipping  price      c1                c2  \\\n",
       "0                     Nike         1   15.0   women  athletic apparel   \n",
       "1  Anastasia Beverly Hills         0   22.0  beauty            makeup   \n",
       "2                  LuLaRoe         0   54.0   women             jeans   \n",
       "3                   Hunter         0   84.0   women             shoes   \n",
       "4                     Nike         0   56.0   women             shoes   \n",
       "\n",
       "              c3  price_bin  \n",
       "0  shirts & tops   (10, 15]  \n",
       "1           lips   (20, 25]  \n",
       "2       leggings   (50, 60]  \n",
       "3          boots   (80, 90]  \n",
       "4       athletic   (50, 60]  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.copy()\n",
    "df1.drop(\"clean_item_description\", inplace=True,axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:12.287015Z",
     "start_time": "2021-05-10T23:14:12.242094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 33 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   train_id                             50000 non-null  int64  \n",
      " 1   item_description_bef_word_count      50000 non-null  float64\n",
      " 2   item_description_bef_char_count      50000 non-null  float64\n",
      " 3   item_description_bef_avg_word_len    50000 non-null  float64\n",
      " 4   item_description_upper_word_count    50000 non-null  float64\n",
      " 5   item_description_upper_char_count    50000 non-null  float64\n",
      " 6   item_description_stopword_count      50000 non-null  float64\n",
      " 7   item_description_punctuation_count   50000 non-null  float64\n",
      " 8   item_description_number_count        50000 non-null  float64\n",
      " 9   item_description_after_word_count    50000 non-null  float64\n",
      " 10  item_description_after_char_count    50000 non-null  float64\n",
      " 11  item_description_after_avg_word_len  50000 non-null  float64\n",
      " 12  clean_item_name                      50000 non-null  object \n",
      " 13  item_name_bef_word_count             50000 non-null  float64\n",
      " 14  item_name_bef_char_count             50000 non-null  float64\n",
      " 15  item_name_bef_avg_word_len           50000 non-null  float64\n",
      " 16  item_name_upper_word_count           50000 non-null  float64\n",
      " 17  item_name_upper_char_count           50000 non-null  float64\n",
      " 18  item_name_stopword_count             50000 non-null  float64\n",
      " 19  item_name_punctuation_count          50000 non-null  float64\n",
      " 20  item_name_number_count               50000 non-null  float64\n",
      " 21  item_name_after_word_count           50000 non-null  float64\n",
      " 22  item_name_after_char_count           50000 non-null  float64\n",
      " 23  item_name_after_avg_word_len         50000 non-null  float64\n",
      " 24  item_condition_id                    50000 non-null  int64  \n",
      " 25  category_name                        50000 non-null  object \n",
      " 26  brand_name                           50000 non-null  object \n",
      " 27  shipping                             50000 non-null  int64  \n",
      " 28  price                                50000 non-null  float64\n",
      " 29  c1                                   50000 non-null  object \n",
      " 30  c2                                   50000 non-null  object \n",
      " 31  c3                                   50000 non-null  object \n",
      " 32  price_bin                            50000 non-null  object \n",
      "dtypes: float64(23), int64(3), object(7)\n",
      "memory usage: 12.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:12.414632Z",
     "start_time": "2021-05-10T23:14:12.400672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 33), (50000, 100))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape,df_cid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:12.586368Z",
     "start_time": "2021-05-10T23:14:12.512396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 133)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat=pd.concat([df1,df_cid],axis=1)\n",
    "df_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using one-hot encoding for category and nominal features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete price bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:12.726731Z",
     "start_time": "2021-05-10T23:14:12.713701Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_catNnom = ['category_name','brand_name', 'c1', 'c2', 'c3'] # columns of category and nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:14.984983Z",
     "start_time": "2021-05-10T23:14:12.838952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3028)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from final.feature_encoding.one_hot_encoding import one_hot_encode_feature\n",
    "df_encode = df_concat\n",
    "for col in cols_catNnom:\n",
    "    df_encode, col_encode = one_hot_encode_feature(df_encode, encode_column=col,drop_first=False)\n",
    "df_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.091697Z",
     "start_time": "2021-05-10T23:14:14.986976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 3028 entries, train_id to c3_yoga & pilates\n",
      "dtypes: float64(123), int64(3), object(2), uint8(2900)\n",
      "memory usage: 187.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_encode.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.122613Z",
     "start_time": "2021-05-10T23:14:15.093690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>c3_window treatments</th>\n",
       "      <th>c3_wine, beer &amp; beverage coolers</th>\n",
       "      <th>c3_wipes &amp; holders</th>\n",
       "      <th>c3_women</th>\n",
       "      <th>c3_women's golf clubs</th>\n",
       "      <th>c3_wool</th>\n",
       "      <th>c3_work &amp; safety</th>\n",
       "      <th>c3_wrap</th>\n",
       "      <th>c3_writing</th>\n",
       "      <th>c3_yoga &amp; pilates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0    806824                              3.0                             13.0   \n",
       "1    772820                              6.0                             42.0   \n",
       "2   1423115                             11.0                             54.0   \n",
       "3    405853                             35.0                            188.0   \n",
       "4   1172086                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  \\\n",
       "0                                 0.0                            0.0   \n",
       "1                                 0.0                            0.0   \n",
       "2                                 0.0                            0.0   \n",
       "3                                 7.0                            1.0   \n",
       "4                                 3.0                            0.0   \n",
       "\n",
       "   item_description_after_word_count  ...  c3_window treatments  \\\n",
       "0                                2.0  ...                     0   \n",
       "1                                5.0  ...                     0   \n",
       "2                                6.0  ...                     0   \n",
       "3                               17.0  ...                     0   \n",
       "4                                5.0  ...                     0   \n",
       "\n",
       "   c3_wine, beer & beverage coolers c3_wipes & holders  c3_women  \\\n",
       "0                                 0                  0         0   \n",
       "1                                 0                  0         0   \n",
       "2                                 0                  0         0   \n",
       "3                                 0                  0         0   \n",
       "4                                 0                  0         0   \n",
       "\n",
       "   c3_women's golf clubs  c3_wool  c3_work & safety  c3_wrap  c3_writing  \\\n",
       "0                      0        0                 0        0           0   \n",
       "1                      0        0                 0        0           0   \n",
       "2                      0        0                 0        0           0   \n",
       "3                      0        0                 0        0           0   \n",
       "4                      0        0                 0        0           0   \n",
       "\n",
       "   c3_yoga & pilates  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 3028 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.138610Z",
     "start_time": "2021-05-10T23:14:15.125606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price\n",
       "0        15.0\n",
       "1        22.0\n",
       "2        54.0\n",
       "3        84.0\n",
       "4        56.0\n",
       "...       ...\n",
       "49995  1609.0\n",
       "49996   205.0\n",
       "49997    36.0\n",
       "49998    20.0\n",
       "49999    72.0\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encode[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.371160Z",
     "start_time": "2021-05-10T23:14:15.140567Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare input X, y\n",
    "X, y = df_encode.copy().drop([\"clean_item_name\",\"train_id\",\"price\",\"price_bin\"],axis=1), df_encode[[\"price\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.479881Z",
     "start_time": "2021-05-10T23:14:15.374142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 3024 entries, item_description_bef_word_count to c3_yoga & pilates\n",
      "dtypes: float64(122), int64(2), uint8(2900)\n",
      "memory usage: 185.6 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.891511Z",
     "start_time": "2021-05-10T23:14:15.483845Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct dimension reduction on the dateframe processed by one-hot encoding\n",
    "skip this step in the first place. <br>\n",
    "let us see how the regression result looks like. and then determine if the dimension reduction on whole dataset needed, or if use other techniques to avoid overfitting(e.g. adding penalty, using RobustScaler, conducting cross validation).<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 1: actually can't skip this step, the dimension is too large to run, Exception was raised: MemoryError: Unable to allocate 11.8 GiB for an array with shape (45079, 35000) and data type float64.\n",
    "Therefore, try conduct PCA again before regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 2: even can't not run PCA due to the large number of features. Try drop clean_item_name instead of encoding it, as it is has very less duplicated items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 3: Since log2 works, skip this step( e.i. 1.5) for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 4: features are too much later, have to reduce dimension at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:18.944806Z",
     "start_time": "2021-05-10T23:14:15.894439Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:22.937089Z",
     "start_time": "2021-05-10T23:14:18.946758Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00290463, 0.00227748, 0.0021392 , 0.00197141, 0.00187969,\n",
       "       0.00185723, 0.00180453, 0.00177984, 0.00174778, 0.00167633,\n",
       "       0.00161552, 0.00160401, 0.00154318, 0.00153357, 0.00145383,\n",
       "       0.00145094, 0.00143836, 0.00143613, 0.00143506, 0.00142606,\n",
       "       0.00141384, 0.00140871, 0.00140269, 0.00139759, 0.00139177,\n",
       "       0.00138739, 0.00138107, 0.00136905, 0.00136496, 0.00136107,\n",
       "       0.00135542, 0.00134973, 0.00133956, 0.00133637, 0.00132216,\n",
       "       0.00131045, 0.00130529, 0.00129102, 0.00127827, 0.00126776,\n",
       "       0.00126149, 0.00124665, 0.001242  , 0.00123949, 0.00122593,\n",
       "       0.0012158 , 0.00121305, 0.00120527, 0.00119444, 0.00117524])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50) # reduce features to 50\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:22.953047Z",
     "start_time": "2021-05-10T23:14:22.939085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 50), (15000, 50))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape, X_test_pca.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Selection\n",
    "Proposal:\n",
    "1. try different regression techniques, and select the best one;\n",
    "      - DT regressor\n",
    "      * Ensemble method\n",
    "      - Adding polynomial items to multiple linear regression? \n",
    "      - Tensorflow.Keras\n",
    "2. focus on the selected one and tuning modelling.(Guessing propably would use Ensemble learning or Keras in the end)<br>\n",
    "**Based on the our previous experiment so far, our results have both large bias and variance.** Probably need to use more powerful algorithm to improve the bias, and then considering solve overfitting issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:24.432427Z",
     "start_time": "2021-05-10T23:14:22.955042Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score,r2_score \n",
    "def evaluate_dt_regressor(X_train, X_test, y_train, y_test,n_iter,max_depth):\n",
    "    # the maximum depth of the tree. If None, then nodes are expanded until all leaves are pure\n",
    "    MSE_test=[]\n",
    "    EVS_test=[]\n",
    "    R2_test=[]\n",
    "    MSE_train=[]\n",
    "    EVS_train=[]\n",
    "    R2_train=[]\n",
    "    for i in range(n_iter):\n",
    "        rg = tree.DecisionTreeRegressor(max_depth=max_depth)\n",
    "        rg.fit(X_train, y_train)\n",
    "        y_train_pred = rg.predict(X_train)\n",
    "        y_pred = rg.predict(X_test)\n",
    "        MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "        EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "        R2_train.append(r2_score(y_train, y_train_pred))\n",
    "        \n",
    "        MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "        EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "        R2_test.append(r2_score(y_test, y_pred))\n",
    "    print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "    print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:27.799730Z",
     "start_time": "2021-05-10T23:14:24.434036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 1.4285714285714285e-05 EVS: 0.9999999996453222 R2: 0.9999999996453222\n",
      "Test score: MSE: 25453.1081 EVS: 0.32469162425114917 R2: 0.32468964011539003\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca, y_train, y_test,1,max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:31.063592Z",
     "start_time": "2021-05-10T23:14:30.502631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 27603.316402674467 EVS: 0.31468007373987195 R2: 0.31468007373987195\n",
      "Test score: MSE: 25451.206550664436 EVS: 0.3247873054026028 R2: 0.32474009116290425\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,y_train, y_test,1,max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:32.233789Z",
     "start_time": "2021-05-10T23:14:31.273341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 23710.359452021607 EVS: 0.41133226333317674 R2: 0.41133226333317674\n",
      "Test score: MSE: 22479.658016756082 EVS: 0.40358066969169526 R2: 0.4035798737923677\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,  y_train, y_test,1,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.037444Z",
     "start_time": "2021-05-10T23:14:32.434209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 1.4285714285714289e-05 EVS: 0.9999999996453222 R2: 0.9999999996453222\n",
      "Test score: MSE: 25176.334681666667 EVS: 0.3320449255957789 R2: 0.33203286735533477\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,  y_train, y_test,10,max_depth=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.321016Z",
     "start_time": "2021-05-10T23:15:05.260423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.01139248e+01,  3.33909961e+00, -1.24632424e+01,\n",
       "         2.92924271e-01, -4.78158123e+00,  1.28572231e+01,\n",
       "        -5.37623204e-01,  4.63062060e+00, -2.34387322e+01,\n",
       "        -6.38668717e+00,  1.11445240e+00, -9.80527906e+00,\n",
       "         1.93814162e+00, -5.89439692e+00,  3.45141980e+00,\n",
       "        -4.19551000e+00,  4.67771693e+00,  2.26721231e+00,\n",
       "        -2.52076644e+00,  3.12808726e-01, -3.33907395e+00,\n",
       "         3.45865149e-01, -2.20375317e-01, -1.06058981e+01,\n",
       "        -1.05208256e+01,  7.39183271e+00, -1.46368928e+00,\n",
       "        -1.93780801e+00, -2.03429896e+00,  5.88554372e+00,\n",
       "         4.62818933e+00, -6.53923613e+00, -5.64377145e+00,\n",
       "         6.17206393e+00,  8.76943599e+00,  1.76356336e+00,\n",
       "         5.56305871e+00, -1.55913194e+00,  2.25449809e+00,\n",
       "        -4.71081324e-01,  4.45548607e+00, -7.80405356e+00,\n",
       "        -6.10614015e+00, -3.82468595e+00, -8.02043049e-01,\n",
       "        -8.38901054e-01, -3.49886943e+00,  3.04608200e+00,\n",
       "         6.28226186e+00, -2.32166991e-02]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train_pca, y_train)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why linear regression is so slow. after 1 and harf hour, not completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.587377Z",
     "start_time": "2021-05-10T23:15:05.574337Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, explained_variance_score,r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.664097Z",
     "start_time": "2021-05-10T23:15:05.589298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'MSE': 28508.33052943577, 'EVS': 0.2922108817931993, 'R2': 0.2922108817931993}\n",
      "test: {'MSE': 25841.256944870216, 'EVS': 0.3144575277431273, 'R2': 0.3143914503977224}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train_pca, y_train)\n",
    "y_train_pred = reg.predict(X_train_pca)\n",
    "y_pred = reg.predict(X_test_pca)\n",
    "\n",
    "print(\"train:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_train, y_train_pred), \n",
    "    \"EVS\": explained_variance_score(y_train, y_train_pred), \n",
    "    \"R2\": r2_score(y_train, y_train_pred)\n",
    "})\n",
    "\n",
    "print(\"test:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred), \n",
    "    \"EVS\": explained_variance_score(y_test, y_pred), \n",
    "    \"R2\": r2_score(y_test, y_pred)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.725932Z",
     "start_time": "2021-05-10T23:15:05.666092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'MSE': 28508.3305295391, 'EVS': 0.2922108817906339, 'R2': 0.2922108817906338}\n",
      "test: {'MSE': 25841.25771250408, 'EVS': 0.31445750733101396, 'R2': 0.31439143003120773}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha=.5) # tuning alpha does not help\n",
    "reg.fit(X_train_pca, y_train)\n",
    "y_train_pred = reg.predict(X_train_pca)\n",
    "y_pred = reg.predict(X_test_pca)\n",
    "\n",
    "print(\"train:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_train, y_train_pred), \n",
    "    \"EVS\": explained_variance_score(y_train, y_train_pred), \n",
    "    \"R2\": r2_score(y_train, y_train_pred)\n",
    "})\n",
    "\n",
    "print(\"test:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred), \n",
    "    \"EVS\": explained_variance_score(y_test, y_pred), \n",
    "    \"R2\": r2_score(y_test, y_pred)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.804721Z",
     "start_time": "2021-05-10T23:15:05.728924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'MSE': 28516.26978674493, 'EVS': 0.2920137702883967, 'R2': 0.2920137702883967}\n",
      "test: {'MSE': 25860.14695920318, 'EVS': 0.313954114991316, 'R2': 0.31389026907529616}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso(alpha=0.8) # tuning alpha does not help\n",
    "reg.fit(X_train_pca, y_train)\n",
    "y_train_pred = reg.predict(X_train_pca)\n",
    "y_pred = reg.predict(X_test_pca)\n",
    "\n",
    "print(\"train:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_train, y_train_pred), \n",
    "    \"EVS\": explained_variance_score(y_train, y_train_pred), \n",
    "    \"R2\": r2_score(y_train, y_train_pred)\n",
    "})\n",
    "\n",
    "print(\"test:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred), \n",
    "    \"EVS\": explained_variance_score(y_test, y_pred), \n",
    "    \"R2\": r2_score(y_test, y_pred)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Bagging) for classification, also for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.865558Z",
     "start_time": "2021-05-10T23:15:05.806715Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def evaluate_rf_regressor(X_train, X_test, y_train, y_test,n_iter,max_depth,random_state):\n",
    "    MSE_test=[]\n",
    "    EVS_test=[]\n",
    "    R2_test=[]\n",
    "    MSE_train=[]\n",
    "    EVS_train=[]\n",
    "    R2_train=[]\n",
    "    for i in range(n_iter):\n",
    "        rg = RandomForestRegressor(max_depth=max_depth, random_state=random_state)\n",
    "        rg.fit(X_train, y_train)\n",
    "        y_train_pred = rg.predict(X_train)\n",
    "        y_pred = rg.predict(X_test)\n",
    "        MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "        EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "        R2_train.append(r2_score(y_train, y_train_pred))\n",
    "        \n",
    "        MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "        EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "        R2_test.append(r2_score(y_test, y_pred))\n",
    "    print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "    print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_regressor turns out very very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:18:22.715535Z",
     "start_time": "2021-05-10T23:15:05.867553Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-ffee7f25d399>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rg.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 977.6322390524449 EVS: 0.9762643748608849 R2: 0.9757278855843557\n",
      "Test score: MSE: 10828.01092624251 EVS: 0.7128459008502149 R2: 0.7127161081190192\n"
     ]
    }
   ],
   "source": [
    "evaluate_rf_regressor(X_train_pca, X_test_pca, y_train, y_test,1,max_depth=None,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:18:53.271110Z",
     "start_time": "2021-05-10T23:18:22.717528Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-558030b727bd>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rg.fit(X_train_pca, y_train)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-558030b727bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mMSE_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    387\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \"\"\"\n\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rg = RandomForestRegressor(max_depth=None, random_state=42)\n",
    "rg.fit(X_train_pca, y_train)\n",
    "y_train_pred = rg.predict(X_train_pca)\n",
    "y_pred = rg.predict(X_test_pca)\n",
    "MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "R2_train.append(r2_score(y_train, y_train_pred))\n",
    "\n",
    "MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "R2_test.append(r2_score(y_test, y_pred))\n",
    "print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:09:48.005739Z",
     "start_time": "2021-05-04T13:09:47.465304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rg.feature_importances_\n",
    "importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:09:49.846589Z",
     "start_time": "2021-05-04T13:09:49.835306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3024)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:14:07.663612Z",
     "start_time": "2021-05-04T13:14:07.573550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 7                              0.105877\n",
      " 2) 24                             0.063736\n",
      " 3) 33                             0.055135\n",
      " 4) 288                            0.033101\n",
      " 5) 1                              0.030501\n",
      " 6) 10                             0.025732\n",
      " 7) 316                            0.017765\n",
      " 8) 89                             0.014740\n",
      " 9) 48                             0.012854\n",
      "10) 469                            0.012297\n",
      "11) 11                             0.010544\n",
      "12) 262                            0.009389\n",
      "13) 2                              0.008283\n",
      "14) 0                              0.007948\n",
      "15) 14                             0.007850\n",
      "16) 491                            0.007349\n",
      "17) 57                             0.006804\n",
      "18) 6                              0.006769\n",
      "19) 34                             0.006605\n",
      "20) 46                             0.006498\n",
      "21) 261                            0.005871\n",
      "22) 476                            0.005158\n",
      "23) 483                            0.004931\n",
      "24) 192                            0.004860\n",
      "25) 252                            0.004593\n",
      "26) 8                              0.004519\n",
      "27) 285                            0.004433\n",
      "28) 273                            0.004364\n",
      "29) 216                            0.004305\n",
      "30) 467                            0.004116\n",
      "31) 116                            0.003915\n",
      "32) 27                             0.003776\n",
      "33) 323                            0.003739\n",
      "34) 175                            0.003534\n",
      "35) 242                            0.003235\n",
      "36) 299                            0.003226\n",
      "37) 399                            0.003218\n",
      "38) 32                             0.003109\n",
      "39) 470                            0.002954\n",
      "40) 25                             0.002944\n",
      "41) 70                             0.002937\n",
      "42) 167                            0.002923\n",
      "43) 455                            0.002843\n",
      "44) 5                              0.002751\n",
      "45) 235                            0.002579\n",
      "46) 477                            0.002554\n",
      "47) 3                              0.002538\n",
      "48) 20                             0.002510\n",
      "49) 39                             0.002465\n",
      "50) 208                            0.002452\n",
      "51) 493                            0.002441\n",
      "52) 269                            0.002374\n",
      "53) 80                             0.002358\n",
      "54) 170                            0.002353\n",
      "55) 321                            0.002326\n",
      "56) 120                            0.002315\n",
      "57) 174                            0.002315\n",
      "58) 484                            0.002294\n",
      "59) 318                            0.002258\n",
      "60) 472                            0.002208\n",
      "61) 26                             0.002193\n",
      "62) 125                            0.002192\n",
      "63) 495                            0.002172\n",
      "64) 274                            0.002160\n",
      "65) 103                            0.002083\n",
      "66) 38                             0.002052\n",
      "67) 222                            0.002014\n",
      "68) 437                            0.001982\n",
      "69) 129                            0.001977\n",
      "70) 15                             0.001932\n",
      "71) 489                            0.001922\n",
      "72) 180                            0.001899\n",
      "73) 390                            0.001878\n",
      "74) 259                            0.001860\n",
      "75) 209                            0.001827\n",
      "76) 91                             0.001807\n",
      "77) 99                             0.001794\n",
      "78) 84                             0.001762\n",
      "79) 479                            0.001747\n",
      "80) 492                            0.001742\n",
      "81) 376                            0.001733\n",
      "82) 12                             0.001718\n",
      "83) 402                            0.001680\n",
      "84) 189                            0.001679\n",
      "85) 355                            0.001668\n",
      "86) 218                            0.001644\n",
      "87) 104                            0.001614\n",
      "88) 71                             0.001593\n",
      "89) 113                            0.001578\n",
      "90) 450                            0.001569\n",
      "91) 409                            0.001556\n",
      "92) 223                            0.001526\n",
      "93) 72                             0.001523\n",
      "94) 298                            0.001514\n",
      "95) 217                            0.001507\n",
      "96) 327                            0.001496\n",
      "97) 154                            0.001495\n",
      "98) 244                            0.001493\n",
      "99) 40                             0.001477\n",
      "100) 162                            0.001472\n",
      "101) 443                            0.001471\n",
      "102) 254                            0.001451\n",
      "103) 258                            0.001448\n",
      "104) 58                             0.001448\n",
      "105) 419                            0.001445\n",
      "106) 311                            0.001441\n",
      "107) 90                             0.001437\n",
      "108) 148                            0.001434\n",
      "109) 291                            0.001429\n",
      "110) 434                            0.001424\n",
      "111) 105                            0.001421\n",
      "112) 28                             0.001421\n",
      "113) 9                              0.001420\n",
      "114) 485                            0.001408\n",
      "115) 52                             0.001407\n",
      "116) 315                            0.001406\n",
      "117) 94                             0.001392\n",
      "118) 13                             0.001392\n",
      "119) 23                             0.001391\n",
      "120) 176                            0.001376\n",
      "121) 418                            0.001368\n",
      "122) 386                            0.001367\n",
      "123) 303                            0.001366\n",
      "124) 268                            0.001365\n",
      "125) 30                             0.001357\n",
      "126) 119                            0.001347\n",
      "127) 356                            0.001347\n",
      "128) 87                             0.001345\n",
      "129) 49                             0.001341\n",
      "130) 73                             0.001339\n",
      "131) 276                            0.001336\n",
      "132) 481                            0.001335\n",
      "133) 42                             0.001318\n",
      "134) 461                            0.001309\n",
      "135) 230                            0.001309\n",
      "136) 100                            0.001309\n",
      "137) 111                            0.001304\n",
      "138) 494                            0.001299\n",
      "139) 382                            0.001298\n",
      "140) 295                            0.001288\n",
      "141) 92                             0.001279\n",
      "142) 83                             0.001278\n",
      "143) 385                            0.001275\n",
      "144) 248                            0.001273\n",
      "145) 465                            0.001262\n",
      "146) 499                            0.001251\n",
      "147) 131                            0.001248\n",
      "148) 183                            0.001246\n",
      "149) 279                            0.001242\n",
      "150) 50                             0.001236\n",
      "151) 246                            0.001232\n",
      "152) 79                             0.001230\n",
      "153) 220                            0.001230\n",
      "154) 411                            0.001228\n",
      "155) 159                            0.001227\n",
      "156) 96                             0.001226\n",
      "157) 497                            0.001223\n",
      "158) 294                            0.001212\n",
      "159) 236                            0.001210\n",
      "160) 102                            0.001204\n",
      "161) 460                            0.001184\n",
      "162) 77                             0.001182\n",
      "163) 18                             0.001176\n",
      "164) 41                             0.001174\n",
      "165) 47                             0.001172\n",
      "166) 452                            0.001158\n",
      "167) 212                            0.001147\n",
      "168) 283                            0.001138\n",
      "169) 496                            0.001135\n",
      "170) 108                            0.001127\n",
      "171) 107                            0.001126\n",
      "172) 146                            0.001125\n",
      "173) 381                            0.001123\n",
      "174) 449                            0.001115\n",
      "175) 413                            0.001109\n",
      "176) 51                             0.001106\n",
      "177) 158                            0.001103\n",
      "178) 98                             0.001100\n",
      "179) 426                            0.001099\n",
      "180) 31                             0.001098\n",
      "181) 63                             0.001096\n",
      "182) 150                            0.001091\n",
      "183) 439                            0.001089\n",
      "184) 21                             0.001088\n",
      "185) 344                            0.001086\n",
      "186) 482                            0.001083\n",
      "187) 458                            0.001081\n",
      "188) 78                             0.001080\n",
      "189) 332                            0.001070\n",
      "190) 16                             0.001064\n",
      "191) 238                            0.001063\n",
      "192) 416                            0.001059\n",
      "193) 322                            0.001058\n",
      "194) 290                            0.001055\n",
      "195) 320                            0.001054\n",
      "196) 287                            0.001052\n",
      "197) 374                            0.001044\n",
      "198) 166                            0.001040\n",
      "199) 474                            0.001031\n",
      "200) 66                             0.001031\n",
      "201) 369                            0.001027\n",
      "202) 312                            0.001026\n",
      "203) 463                            0.001023\n",
      "204) 251                            0.001019\n",
      "205) 114                            0.001019\n",
      "206) 112                            0.001017\n",
      "207) 4                              0.001013\n",
      "208) 420                            0.001012\n",
      "209) 35                             0.001010\n",
      "210) 117                            0.001004\n",
      "211) 227                            0.001004\n",
      "212) 115                            0.001001\n",
      "213) 490                            0.001000\n",
      "214) 86                             0.000999\n",
      "215) 234                            0.000995\n",
      "216) 328                            0.000995\n",
      "217) 68                             0.000992\n",
      "218) 186                            0.000990\n",
      "219) 53                             0.000989\n",
      "220) 142                            0.000986\n",
      "221) 178                            0.000986\n",
      "222) 448                            0.000985\n",
      "223) 237                            0.000982\n",
      "224) 301                            0.000982\n",
      "225) 256                            0.000979\n",
      "226) 267                            0.000969\n",
      "227) 309                            0.000968\n",
      "228) 128                            0.000967\n",
      "229) 67                             0.000964\n",
      "230) 134                            0.000962\n",
      "231) 480                            0.000959\n",
      "232) 181                            0.000957\n",
      "233) 36                             0.000957\n",
      "234) 135                            0.000954\n",
      "235) 253                            0.000953\n",
      "236) 410                            0.000951\n",
      "237) 471                            0.000945\n",
      "238) 106                            0.000945\n",
      "239) 165                            0.000942\n",
      "240) 200                            0.000942\n",
      "241) 468                            0.000942\n",
      "242) 171                            0.000941\n",
      "243) 398                            0.000941\n",
      "244) 286                            0.000940\n",
      "245) 475                            0.000940\n",
      "246) 144                            0.000939\n",
      "247) 199                            0.000938\n",
      "248) 407                            0.000936\n",
      "249) 93                             0.000934\n",
      "250) 394                            0.000934\n",
      "251) 447                            0.000930\n",
      "252) 488                            0.000929\n",
      "253) 423                            0.000928\n",
      "254) 61                             0.000924\n",
      "255) 330                            0.000923\n",
      "256) 215                            0.000921\n",
      "257) 155                            0.000920\n",
      "258) 55                             0.000913\n",
      "259) 457                            0.000909\n",
      "260) 352                            0.000909\n",
      "261) 179                            0.000906\n",
      "262) 388                            0.000905\n",
      "263) 335                            0.000904\n",
      "264) 319                            0.000899\n",
      "265) 195                            0.000898\n",
      "266) 459                            0.000897\n",
      "267) 76                             0.000894\n",
      "268) 44                             0.000891\n",
      "269) 375                            0.000890\n",
      "270) 438                            0.000890\n",
      "271) 453                            0.000887\n",
      "272) 313                            0.000886\n",
      "273) 22                             0.000885\n",
      "274) 271                            0.000883\n",
      "275) 266                            0.000882\n",
      "276) 451                            0.000881\n",
      "277) 60                             0.000881\n",
      "278) 349                            0.000881\n",
      "279) 264                            0.000880\n",
      "280) 121                            0.000877\n",
      "281) 370                            0.000876\n",
      "282) 153                            0.000876\n",
      "283) 314                            0.000868\n",
      "284) 280                            0.000867\n",
      "285) 401                            0.000867\n",
      "286) 29                             0.000866\n",
      "287) 184                            0.000860\n",
      "288) 387                            0.000860\n",
      "289) 126                            0.000859\n",
      "290) 19                             0.000853\n",
      "291) 211                            0.000852\n",
      "292) 110                            0.000852\n",
      "293) 431                            0.000851\n",
      "294) 182                            0.000847\n",
      "295) 289                            0.000843\n",
      "296) 446                            0.000841\n",
      "297) 62                             0.000837\n",
      "298) 337                            0.000835\n",
      "299) 462                            0.000835\n",
      "300) 417                            0.000833\n",
      "301) 231                            0.000831\n",
      "302) 270                            0.000827\n",
      "303) 168                            0.000826\n",
      "304) 338                            0.000826\n",
      "305) 172                            0.000825\n",
      "306) 308                            0.000823\n",
      "307) 132                            0.000821\n",
      "308) 265                            0.000818\n",
      "309) 421                            0.000817\n",
      "310) 45                             0.000817\n",
      "311) 487                            0.000815\n",
      "312) 198                            0.000809\n",
      "313) 436                            0.000808\n",
      "314) 228                            0.000807\n",
      "315) 341                            0.000806\n",
      "316) 161                            0.000805\n",
      "317) 428                            0.000802\n",
      "318) 293                            0.000802\n",
      "319) 151                            0.000801\n",
      "320) 361                            0.000799\n",
      "321) 359                            0.000798\n",
      "322) 464                            0.000794\n",
      "323) 353                            0.000791\n",
      "324) 367                            0.000791\n",
      "325) 284                            0.000790\n",
      "326) 122                            0.000789\n",
      "327) 37                             0.000788\n",
      "328) 194                            0.000787\n",
      "329) 240                            0.000783\n",
      "330) 354                            0.000778\n",
      "331) 221                            0.000776\n",
      "332) 430                            0.000776\n",
      "333) 101                            0.000776\n",
      "334) 203                            0.000775\n",
      "335) 404                            0.000772\n",
      "336) 249                            0.000772\n",
      "337) 81                             0.000769\n",
      "338) 56                             0.000765\n",
      "339) 396                            0.000765\n",
      "340) 444                            0.000763\n",
      "341) 331                            0.000760\n",
      "342) 445                            0.000760\n",
      "343) 325                            0.000757\n",
      "344) 306                            0.000756\n",
      "345) 435                            0.000755\n",
      "346) 362                            0.000754\n",
      "347) 219                            0.000753\n",
      "348) 351                            0.000753\n",
      "349) 124                            0.000750\n",
      "350) 422                            0.000748\n",
      "351) 17                             0.000748\n",
      "352) 147                            0.000746\n",
      "353) 282                            0.000746\n",
      "354) 160                            0.000746\n",
      "355) 202                            0.000745\n",
      "356) 272                            0.000744\n",
      "357) 406                            0.000740\n",
      "358) 43                             0.000738\n",
      "359) 281                            0.000738\n",
      "360) 123                            0.000737\n",
      "361) 345                            0.000735\n",
      "362) 185                            0.000733\n",
      "363) 74                             0.000733\n",
      "364) 133                            0.000731\n",
      "365) 145                            0.000730\n",
      "366) 383                            0.000726\n",
      "367) 339                            0.000726\n",
      "368) 310                            0.000722\n",
      "369) 486                            0.000721\n",
      "370) 164                            0.000717\n",
      "371) 454                            0.000714\n",
      "372) 173                            0.000711\n",
      "373) 75                             0.000708\n",
      "374) 317                            0.000706\n",
      "375) 141                            0.000705\n",
      "376) 427                            0.000704\n",
      "377) 363                            0.000703\n",
      "378) 278                            0.000702\n",
      "379) 69                             0.000702\n",
      "380) 263                            0.000701\n",
      "381) 229                            0.000701\n",
      "382) 54                             0.000698\n",
      "383) 210                            0.000698\n",
      "384) 441                            0.000693\n",
      "385) 241                            0.000691\n",
      "386) 243                            0.000689\n",
      "387) 478                            0.000686\n",
      "388) 473                            0.000683\n",
      "389) 204                            0.000682\n",
      "390) 371                            0.000681\n",
      "391) 187                            0.000679\n",
      "392) 257                            0.000676\n",
      "393) 225                            0.000674\n",
      "394) 296                            0.000672\n",
      "395) 350                            0.000671\n",
      "396) 156                            0.000670\n",
      "397) 95                             0.000670\n",
      "398) 177                            0.000670\n",
      "399) 82                             0.000669\n",
      "400) 336                            0.000666\n",
      "401) 429                            0.000665\n",
      "402) 307                            0.000665\n",
      "403) 346                            0.000663\n",
      "404) 233                            0.000663\n",
      "405) 140                            0.000662\n",
      "406) 403                            0.000660\n",
      "407) 456                            0.000659\n",
      "408) 188                            0.000658\n",
      "409) 127                            0.000657\n",
      "410) 405                            0.000656\n",
      "411) 152                            0.000654\n",
      "412) 466                            0.000652\n",
      "413) 138                            0.000648\n",
      "414) 373                            0.000648\n",
      "415) 224                            0.000647\n",
      "416) 408                            0.000643\n",
      "417) 232                            0.000639\n",
      "418) 137                            0.000637\n",
      "419) 326                            0.000635\n",
      "420) 143                            0.000632\n",
      "421) 292                            0.000631\n",
      "422) 277                            0.000629\n",
      "423) 136                            0.000627\n",
      "424) 85                             0.000624\n",
      "425) 88                             0.000624\n",
      "426) 414                            0.000623\n",
      "427) 364                            0.000622\n",
      "428) 365                            0.000620\n",
      "429) 226                            0.000619\n",
      "430) 360                            0.000617\n",
      "431) 300                            0.000616\n",
      "432) 118                            0.000612\n",
      "433) 206                            0.000612\n",
      "434) 302                            0.000612\n",
      "435) 368                            0.000607\n",
      "436) 432                            0.000604\n",
      "437) 149                            0.000603\n",
      "438) 329                            0.000594\n",
      "439) 297                            0.000593\n",
      "440) 348                            0.000593\n",
      "441) 392                            0.000592\n",
      "442) 377                            0.000592\n",
      "443) 415                            0.000590\n",
      "444) 139                            0.000589\n",
      "445) 190                            0.000588\n",
      "446) 201                            0.000586\n",
      "447) 498                            0.000586\n",
      "448) 191                            0.000584\n",
      "449) 340                            0.000582\n",
      "450) 197                            0.000580\n",
      "451) 247                            0.000580\n",
      "452) 333                            0.000580\n",
      "453) 347                            0.000577\n",
      "454) 260                            0.000577\n",
      "455) 59                             0.000576\n",
      "456) 130                            0.000573\n",
      "457) 196                            0.000571\n",
      "458) 357                            0.000567\n",
      "459) 245                            0.000565\n",
      "460) 433                            0.000563\n",
      "461) 275                            0.000561\n",
      "462) 412                            0.000561\n",
      "463) 255                            0.000561\n",
      "464) 97                             0.000559\n",
      "465) 442                            0.000554\n",
      "466) 372                            0.000553\n",
      "467) 378                            0.000551\n",
      "468) 250                            0.000550\n",
      "469) 64                             0.000550\n",
      "470) 109                            0.000548\n",
      "471) 393                            0.000548\n",
      "472) 213                            0.000547\n",
      "473) 440                            0.000539\n",
      "474) 343                            0.000538\n",
      "475) 395                            0.000537\n",
      "476) 305                            0.000536\n",
      "477) 342                            0.000533\n",
      "478) 324                            0.000531\n",
      "479) 397                            0.000526\n",
      "480) 214                            0.000522\n",
      "481) 205                            0.000521\n",
      "482) 379                            0.000520\n",
      "483) 391                            0.000517\n",
      "484) 65                             0.000515\n",
      "485) 389                            0.000515\n",
      "486) 384                            0.000515\n",
      "487) 163                            0.000507\n",
      "488) 304                            0.000497\n",
      "489) 366                            0.000495\n",
      "490) 424                            0.000494\n",
      "491) 193                            0.000486\n",
      "492) 207                            0.000483\n",
      "493) 358                            0.000476\n",
      "494) 169                            0.000476\n",
      "495) 425                            0.000473\n",
      "496) 239                            0.000469\n",
      "497) 334                            0.000453\n",
      "498) 157                            0.000446\n",
      "499) 380                            0.000433\n",
      "500) 400                            0.000413\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 500 is out of bounds for axis 0 with size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-665614754bd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     print(\"%2d) %-*s %f\" % (f + 1, 30, \n\u001b[1;32m----> 6\u001b[1;33m                             \u001b[0mfeat_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                             importances[indices[f]]))\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 500 is out of bounds for axis 0 with size 500"
     ]
    }
   ],
   "source": [
    "feat_labels = range(X_train_pca.shape[1])\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train_pca.shape[1]), \n",
    "        importances[indices],\n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train_pca.shape[1]), \n",
    "           feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train_pca.shape[1]])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/04_09.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning multiple linear regression with polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:19:06.120875Z",
     "start_time": "2021-05-10T23:19:06.114838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:19:08.498431Z",
     "start_time": "2021-05-10T23:19:08.492444Z"
    }
   },
   "outputs": [],
   "source": [
    "def r_2_score(y_true, y_pred):\n",
    "    from tensorflow.keras import backend as K\n",
    "    RSS =  K.sum(K.square( y_true- y_pred ))\n",
    "    TSS = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1. - RSS/(TSS) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:19:09.124905Z",
     "start_time": "2021-05-10T23:19:09.109659Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:30:31.851509Z",
     "start_time": "2021-05-10T23:30:31.805786Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X_train_pca.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model_train = Model(inputs=input_layer, outputs=output)\n",
    "model_train.compile(loss=\"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\",\"mean_squared_logarithmic_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:52:03.939230Z",
     "start_time": "2021-05-10T23:30:32.071055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 27596.1348 - mean_squared_error: 27596.1348 - mean_squared_logarithmic_error: 1.2500 - val_loss: 25329.7012 - val_mean_squared_error: 25329.7012 - val_mean_squared_logarithmic_error: 1.1910\n",
      "Epoch 2/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 23104.7715 - mean_squared_error: 23104.7715 - mean_squared_logarithmic_error: 1.0373 - val_loss: 21706.9902 - val_mean_squared_error: 21706.9902 - val_mean_squared_logarithmic_error: 0.9479\n",
      "Epoch 3/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 21469.6289 - mean_squared_error: 21469.6289 - mean_squared_logarithmic_error: 0.9764 - val_loss: 21258.8203 - val_mean_squared_error: 21258.8203 - val_mean_squared_logarithmic_error: 1.0591\n",
      "Epoch 4/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 20243.5508 - mean_squared_error: 20243.5508 - mean_squared_logarithmic_error: 0.9568 - val_loss: 20111.1914 - val_mean_squared_error: 20111.1914 - val_mean_squared_logarithmic_error: 0.9289\n",
      "Epoch 5/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 19365.1680 - mean_squared_error: 19365.1680 - mean_squared_logarithmic_error: 0.9186 - val_loss: 19669.8867 - val_mean_squared_error: 19669.8867 - val_mean_squared_logarithmic_error: 0.8521\n",
      "Epoch 6/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 18971.2871 - mean_squared_error: 18971.2871 - mean_squared_logarithmic_error: 0.9002 - val_loss: 18946.7148 - val_mean_squared_error: 18946.7148 - val_mean_squared_logarithmic_error: 0.9812\n",
      "Epoch 7/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 18460.4648 - mean_squared_error: 18460.4648 - mean_squared_logarithmic_error: 0.8920 - val_loss: 17878.2910 - val_mean_squared_error: 17878.2910 - val_mean_squared_logarithmic_error: 0.8742\n",
      "Epoch 8/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 17803.7305 - mean_squared_error: 17803.7305 - mean_squared_logarithmic_error: 0.8705 - val_loss: 18299.5547 - val_mean_squared_error: 18299.5547 - val_mean_squared_logarithmic_error: 0.8113\n",
      "Epoch 9/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 17606.3730 - mean_squared_error: 17606.3730 - mean_squared_logarithmic_error: 0.8514 - val_loss: 18484.0098 - val_mean_squared_error: 18484.0098 - val_mean_squared_logarithmic_error: 1.0244\n",
      "Epoch 10/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 17104.4355 - mean_squared_error: 17104.4355 - mean_squared_logarithmic_error: 0.8451 - val_loss: 17703.4688 - val_mean_squared_error: 17703.4688 - val_mean_squared_logarithmic_error: 0.8590\n",
      "Epoch 11/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16580.9199 - mean_squared_error: 16580.9199 - mean_squared_logarithmic_error: 0.8340 - val_loss: 19738.0547 - val_mean_squared_error: 19738.0547 - val_mean_squared_logarithmic_error: 1.0174\n",
      "Epoch 12/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16568.9668 - mean_squared_error: 16568.9668 - mean_squared_logarithmic_error: 0.8325 - val_loss: 18725.0977 - val_mean_squared_error: 18725.0977 - val_mean_squared_logarithmic_error: 0.8806\n",
      "Epoch 13/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16169.7793 - mean_squared_error: 16169.7793 - mean_squared_logarithmic_error: 0.8221 - val_loss: 21519.7422 - val_mean_squared_error: 21519.7422 - val_mean_squared_logarithmic_error: 0.8062\n",
      "Epoch 14/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16125.0830 - mean_squared_error: 16125.0830 - mean_squared_logarithmic_error: 0.8179 - val_loss: 18975.1289 - val_mean_squared_error: 18975.1289 - val_mean_squared_logarithmic_error: 0.7842\n",
      "Epoch 15/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15619.8008 - mean_squared_error: 15619.8008 - mean_squared_logarithmic_error: 0.8087 - val_loss: 19481.1230 - val_mean_squared_error: 19481.1230 - val_mean_squared_logarithmic_error: 0.7829\n",
      "Epoch 16/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15560.1562 - mean_squared_error: 15560.1562 - mean_squared_logarithmic_error: 0.7977 - val_loss: 16526.0820 - val_mean_squared_error: 16526.0820 - val_mean_squared_logarithmic_error: 0.7614\n",
      "Epoch 17/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15207.5615 - mean_squared_error: 15207.5615 - mean_squared_logarithmic_error: 0.7936 - val_loss: 21504.8242 - val_mean_squared_error: 21504.8242 - val_mean_squared_logarithmic_error: 0.9012\n",
      "Epoch 18/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 14875.1943 - mean_squared_error: 14875.1943 - mean_squared_logarithmic_error: 0.7862 - val_loss: 17747.4414 - val_mean_squared_error: 17747.4414 - val_mean_squared_logarithmic_error: 0.8990\n",
      "Epoch 19/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 14555.4326 - mean_squared_error: 14555.4326 - mean_squared_logarithmic_error: 0.7724 - val_loss: 18384.6758 - val_mean_squared_error: 18384.6758 - val_mean_squared_logarithmic_error: 0.8570\n",
      "Epoch 20/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 14297.9316 - mean_squared_error: 14297.9316 - mean_squared_logarithmic_error: 0.7720 - val_loss: 15992.8867 - val_mean_squared_error: 15992.8867 - val_mean_squared_logarithmic_error: 0.8286\n",
      "Epoch 21/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 14412.5430 - mean_squared_error: 14412.5430 - mean_squared_logarithmic_error: 0.7668 - val_loss: 16223.9395 - val_mean_squared_error: 16223.9395 - val_mean_squared_logarithmic_error: 0.8415\n",
      "Epoch 22/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 14043.5225 - mean_squared_error: 14043.5225 - mean_squared_logarithmic_error: 0.7701 - val_loss: 15205.5332 - val_mean_squared_error: 15205.5332 - val_mean_squared_logarithmic_error: 0.7794\n",
      "Epoch 23/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13779.6689 - mean_squared_error: 13779.6689 - mean_squared_logarithmic_error: 0.7623 - val_loss: 15780.1279 - val_mean_squared_error: 15780.1279 - val_mean_squared_logarithmic_error: 0.8481\n",
      "Epoch 24/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13409.3018 - mean_squared_error: 13409.3018 - mean_squared_logarithmic_error: 0.7591 - val_loss: 16333.2803 - val_mean_squared_error: 16333.2803 - val_mean_squared_logarithmic_error: 0.7623\n",
      "Epoch 25/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13373.6455 - mean_squared_error: 13373.6455 - mean_squared_logarithmic_error: 0.7508 - val_loss: 15916.0781 - val_mean_squared_error: 15916.0781 - val_mean_squared_logarithmic_error: 0.78193481.1250 - mean_squared_error: 13481.1250 - mean_squar\n",
      "Epoch 26/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13259.7812 - mean_squared_error: 13259.7812 - mean_squared_logarithmic_error: 0.7563 - val_loss: 15405.0938 - val_mean_squared_error: 15405.0938 - val_mean_squared_logarithmic_error: 0.8160\n",
      "Epoch 27/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13071.1123 - mean_squared_error: 13071.1123 - mean_squared_logarithmic_error: 0.7452 - val_loss: 15399.2910 - val_mean_squared_error: 15399.2910 - val_mean_squared_logarithmic_error: 0.7934\n",
      "Epoch 28/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12861.7197 - mean_squared_error: 12861.7197 - mean_squared_logarithmic_error: 0.7553 - val_loss: 15017.0869 - val_mean_squared_error: 15017.0869 - val_mean_squared_logarithmic_error: 0.8216mean_squared_logarithmic_error: 0.\n",
      "Epoch 29/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12592.0078 - mean_squared_error: 12592.0078 - mean_squared_logarithmic_error: 0.7410 - val_loss: 14799.2080 - val_mean_squared_error: 14799.2080 - val_mean_squared_logarithmic_error: 0.8112\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12524.7578 - mean_squared_error: 12524.7578 - mean_squared_logarithmic_error: 0.7465 - val_loss: 14890.4209 - val_mean_squared_error: 14890.4209 - val_mean_squared_logarithmic_error: 0.7682\n",
      "Epoch 31/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12249.0459 - mean_squared_error: 12249.0459 - mean_squared_logarithmic_error: 0.7454 - val_loss: 14734.7197 - val_mean_squared_error: 14734.7197 - val_mean_squared_logarithmic_error: 0.8082mean_squared_loga - ETA: 4s - los\n",
      "Epoch 32/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12019.6064 - mean_squared_error: 12019.6064 - mean_squared_logarithmic_error: 0.7368 - val_loss: 14800.7773 - val_mean_squared_error: 14800.7773 - val_mean_squared_logarithmic_error: 0.8493n_squared_error: 12407.1260 - mean_squared_lo - ETA: 7s - loss: 12022.3018 - mean_squared_error: 12022.3 - ETA: 5s - loss: 11868.1201 - mean_squared - ETA: 2s - loss: 12070.4814 - mean_squared_error: 1207\n",
      "Epoch 33/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12028.8877 - mean_squared_error: 12028.8877 - mean_squared_logarithmic_error: 0.7428 - val_loss: 14709.1445 - val_mean_squared_error: 14709.1445 - val_mean_squared_logarithmic_error: 0.7715ean_squared_error: 11920.0645 - mean_squared_logarithmic_err - ETA: 0s - loss: 11858.3506 - mean_squared_error: 11858.3506 - mean_squared_logarithmic_error: 0.\n",
      "Epoch 34/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11800.7207 - mean_squared_error: 11800.7207 - mean_squared_logarithmic_error: 0.7296 - val_loss: 15472.4521 - val_mean_squared_error: 15472.4521 - val_mean_squared_logarithmic_error: 0.7325\n",
      "Epoch 35/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11504.6768 - mean_squared_error: 11504.6768 - mean_squared_logarithmic_error: 0.7228 - val_loss: 15593.3838 - val_mean_squared_error: 15593.3838 - val_mean_squared_logarithmic_error: 0.7914\n",
      "Epoch 36/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11396.9580 - mean_squared_error: 11396.9580 - mean_squared_logarithmic_error: 0.7287 - val_loss: 14085.4033 - val_mean_squared_error: 14085.4033 - val_mean_squared_logarithmic_error: 0.7921\n",
      "Epoch 37/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11274.3545 - mean_squared_error: 11274.3545 - mean_squared_logarithmic_error: 0.7337 - val_loss: 14850.3955 - val_mean_squared_error: 14850.3955 - val_mean_squared_logarithmic_error: 0.8541\n",
      "Epoch 38/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11195.4072 - mean_squared_error: 11195.4072 - mean_squared_logarithmic_error: 0.7165 - val_loss: 14895.3711 - val_mean_squared_error: 14895.3711 - val_mean_squared_logarithmic_error: 0.7959\n",
      "Epoch 39/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11201.5801 - mean_squared_error: 11201.5801 - mean_squared_logarithmic_error: 0.7266 - val_loss: 17181.8203 - val_mean_squared_error: 17181.8203 - val_mean_squared_logarithmic_error: 0.8362s: 11164.9219 - mean_squared_error: 11164.9\n",
      "Epoch 40/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10883.8438 - mean_squared_error: 10883.8438 - mean_squared_logarithmic_error: 0.7129 - val_loss: 15149.7627 - val_mean_squared_error: 15149.7627 - val_mean_squared_logarithmic_error: 0.8628\n",
      "Epoch 41/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10811.8115 - mean_squared_error: 10811.8115 - mean_squared_logarithmic_error: 0.7147 - val_loss: 14204.2607 - val_mean_squared_error: 14204.2607 - val_mean_squared_logarithmic_error: 0.7217\n",
      "Epoch 42/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10788.4688 - mean_squared_error: 10788.4688 - mean_squared_logarithmic_error: 0.7091 - val_loss: 14300.0400 - val_mean_squared_error: 14300.0400 - val_mean_squared_logarithmic_error: 0.7483\n",
      "Epoch 43/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10537.6943 - mean_squared_error: 10537.6943 - mean_squared_logarithmic_error: 0.7130 - val_loss: 14966.4961 - val_mean_squared_error: 14966.4961 - val_mean_squared_logarithmic_error: 0.8032\n",
      "Epoch 44/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10536.5254 - mean_squared_error: 10536.5254 - mean_squared_logarithmic_error: 0.7138 - val_loss: 16755.7461 - val_mean_squared_error: 16755.7461 - val_mean_squared_logarithmic_error: 0.7717\n",
      "Epoch 45/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10363.9502 - mean_squared_error: 10363.9502 - mean_squared_logarithmic_error: 0.7093 - val_loss: 17431.0391 - val_mean_squared_error: 17431.0391 - val_mean_squared_logarithmic_error: 0.7685\n",
      "Epoch 46/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10369.8379 - mean_squared_error: 10369.8379 - mean_squared_logarithmic_error: 0.7086 - val_loss: 16843.0352 - val_mean_squared_error: 16843.0352 - val_mean_squared_logarithmic_error: 0.7323\n",
      "Epoch 47/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9995.5713 - mean_squared_error: 9995.5713 - mean_squared_logarithmic_error: 0.7041 - val_loss: 17644.1406 - val_mean_squared_error: 17644.1406 - val_mean_squared_logarithmic_error: 0.7696\n",
      "Epoch 48/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9957.7559 - mean_squared_error: 9957.7559 - mean_squared_logarithmic_error: 0.7139 - val_loss: 14084.0566 - val_mean_squared_error: 14084.0566 - val_mean_squared_logarithmic_error: 0.73270s - loss: 10020.4180 - mean_squared_error: 10020.4180 - mean_squared_logarithmic_error: 0.\n",
      "Epoch 49/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10072.8037 - mean_squared_error: 10072.8037 - mean_squared_logarithmic_error: 0.7005 - val_loss: 13771.9570 - val_mean_squared_error: 13771.9570 - val_mean_squared_logarithmic_error: 0.7783\n",
      "Epoch 50/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9941.2744 - mean_squared_error: 9941.2744 - mean_squared_logarithmic_error: 0.7045 - val_loss: 14095.3330 - val_mean_squared_error: 14095.3330 - val_mean_squared_logarithmic_error: 0.7434\n",
      "Epoch 51/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9814.1680 - mean_squared_error: 9814.1680 - mean_squared_logarithmic_error: 0.6984 - val_loss: 15608.6475 - val_mean_squared_error: 15608.6475 - val_mean_squared_logarithmic_error: 0.7935\n",
      "Epoch 52/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9466.9287 - mean_squared_error: 9466.9287 - mean_squared_logarithmic_error: 0.7025 - val_loss: 19966.0703 - val_mean_squared_error: 19966.0703 - val_mean_squared_logarithmic_error: 0.8076\n",
      "Epoch 53/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9613.4746 - mean_squared_error: 9613.4746 - mean_squared_logarithmic_error: 0.6923 - val_loss: 14269.5996 - val_mean_squared_error: 14269.5996 - val_mean_squared_logarithmic_error: 0.7558\n",
      "Epoch 54/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9475.2832 - mean_squared_error: 9475.2832 - mean_squared_logarithmic_error: 0.6971 - val_loss: 18975.4492 - val_mean_squared_error: 18975.4492 - val_mean_squared_logarithmic_error: 0.7288- loss: 9240.2422 - mean_squared_error: 9240.2422 - mean_squared_logarithm - ETA: 4s - loss:\n",
      "Epoch 55/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9457.5303 - mean_squared_error: 9457.5303 - mean_squared_logarithmic_error: 0.6990 - val_loss: 16547.6914 - val_mean_squared_error: 16547.6914 - val_mean_squared_logarithmic_error: 0.7526\n",
      "Epoch 56/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9185.6846 - mean_squared_error: 9185.6846 - mean_squared_logarithmic_error: 0.6905 - val_loss: 13972.4268 - val_mean_squared_error: 13972.4268 - val_mean_squared_logarithmic_error: 0.8074 loss: 8885.3232 - mean_squared_error: 8885.3232 - mean_squared_log - ETA: 3s - loss: 8769.5264 - mea\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9141.3906 - mean_squared_error: 9141.3906 - mean_squared_logarithmic_error: 0.6912 - val_loss: 16197.0029 - val_mean_squared_error: 16197.0029 - val_mean_squared_logarithmic_error: 0.8020ss: 8946.9746 - mean_squared_error: 8946.9746 - mea\n",
      "Epoch 58/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9199.8750 - mean_squared_error: 9199.8750 - mean_squared_logarithmic_error: 0.6931 - val_loss: 14452.7432 - val_mean_squared_error: 14452.7432 - val_mean_squared_logarithmic_error: 0.7674\n",
      "Epoch 59/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9000.7275 - mean_squared_error: 9000.7275 - mean_squared_logarithmic_error: 0.6916 - val_loss: 17332.6895 - val_mean_squared_error: 17332.6895 - val_mean_squared_logarithmic_error: 0.6990\n",
      "Epoch 60/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8939.5078 - mean_squared_error: 8939.5078 - mean_squared_logarithmic_error: 0.6827 - val_loss: 15161.3652 - val_mean_squared_error: 15161.3652 - val_mean_squared_logarithmic_error: 0.8230\n",
      "Epoch 61/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8815.1279 - mean_squared_error: 8815.1279 - mean_squared_logarithmic_error: 0.6764 - val_loss: 20771.9473 - val_mean_squared_error: 20771.9473 - val_mean_squared_logarithmic_error: 0.8395\n",
      "Epoch 62/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8774.3770 - mean_squared_error: 8774.3770 - mean_squared_logarithmic_error: 0.6819 - val_loss: 14438.2432 - val_mean_squared_error: 14438.2432 - val_mean_squared_logarithmic_error: 0.7290\n",
      "Epoch 63/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8712.7129 - mean_squared_error: 8712.7129 - mean_squared_logarithmic_error: 0.6708 - val_loss: 16383.2764 - val_mean_squared_error: 16383.2764 - val_mean_squared_logarithmic_error: 0.8602\n",
      "Epoch 64/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8760.0771 - mean_squared_error: 8760.0771 - mean_squared_logarithmic_error: 0.6769 - val_loss: 15417.8281 - val_mean_squared_error: 15417.8281 - val_mean_squared_logarithmic_error: 0.7433\n",
      "Epoch 65/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8696.6416 - mean_squared_error: 8696.6416 - mean_squared_logarithmic_error: 0.6784 - val_loss: 18625.0078 - val_mean_squared_error: 18625.0078 - val_mean_squared_logarithmic_error: 0.7220\n",
      "Epoch 66/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8473.6846 - mean_squared_error: 8473.6846 - mean_squared_logarithmic_error: 0.6675 - val_loss: 14820.0469 - val_mean_squared_error: 14820.0469 - val_mean_squared_logarithmic_error: 0.7420\n",
      "Epoch 67/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8523.8018 - mean_squared_error: 8523.8018 - mean_squared_logarithmic_error: 0.6695 - val_loss: 13956.1035 - val_mean_squared_error: 13956.1035 - val_mean_squared_logarithmic_error: 0.7242\n",
      "Epoch 68/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8353.9863 - mean_squared_error: 8353.9863 - mean_squared_logarithmic_error: 0.6727 - val_loss: 21217.2676 - val_mean_squared_error: 21217.2676 - val_mean_squared_logarithmic_error: 0.7579ed_error: 8046.803\n",
      "Epoch 69/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8367.4668 - mean_squared_error: 8367.4668 - mean_squared_logarithmic_error: 0.6680 - val_loss: 15353.4492 - val_mean_squared_error: 15353.4492 - val_mean_squared_logarithmic_error: 0.7326\n",
      "Epoch 70/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8328.3525 - mean_squared_error: 8328.3525 - mean_squared_logarithmic_error: 0.6685 - val_loss: 16065.5479 - val_mean_squared_error: 16065.5479 - val_mean_squared_logarithmic_error: 0.7895quared_error: 8380.1602 - mean_squared_logarithmic_error:\n",
      "Epoch 71/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8196.4219 - mean_squared_error: 8196.4219 - mean_squared_logarithmic_error: 0.6756 - val_loss: 22266.0547 - val_mean_squared_error: 22266.0547 - val_mean_squared_logarithmic_error: 0.7613\n",
      "Epoch 72/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8158.6084 - mean_squared_error: 8158.6084 - mean_squared_logarithmic_error: 0.6671 - val_loss: 22728.7129 - val_mean_squared_error: 22728.7129 - val_mean_squared_logarithmic_error: 0.7655\n",
      "Epoch 73/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8114.3721 - mean_squared_error: 8114.3721 - mean_squared_logarithmic_error: 0.6635 - val_loss: 15013.0771 - val_mean_squared_error: 15013.0771 - val_mean_squared_logarithmic_error: 0.7372\n",
      "Epoch 74/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7827.3667 - mean_squared_error: 7827.3667 - mean_squared_logarithmic_error: 0.6632 - val_loss: 20471.3027 - val_mean_squared_error: 20471.3027 - val_mean_squared_logarithmic_error: 0.7172\n",
      "Epoch 75/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7969.6582 - mean_squared_error: 7969.6582 - mean_squared_logarithmic_error: 0.6643 - val_loss: 22084.1016 - val_mean_squared_error: 22084.1016 - val_mean_squared_logarithmic_error: 0.7233\n",
      "Epoch 76/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7927.0596 - mean_squared_error: 7927.0596 - mean_squared_logarithmic_error: 0.6633 - val_loss: 15439.7930 - val_mean_squared_error: 15439.7930 - val_mean_squared_logarithmic_error: 0.7553_logarithmic_error: 0\n",
      "Epoch 77/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7848.9155 - mean_squared_error: 7848.9155 - mean_squared_logarithmic_error: 0.6598 - val_loss: 16229.5029 - val_mean_squared_error: 16229.5029 - val_mean_squared_logarithmic_error: 0.7356\n",
      "Epoch 78/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7735.1763 - mean_squared_error: 7735.1763 - mean_squared_logarithmic_error: 0.6548 - val_loss: 17204.9805 - val_mean_squared_error: 17204.9805 - val_mean_squared_logarithmic_error: 0.7651\n",
      "Epoch 79/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7769.0117 - mean_squared_error: 7769.0117 - mean_squared_logarithmic_error: 0.6623 - val_loss: 18266.2773 - val_mean_squared_error: 18266.2773 - val_mean_squared_logarithmic_error: 0.7354\n",
      "Epoch 80/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7627.1084 - mean_squared_error: 7627.1084 - mean_squared_logarithmic_error: 0.6585 - val_loss: 15842.2383 - val_mean_squared_error: 15842.2383 - val_mean_squared_logarithmic_error: 0.7405\n",
      "Epoch 81/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7659.7729 - mean_squared_error: 7659.7729 - mean_squared_logarithmic_error: 0.6600 - val_loss: 15666.5635 - val_mean_squared_error: 15666.5635 - val_mean_squared_logarithmic_error: 0.7738\n",
      "Epoch 82/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7458.6436 - mean_squared_error: 7458.6436 - mean_squared_logarithmic_error: 0.6541 - val_loss: 19868.0254 - val_mean_squared_error: 19868.0254 - val_mean_squared_logarithmic_error: 0.7530\n",
      "Epoch 83/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7561.7520 - mean_squared_error: 7561.7520 - mean_squared_logarithmic_error: 0.6604 - val_loss: 18625.3867 - val_mean_squared_error: 18625.3867 - val_mean_squared_logarithmic_error: 0.6983\n",
      "Epoch 84/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7479.8320 - mean_squared_error: 7479.8320 - mean_squared_logarithmic_error: 0.6414 - val_loss: 21466.2852 - val_mean_squared_error: 21466.2852 - val_mean_squared_logarithmic_error: 0.7708\n",
      "Epoch 85/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7314.7021 - mean_squared_error: 7314.7021 - mean_squared_logarithmic_error: 0.6550 - val_loss: 18486.5293 - val_mean_squared_error: 18486.5293 - val_mean_squared_logarithmic_error: 0.7436\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7320.6836 - mean_squared_error: 7320.6836 - mean_squared_logarithmic_error: 0.6477 - val_loss: 20451.2754 - val_mean_squared_error: 20451.2754 - val_mean_squared_logarithmic_error: 0.7316\n",
      "Epoch 87/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7430.7344 - mean_squared_error: 7430.7344 - mean_squared_logarithmic_error: 0.6489 - val_loss: 18921.1152 - val_mean_squared_error: 18921.1152 - val_mean_squared_logarithmic_error: 0.7839\n",
      "Epoch 88/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7280.3369 - mean_squared_error: 7280.3369 - mean_squared_logarithmic_error: 0.6554 - val_loss: 26853.6191 - val_mean_squared_error: 26853.6191 - val_mean_squared_logarithmic_error: 0.73827269.4302 - mean_squared_error: 7269.4302 - mean_s\n",
      "Epoch 89/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7099.2261 - mean_squared_error: 7099.2261 - mean_squared_logarithmic_error: 0.6572 - val_loss: 19209.5156 - val_mean_squared_error: 19209.5156 - val_mean_squared_logarithmic_error: 0.7960\n",
      "Epoch 90/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7354.7368 - mean_squared_error: 7354.7368 - mean_squared_logarithmic_error: 0.6496 - val_loss: 20587.9629 - val_mean_squared_error: 20587.9629 - val_mean_squared_logarithmic_error: 0.7319\n",
      "Epoch 91/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7126.9272 - mean_squared_error: 7126.9272 - mean_squared_logarithmic_error: 0.6473 - val_loss: 15695.2607 - val_mean_squared_error: 15695.2607 - val_mean_squared_logarithmic_error: 0.7312\n",
      "Epoch 92/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6973.1650 - mean_squared_error: 6973.1650 - mean_squared_logarithmic_error: 0.6450 - val_loss: 16567.1582 - val_mean_squared_error: 16567.1582 - val_mean_squared_logarithmic_error: 0.7694- mean_squared_logarithmic_error: 0.64\n",
      "Epoch 93/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7097.9570 - mean_squared_error: 7097.9570 - mean_squared_logarithmic_error: 0.6477 - val_loss: 17956.6855 - val_mean_squared_error: 17956.6855 - val_mean_squared_logarithmic_error: 0.7583\n",
      "Epoch 94/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6970.4307 - mean_squared_error: 6970.4307 - mean_squared_logarithmic_error: 0.6472 - val_loss: 17313.5879 - val_mean_squared_error: 17313.5879 - val_mean_squared_logarithmic_error: 0.7506\n",
      "Epoch 95/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6931.2949 - mean_squared_error: 6931.2949 - mean_squared_logarithmic_error: 0.6465 - val_loss: 31790.9922 - val_mean_squared_error: 31790.9922 - val_mean_squared_logarithmic_error: 0.7652\n",
      "Epoch 96/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6889.8140 - mean_squared_error: 6889.8140 - mean_squared_logarithmic_error: 0.6408 - val_loss: 21159.1992 - val_mean_squared_error: 21159.1992 - val_mean_squared_logarithmic_error: 0.7343\n",
      "Epoch 97/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6888.9927 - mean_squared_error: 6888.9927 - mean_squared_logarithmic_error: 0.6428 - val_loss: 24708.8574 - val_mean_squared_error: 24708.8574 - val_mean_squared_logarithmic_error: 0.760917 - me\n",
      "Epoch 98/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6849.8477 - mean_squared_error: 6849.8477 - mean_squared_logarithmic_error: 0.6369 - val_loss: 26324.6270 - val_mean_squared_error: 26324.6270 - val_mean_squared_logarithmic_error: 0.7397- loss: 7031.1797 - mean_squared_error: 7031.1797 - mean_squared_logarithmic_error: 0.63 - ETA: 3s - loss: 7092.4883 - mean_squared_error: 7092.4883 - mean_squared_logarithmic_error:  - ETA: 3s - loss: 6991.3789 - mean_squared_error - ETA: 0s - loss: 6983.0332 - mean_squared_error: 6983.0332 - mean_squared_logarithmi\n",
      "Epoch 99/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6776.5005 - mean_squared_error: 6776.5005 - mean_squared_logarithmic_error: 0.6320 - val_loss: 24374.9941 - val_mean_squared_error: 24374.9941 - val_mean_squared_logarithmic_error: 0.8170\n",
      "Epoch 100/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6778.5527 - mean_squared_error: 6778.5527 - mean_squared_logarithmic_error: 0.6402 - val_loss: 19052.1660 - val_mean_squared_error: 19052.1660 - val_mean_squared_logarithmic_error: 0.7462s: 6781.2627 - mean_squared_error: 6781.2627 - m - ETA: 4s - loss: 6832.3750 - mean_squared_e - ETA: 1s - loss: 6841.4580 - mean_squared_error: 6841.4580 - mean_squared_logarithmic_erro - ETA: 0s - loss: 6833.1660 - mean_squared_error: 6833.1660 - mean_squared_logar\n"
     ]
    }
   ],
   "source": [
    "history_train = model_train.fit(X_train_pca, y_train, batch_size=2, epochs=100, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T19:20:04.457314Z",
     "start_time": "2021-05-10T19:20:04.397782Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X_train_pca.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(loss=\"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\",\"mean_squared_logarithmic_error\",det_coeff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T19:42:48.266939Z",
     "start_time": "2021-05-10T19:20:09.669230Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 27502.4492 - mean_squared_error: 27502.4492 - mean_squared_logarithmic_error: 1.2241 - det_coeff: -inf - val_loss: 25228.3965 - val_mean_squared_error: 25228.3965 - val_mean_squared_logarithmic_error: 0.9755 - val_det_coeff: -inf\n",
      "Epoch 2/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 23168.6055 - mean_squared_error: 23168.6055 - mean_squared_logarithmic_error: 1.0271 - det_coeff: -inf - val_loss: 24931.4199 - val_mean_squared_error: 24931.4199 - val_mean_squared_logarithmic_error: 1.1732 - val_det_coeff: -infn_squared_error: 22650.7832 - mean_squared_logarithmic_error: 1.0234 - det_c - ETA: 3s - loss: 22628.4902 - mean_squared_error: 2\n",
      "Epoch 3/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 21653.6055 - mean_squared_error: 21653.6055 - mean_squared_logarithmic_error: 0.9881 - det_coeff: -inf - val_loss: 22447.9824 - val_mean_squared_error: 22447.9824 - val_mean_squared_logarithmic_error: 1.1357 - val_det_coeff: -inf\n",
      "Epoch 4/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 20732.7422 - mean_squared_error: 20732.7422 - mean_squared_logarithmic_error: 0.9645 - det_coeff: -inf - val_loss: 22273.5488 - val_mean_squared_error: 22273.5488 - val_mean_squared_logarithmic_error: 1.1145 - val_det_coeff: -inf\n",
      "Epoch 5/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 20257.8281 - mean_squared_error: 20257.8281 - mean_squared_logarithmic_error: 0.9410 - det_coeff: -inf - val_loss: 22732.7266 - val_mean_squared_error: 22732.7266 - val_mean_squared_logarithmic_error: 0.8842 - val_det_coeff: -inf\n",
      "Epoch 6/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 19489.2051 - mean_squared_error: 19489.2051 - mean_squared_logarithmic_error: 0.9200 - det_coeff: -inf - val_loss: 20481.5527 - val_mean_squared_error: 20481.5527 - val_mean_squared_logarithmic_error: 1.0290 - val_det_coeff: -infloss: 19313.5215 - mean_squared_error: 19313.5215 - mean_squared_logarithmic_error: 0.8959 - det_coe - ETA: 6s - loss: 19245.2598 - mean_squared_error: 19245.2598 - mean_squared_logarithmic_e - ETA: 4s - loss: 18830.4395 - mean_squared_error: 18830.4395 - mean_squared_logarithmic - ETA: 3s - loss: 19152.1680 - mean_squared_error: 19152.1680 - mean_squared_loga - ETA: 1s - loss: 19111.3945 - mean_squared_error: 19111.3945 - mean_squared_logarithmic_error: 0. - ETA: 0s - loss: 19481.2285 - mean_squared_error: 19481.2285 - mean_squared_logarithmic_error: 0.9197 - det_coeff: -in\n",
      "Epoch 7/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 18924.6309 - mean_squared_error: 18924.6309 - mean_squared_logarithmic_error: 0.9216 - det_coeff: -inf - val_loss: 20580.3125 - val_mean_squared_error: 20580.3125 - val_mean_squared_logarithmic_error: 0.9293 - val_det_coeff: -infss: 19170.1387 - mean_squared_error: 19170.1387 - mean_squared_logarithmic_error: 0.9276 - det_coef - ETA: 1s - loss: 18959.9609 - mean_squared_error: 18959.9609 - mean_squared_logarithmic_error: 0.9264 - de - ETA: 0s - loss: 19001.2734 - mean_squared_error: 19001.2734 - mean_squared_logarithmic_error: 0.9256 - det_coeff:  - ETA: 0s - loss: 18886.9980 - mean_squared_error: 18886.9980 - mean_squared_logarithmic_error: 0.9250 - det_coeff: - - ETA: 0s - loss: 18792.2559 - mean_squared_error: 18792.2559 - mean_squared_logarithmic_error: 0.9222 - det_coeff - ETA: 0s - loss: 18855.8965 - mean_squared_error: 18855.8965 - mean_squared_logarithmic_error: 0.9201 - det_coeff:\n",
      "Epoch 8/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 18490.8379 - mean_squared_error: 18490.8379 - mean_squared_logarithmic_error: 0.8992 - det_coeff: -inf - val_loss: 21092.4824 - val_mean_squared_error: 21092.4824 - val_mean_squared_logarithmic_error: 1.0076 - val_det_coeff: -inf023 - mean_sq - ETA: 1s - loss: 18509.7207 - mean_squared_error: 18509.7207 - mean_squared_logar\n",
      "Epoch 9/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 18131.6758 - mean_squared_error: 18131.6758 - mean_squared_logarithmic_error: 0.8918 - det_coeff: -inf - val_loss: 18996.1172 - val_mean_squared_error: 18996.1172 - val_mean_squared_logarithmic_error: 0.9336 - val_det_coeff: -inf\n",
      "Epoch 10/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 17704.5137 - mean_squared_error: 17704.5137 - mean_squared_logarithmic_error: 0.8714 - det_coeff: -inf - val_loss: 20731.7969 - val_mean_squared_error: 20731.7969 - val_mean_squared_logarithmic_error: 1.1087 - val_det_coeff: -infsquared_error: 17962.3477 - mean_squared_logarithmic_error: 0.8668 - det_coeff: -i - ETA: 2s - loss: 18056.7285 - mean_squared_error: 18056.7285 - mean_squared_logarithmic_error: 0. - ETA: 0s - loss: 17948.0156 - mean_squared_error: 17948.0156 - mean_squared_logarithmic_error: 0.8699 - det_coeff: - ETA: 0s - loss: 17829.6719 - mean_squared_error: 17829.6719 - mean_squared_logarithmic_error: 0.8691 - de\n",
      "Epoch 11/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 17624.5039 - mean_squared_error: 17624.5039 - mean_squared_logarithmic_error: 0.8629 - det_coeff: -inf - val_loss: 18923.8086 - val_mean_squared_error: 18923.8086 - val_mean_squared_logarithmic_error: 0.8354 - val_det_coeff: -infsquared_error: 17560.2539 - mean_squared_logarithmic_error: 0.8576 - det_coeff: - - ETA: 1s - loss: 17745.0371 - mean_squared_error: 17745.0371 - mean_squared_logarithmic_error: 0.8607 - det_coeff: - ETA: 0s - loss: 17973.9141 - mean_squared_error: 17973.9141 - mean_squared_logarithmic_error: 0.863\n",
      "Epoch 12/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 17042.7656 - mean_squared_error: 17042.7656 - mean_squared_logarithmic_error: 0.8509 - det_coeff: -inf - val_loss: 18518.2773 - val_mean_squared_error: 18518.2773 - val_mean_squared_logarithmic_error: 0.8770 - val_det_coeff: -infquared_error: 17504.5195 - mean_squared_logarithmic_error: 0.8513 - ETA: 5s - loss: 17349.1484 - mean_squared_error: 17349.1484 - mean_squared_l - ETA: 3s - loss: 16788.6719 - mean_squared_error: 16788.6719 - mean_squared_logarithmic_error: 0.8498 - d - ETA: 2s - loss: 16917.2520 - mean_squared_error: 16917.2520 - mean_squa\n",
      "Epoch 13/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 16884.4707 - mean_squared_error: 16884.4707 - mean_squared_logarithmic_error: 0.8426 - det_coeff: -inf - val_loss: 19154.5000 - val_mean_squared_error: 19154.5000 - val_mean_squared_logarithmic_error: 0.8066 - val_det_coeff: -infETA: 1s - loss: 16707.8008 - mean_squared_error: 16707.8008 - mean_squared_logarithmic_error: - ETA: 0s - loss: 16901.0098 - mean_squared_error: 16901.0098 - mean_squared_logarithmic_error: 0.8415 - det_coeff: -i\n",
      "Epoch 14/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16679.7344 - mean_squared_error: 16679.7344 - mean_squared_logarithmic_error: 0.8315 - det_coeff: -inf - val_loss: 17984.8359 - val_mean_squared_error: 17984.8359 - val_mean_squared_logarithmic_error: 0.7637 - val_det_coeff: -infred_error: 16758.8008 -  - ETA: 0s - loss: 16770.7500 - mean_squared_error: 16770.7500 - mean_squared_logarithmic_error: 0.8323 - det_\n",
      "Epoch 15/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 16462.9766 - mean_squared_error: 16462.9766 - mean_squared_logarithmic_error: 0.8283 - det_coeff: -inf - val_loss: 17721.0469 - val_mean_squared_error: 17721.0469 - val_mean_squared_logarithmic_error: 1.0161 - val_det_coeff: -inf\n",
      "Epoch 16/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16329.8203 - mean_squared_error: 16329.8203 - mean_squared_logarithmic_error: 0.8316 - det_coeff: -inf - val_loss: 17391.5215 - val_mean_squared_error: 17391.5215 - val_mean_squared_logarithmic_error: 0.8624 - val_det_coeff: -inf mean_squared_error: 16798.3809 - mean_squared_logarithmic_error: 0.8540 - det_co - ETA: 8s - loss: 15947.4736 - mean_squared_error: 15947.4736  - ETA: 5s - loss: 16672.9746 - mean_squared_error: 16672.9746 - mean_squared_logarithmic_error: 0.8261 - det_coef - ETA: 4s - loss: 16593.8066 - mean_squared_error: 16593.8066 - mean_squared_logarithmic - ETA: 2s - loss: 16442.7324 - mean_squared_error: 16442.7324 - m\n",
      "Epoch 17/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15682.1094 - mean_squared_error: 15682.1094 - mean_squared_logarithmic_error: 0.8192 - det_coeff: -inf - val_loss: 16820.3477 - val_mean_squared_error: 16820.3477 - val_mean_squared_logarithmic_error: 0.8263 - val_det_coeff: -inf.2607 - mean_squ - ETA: 2s - loss: 16075.3301 - mean_squared_error: 16075.3301\n",
      "Epoch 18/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15948.5361 - mean_squared_error: 15948.5361 - mean_squared_logarithmic_error: 0.8214 - det_coeff: -inf - val_loss: 17265.6953 - val_mean_squared_error: 17265.6953 - val_mean_squared_logarithmic_error: 0.8601 - val_det_coeff: -infoss: 16248.5527 - mean_squared_error: 16248.5527 - mean_squared_logarithmic_ - ETA: 5s - loss: 15932.3936 - mean_squared_error: 15932.3936 - mean_squared_logarithmic_error: 0.8291 - det_co - ETA: 5s - loss: 16023.9424 - mean_squared_error: 16023.9424 - mean_squared_logarithmic_error: 0.8274 - det_coeff: -i - ETA: 5s - \n",
      "Epoch 19/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15544.9395 - mean_squared_error: 15544.9395 - mean_squared_logarithmic_error: 0.8061 - det_coeff: -inf - val_loss: 17520.9531 - val_mean_squared_error: 17520.9531 - val_mean_squared_logarithmic_error: 0.9184 - val_det_coeff: -inf5104.7354 - mean_squared - ETA: 1s - loss: 15752.5400 - mean_squared_error: 15752.5400 - mean_squared_logarithmic_error: \n",
      "Epoch 20/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 15304.5850 - mean_squared_error: 15304.5850 - mean_squared_logarithmic_error: 0.8106 - det_coeff: -inf - val_loss: 17545.3711 - val_mean_squared_error: 17545.3711 - val_mean_squared_logarithmic_error: 1.0540 - val_det_coeff: -inf_squared_logarithmic_error: 0.7951 - det_coeff: - ETA: 3s - loss: 14896.5850 - mean_squared_error: 14896.5850 - ETA: 0s - loss: 14909.0537 - mean_squared_error: 14909.0537 - mean_squared_logarithmic_error: 0.804\n",
      "Epoch 21/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15118.3291 - mean_squared_error: 15118.3291 - mean_squared_logarithmic_error: 0.8075 - det_coeff: -inf - val_loss: 16808.9043 - val_mean_squared_error: 16808.9043 - val_mean_squared_logarithmic_error: 0.9864 - val_det_coeff: -inf\n",
      "Epoch 22/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15010.0215 - mean_squared_error: 15010.0215 - mean_squared_logarithmic_error: 0.8006 - det_coeff: -inf - val_loss: 16347.0127 - val_mean_squared_error: 16347.0127 - val_mean_squared_logarithmic_error: 0.8461 - val_det_coeff: -inf656.2891 - mean_squared_logarithmic - ETA: 5s - loss: 1\n",
      "Epoch 23/100\n",
      "12250/12250 [==============================] - 12s 1ms/step - loss: 14688.3477 - mean_squared_error: 14688.3477 - mean_squared_logarithmic_error: 0.7938 - det_coeff: -inf - val_loss: 17766.3574 - val_mean_squared_error: 17766.3574 - val_mean_squared_logarithmic_error: 0.8179 - val_det_coeff: -infrror: 14479.2051 - mean_squared_logarithmic_error: 0.7938 - \n",
      "Epoch 24/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 14472.7656 - mean_squared_error: 14472.7656 - mean_squared_logarithmic_error: 0.7825 - det_coeff: -inf - val_loss: 16781.3184 - val_mean_squared_error: 16781.3184 - val_mean_squared_logarithmic_error: 0.8077 - val_det_coeff: -inf80.1924\n",
      "Epoch 25/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 14477.1162 - mean_squared_error: 14477.1162 - mean_squared_logarithmic_error: 0.7828 - det_coeff: -inf - val_loss: 16238.1533 - val_mean_squared_error: 16238.1533 - val_mean_squared_logarithmic_error: 0.8128 - val_det_coeff: -inf\n",
      "Epoch 26/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 14252.3027 - mean_squared_error: 14252.3027 - mean_squared_logarithmic_error: 0.7905 - det_coeff: -inf - val_loss: 16083.0869 - val_mean_squared_error: 16083.0869 - val_mean_squared_logarithmic_error: 0.8429 - val_det_coeff: -infn_squared_error: 1470\n",
      "Epoch 27/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 13803.9590 - mean_squared_error: 13803.9590 - mean_squared_logarithmic_error: 0.7733 - det_coeff: -inf - val_loss: 18212.3320 - val_mean_squared_error: 18212.3320 - val_mean_squared_logarithmic_error: 1.0120 - val_det_coeff: -inf_squared_error: 13352.1221 - mean_squared_logarithmic_error: 0.7719 - det_coeff: - ETA: 3s - loss: 13420.5752 - mean_squared_error\n",
      "Epoch 28/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13745.7607 - mean_squared_error: 13745.7607 - mean_squared_logarithmic_error: 0.7856 - det_coeff: -inf - val_loss: 16963.2598 - val_mean_squared_error: 16963.2598 - val_mean_squared_logarithmic_error: 0.9141 - val_det_coeff: -inf: 13893.4189 - mean_squared_error: 13893.4189 - mean_squared_logarithmic_error: 0.7\n",
      "Epoch 29/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 13469.5801 - mean_squared_error: 13469.5801 - mean_squared_logarithmic_error: 0.7718 - det_coeff: -inf - val_loss: 16738.9980 - val_mean_squared_error: 16738.9980 - val_mean_squared_logarithmic_error: 0.8905 - val_det_coeff: -inf6 - mean_squared_logarithmic_error: 0.7716 - det_coeff - ETA: 6s - loss: 12617.4023 - mean_squ - ETA: 2s - loss: 13630.0322 - mean_squared_error: 13630.0322 - mean_squared_logarithmic_error: 0.7738 - det_coeff:  - ETA: 2s - loss: 13602.2061 - mean_squared_error: 13602.2061 - mean_squared_logarithmic_error: 0.7725 - det_co - ETA: 1s - loss: 13368.8672 - mean_squared_error: 13368.8672 - mean_squared_logarit\n",
      "Epoch 30/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 13484.0449 - mean_squared_error: 13484.0449 - mean_squared_logarithmic_error: 0.7792 - det_coeff: -inf - val_loss: 15721.9248 - val_mean_squared_error: 15721.9248 - val_mean_squared_logarithmic_error: 0.8149 - val_det_coeff: -inf_squared_error: 13423.6045 - mean_squared_l - ETA: 5s - loss: 13121.8105 - mean_squared_error: 13121.8105 - mean_squared_logarithmic_er - ETA: 3s - loss: 13270.7939 - mean_squared_error: 13270.7939 - mean_squared_logarithmic_e - ETA: 2s - loss: 13418.4004 - mean_squared_error: 13418.4004 - mean_squared_logarithmic_erro - ETA: 1s - loss: 13591.0771 - mean_squared_error: 13591.0771 - mean_squared_logarithmic_error: 0.7\n",
      "Epoch 31/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13312.4189 - mean_squared_error: 13312.4189 - mean_squared_logarithmic_error: 0.7686 - det_coeff: -inf - val_loss: 15679.4678 - val_mean_squared_error: 15679.4678 - val_mean_squared_logarithmic_error: 0.7931 - val_det_coeff: -inf\n",
      "Epoch 32/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 13118.9668 - mean_squared_error: 13118.9668 - mean_squared_logarithmic_error: 0.7731 - det_coeff: -inf - val_loss: 17877.8496 - val_mean_squared_error: 17877.8496 - val_mean_squared_logarithmic_error: 0.9701 - val_det_coeff: -infquared_error: 13322.0537 - mean_squared_logarithmic_error: 0.7650 - det_c - ETA: 3s - loss: 13343.4570 - mean_squared_error: 13343.4570 - mean_squared_logarithmic_error: 0.7715 - det_coeff: - ETA: 3s - loss: 13196.0889 - mean_squared_error: 13196.\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12250/12250 [==============================] - 14s 1ms/step - loss: 12940.5039 - mean_squared_error: 12940.5039 - mean_squared_logarithmic_error: 0.7619 - det_coeff: -inf - val_loss: 16808.1348 - val_mean_squared_error: 16808.1348 - val_mean_squared_logarithmic_error: 0.8210 - val_det_coeff: -inf\n",
      "Epoch 34/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 12568.7129 - mean_squared_error: 12568.7129 - mean_squared_logarithmic_error: 0.7597 - det_coeff: -inf - val_loss: 15230.9590 - val_mean_squared_error: 15230.9590 - val_mean_squared_logarithmic_error: 0.8207 - val_det_coeff: -infr: 12721.4277 - mean_squared_logarithmic_error: 0.7 - ETA: 2s - loss: 12274.6953 - mean_squared_error: 12274.6953 - mean_squared_logarithmic_error: 0.7621 - det_coe - ETA: 2s - loss: 12402.8125 - mean_squared_error: 12402.8125 - mean_squared_\n",
      "Epoch 35/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12562.4775 - mean_squared_error: 12562.4775 - mean_squared_logarithmic_error: 0.7620 - det_coeff: -inf - val_loss: 14392.3203 - val_mean_squared_error: 14392.3203 - val_mean_squared_logarithmic_error: 0.8078 - val_det_coeff: -inf\n",
      "Epoch 36/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 12418.1484 - mean_squared_error: 12418.1484 - mean_squared_logarithmic_error: 0.7510 - det_coeff: -inf - val_loss: 14120.7207 - val_mean_squared_error: 14120.7207 - val_mean_squared_logarithmic_error: 0.8669 - val_det_coeff: -inf\n",
      "Epoch 37/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 12177.0869 - mean_squared_error: 12177.0869 - mean_squared_logarithmic_error: 0.7671 - det_coeff: -inf - val_loss: 15172.0703 - val_mean_squared_error: 15172.0703 - val_mean_squared_logarithmic_error: 0.7707 - val_det_coeff: -infared_logarithmic_error: 0.7693 - det_co - ETA: 7s - loss: 11646.5820 - ETA: 2s - loss: 12408.3779 - mean_squared_error: 12408.3779 - mean_squa - ETA: 0s - loss: 12200.0420 - mean_squared_error: 12200.0420 - mean_squared_logarithmic_error: 0.7677 - det_coeff: -\n",
      "Epoch 38/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 11941.8164 - mean_squared_error: 11941.8164 - mean_squared_logarithmic_error: 0.7485 - det_coeff: -inf - val_loss: 14693.2969 - val_mean_squared_error: 14693.2969 - val_mean_squared_logarithmic_error: 0.7858 - val_det_coeff: -infA: 4s - loss: 11912.7832 - mean_squa\n",
      "Epoch 39/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 11925.2031 - mean_squared_error: 11925.2031 - mean_squared_logarithmic_error: 0.7522 - det_coeff: -inf - val_loss: 14899.6084 - val_mean_squared_error: 14899.6084 - val_mean_squared_logarithmic_error: 0.7709 - val_det_coeff: -inf01.4434 - mean_squ\n",
      "Epoch 40/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11677.3965 - mean_squared_error: 11677.3965 - mean_squared_logarithmic_error: 0.7396 - det_coeff: -inf - val_loss: 15724.3506 - val_mean_squared_error: 15724.3506 - val_mean_squared_logarithmic_error: 0.9254 - val_det_coeff: -inf\n",
      "Epoch 41/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 11645.2373 - mean_squared_error: 11645.2373 - mean_squared_logarithmic_error: 0.7398 - det_coeff: -inf - val_loss: 14544.7715 - val_mean_squared_error: 14544.7715 - val_mean_squared_logarithmic_error: 0.8295 - val_det_coeff: -inf\n",
      "Epoch 42/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11322.1748 - mean_squared_error: 11322.1748 - mean_squared_logarithmic_error: 0.7473 - det_coeff: -inf - val_loss: 15496.0107 - val_mean_squared_error: 15496.0107 - val_mean_squared_logarithmic_error: 0.8097 - val_det_coeff: -inf\n",
      "Epoch 43/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11289.7373 - mean_squared_error: 11289.7373 - mean_squared_logarithmic_error: 0.7423 - det_coeff: -inf - val_loss: 14979.8018 - val_mean_squared_error: 14979.8018 - val_mean_squared_logarithmic_error: 0.8392 - val_det_coeff: -inf\n",
      "Epoch 44/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 11165.1504 - mean_squared_error: 11165.1504 - mean_squared_logarithmic_error: 0.7369 - det_coeff: -inf - val_loss: 14669.8008 - val_mean_squared_error: 14669.8008 - val_mean_squared_logarithmic_error: 0.7724 - val_det_coeff: -inf\n",
      "Epoch 45/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11148.7910 - mean_squared_error: 11148.7910 - mean_squared_logarithmic_error: 0.7380 - det_coeff: -inf - val_loss: 14110.4346 - val_mean_squared_error: 14110.4346 - val_mean_squared_logarithmic_error: 0.8306 - val_det_coeff: -inf\n",
      "Epoch 46/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10938.3828 - mean_squared_error: 10938.3828 - mean_squared_logarithmic_error: 0.7316 - det_coeff: -inf - val_loss: 13844.6768 - val_mean_squared_error: 13844.6768 - val_mean_squared_logarithmic_error: 0.7954 - val_det_coeff: -inf\n",
      "Epoch 47/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10606.5137 - mean_squared_error: 10606.5137 - mean_squared_logarithmic_error: 0.7221 - det_coeff: -inf - val_loss: 16168.8779 - val_mean_squared_error: 16168.8779 - val_mean_squared_logarithmic_error: 0.8213 - val_det_coeff: -inf\n",
      "Epoch 48/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10555.4189 - mean_squared_error: 10555.4189 - mean_squared_logarithmic_error: 0.7226 - det_coeff: -inf - val_loss: 14004.8945 - val_mean_squared_error: 14004.8945 - val_mean_squared_logarithmic_error: 0.7421 - val_det_coeff: -inf\n",
      "Epoch 49/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10457.1240 - mean_squared_error: 10457.1240 - mean_squared_logarithmic_error: 0.7284 - det_coeff: -inf - val_loss: 15569.9141 - val_mean_squared_error: 15569.9141 - val_mean_squared_logarithmic_error: 0.8653 - val_det_coeff: -infror: 10132.1465 - mean_squared_logarithmic_error: 0.704 - ETA:\n",
      "Epoch 50/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 10244.0752 - mean_squared_error: 10244.0752 - mean_squared_logarithmic_error: 0.7163 - det_coeff: -inf - val_loss: 14942.9961 - val_mean_squared_error: 14942.9961 - val_mean_squared_logarithmic_error: 0.7928 - val_det_coeff: -inf mean_squared_logarithmic_error: 0.7015 - det_coeff: - ETA: 3s - loss: 9876.6846 - mean_squared_error: 9876.6846 - mean_squared_logarithmic_error: 0.7021 - det_coeff:  - ETA: 2s - loss: 9935.3701 - mean_squared_error: 9935.3701 -\n",
      "Epoch 51/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 10388.6631 - mean_squared_error: 10388.6631 - mean_squared_logarithmic_error: 0.7275 - det_coeff: -inf - val_loss: 14086.8711 - val_mean_squared_error: 14086.8711 - val_mean_squared_logarithmic_error: 0.8597 - val_det_coeff: -inf\n",
      "Epoch 52/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10262.5635 - mean_squared_error: 10262.5635 - mean_squared_logarithmic_error: 0.7208 - det_coeff: -inf - val_loss: 14675.6191 - val_mean_squared_error: 14675.6191 - val_mean_squared_logarithmic_error: 0.7461 - val_det_coeff: -inf\n",
      "Epoch 53/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10264.8809 - mean_squared_error: 10264.8809 - mean_squared_logarithmic_error: 0.7086 - det_coeff: -inf - val_loss: 14411.1631 - val_mean_squared_error: 14411.1631 - val_mean_squared_logarithmic_error: 0.7821 - val_det_coeff: -inf\n",
      "Epoch 54/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10041.9941 - mean_squared_error: 10041.9941 - mean_squared_logarithmic_error: 0.6973 - det_coeff: -inf - val_loss: 15113.4658 - val_mean_squared_error: 15113.4658 - val_mean_squared_logarithmic_error: 0.7725 - val_det_coeff: -inf\n",
      "Epoch 55/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 9815.1094 - mean_squared_error: 9815.1094 - mean_squared_logarithmic_error: 0.7084 - det_coeff: -inf - val_loss: 13883.5518 - val_mean_squared_error: 13883.5518 - val_mean_squared_logarithmic_error: 0.7527 - val_det_coeff: -inf\n",
      "Epoch 56/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 9792.1670 - mean_squared_error: 9792.1670 - mean_squared_logarithmic_error: 0.6971 - det_coeff: -inf - val_loss: 15096.0840 - val_mean_squared_error: 15096.0840 - val_mean_squared_logarithmic_error: 0.8600 - val_det_coeff: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 9886.0420 - mean_squared_error: 9886.0420 - mean_squared_logarithmic_error: 0.6970 - det_coeff: -inf - val_loss: 14483.3555 - val_mean_squared_error: 14483.3555 - val_mean_squared_logarithmic_error: 0.8303 - val_det_coeff: -inf\n",
      "Epoch 58/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 9623.2539 - mean_squared_error: 9623.2539 - mean_squared_logarithmic_error: 0.7022 - det_coeff: -inf - val_loss: 13866.3516 - val_mean_squared_error: 13866.3516 - val_mean_squared_logarithmic_error: 0.7694 - val_det_coeff: -inf\n",
      "Epoch 59/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9467.2676 - mean_squared_error: 9467.2676 - mean_squared_logarithmic_error: 0.6957 - det_coeff: -inf - val_loss: 14260.2363 - val_mean_squared_error: 14260.2363 - val_mean_squared_logarithmic_error: 0.7792 - val_det_coeff: -inf\n",
      "Epoch 60/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9474.6543 - mean_squared_error: 9474.6543 - mean_squared_logarithmic_error: 0.6905 - det_coeff: -inf - val_loss: 13717.5469 - val_mean_squared_error: 13717.5469 - val_mean_squared_logarithmic_error: 0.7281 - val_det_coeff: -inf\n",
      "Epoch 61/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9254.5186 - mean_squared_error: 9254.5186 - mean_squared_logarithmic_error: 0.7023 - det_coeff: -inf - val_loss: 13927.9883 - val_mean_squared_error: 13927.9883 - val_mean_squared_logarithmic_error: 0.7768 - val_det_coeff: -inf\n",
      "Epoch 62/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 9296.4473 - mean_squared_error: 9296.4473 - mean_squared_logarithmic_error: 0.6936 - det_coeff: -inf - val_loss: 13680.6982 - val_mean_squared_error: 13680.6982 - val_mean_squared_logarithmic_error: 0.7408 - val_det_coeff: -infTA: 4s - loss: 8830.\n",
      "Epoch 63/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9311.2480 - mean_squared_error: 9311.2480 - mean_squared_logarithmic_error: 0.7013 - det_coeff: -inf - val_loss: 13563.3447 - val_mean_squared_error: 13563.3447 - val_mean_squared_logarithmic_error: 0.7477 - val_det_coeff: -infss: 8956.4189 - mean_squared_error: 8956.4189 - mean_squared_logarithmic_error:  - ETA: 3s - loss: 9059.2197 - mean_squared_error: 9059.2197 - mean_squared_logarithmic_error: 0.7037 - det_coeff: -in - ETA: 3s - loss: 9037.9727 - mean_squared_error: 903\n",
      "Epoch 64/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9210.5342 - mean_squared_error: 9210.5342 - mean_squared_logarithmic_error: 0.6878 - det_coeff: -inf - val_loss: 14102.5781 - val_mean_squared_error: 14102.5781 - val_mean_squared_logarithmic_error: 0.7265 - val_det_coeff: -inf\n",
      "Epoch 65/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9184.7695 - mean_squared_error: 9184.7695 - mean_squared_logarithmic_error: 0.6942 - det_coeff: -inf - val_loss: 13829.2021 - val_mean_squared_error: 13829.2021 - val_mean_squared_logarithmic_error: 0.7872 - val_det_coeff: -inf\n",
      "Epoch 66/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8938.2188 - mean_squared_error: 8938.2188 - mean_squared_logarithmic_error: 0.6877 - det_coeff: -inf - val_loss: 13522.3730 - val_mean_squared_error: 13522.3730 - val_mean_squared_logarithmic_error: 0.8291 - val_det_coeff: -inf\n",
      "Epoch 67/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8985.7051 - mean_squared_error: 8985.7051 - mean_squared_logarithmic_error: 0.6951 - det_coeff: -inf - val_loss: 14347.9570 - val_mean_squared_error: 14347.9570 - val_mean_squared_logarithmic_error: 0.7824 - val_det_coeff: -inf\n",
      "Epoch 68/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8815.6709 - mean_squared_error: 8815.6709 - mean_squared_logarithmic_error: 0.6819 - det_coeff: -inf - val_loss: 14006.9990 - val_mean_squared_error: 14006.9990 - val_mean_squared_logarithmic_error: 0.8299 - val_det_coeff: -infn_squared_logarithmic_erro\n",
      "Epoch 69/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8687.8945 - mean_squared_error: 8687.8945 - mean_squared_logarithmic_error: 0.6788 - det_coeff: -inf - val_loss: 14023.5371 - val_mean_squared_error: 14023.5371 - val_mean_squared_logarithmic_error: 0.7706 - val_det_coeff: -inf37.1270 - mean_squared_error: 8937.1270 - mean_squared - ETA: 5s - loss: 8794.7324 - mean_squared_error: 8794.7324 - mean_squared_logarithmic_erro - ETA: 3s - loss: 9086.8906 - mean_squared_error\n",
      "Epoch 70/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8733.2393 - mean_squared_error: 8733.2393 - mean_squared_logarithmic_error: 0.6829 - det_coeff: -inf - val_loss: 13349.2783 - val_mean_squared_error: 13349.2783 - val_mean_squared_logarithmic_error: 0.7846 - val_det_coeff: -infrror: 8717.3418 - mean_squared_logarithmic_error: 0.6831 - det_co\n",
      "Epoch 71/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8495.4082 - mean_squared_error: 8495.4082 - mean_squared_logarithmic_error: 0.6876 - det_coeff: -inf - val_loss: 13489.6230 - val_mean_squared_error: 13489.6230 - val_mean_squared_logarithmic_error: 0.7829 - val_det_coeff: -inf\n",
      "Epoch 72/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8525.2988 - mean_squared_error: 8525.2988 - mean_squared_logarithmic_error: 0.6815 - det_coeff: -inf - val_loss: 15325.9463 - val_mean_squared_error: 15325.9463 - val_mean_squared_logarithmic_error: 0.8171 - val_det_coeff: -infsquared_error: 8248.9238 - mean_squared_logar - ETA: 7s - loss: - ETA: 1s - loss: 8448.3750 - mean_squared_error: 8448.3750 - mean_squared_logarithmic_e\n",
      "Epoch 73/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8523.9971 - mean_squared_error: 8523.9971 - mean_squared_logarithmic_error: 0.6766 - det_coeff: -inf - val_loss: 14025.4502 - val_mean_squared_error: 14025.4502 - val_mean_squared_logarithmic_error: 0.7976 - val_det_coeff: -inf\n",
      "Epoch 74/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8309.5537 - mean_squared_error: 8309.5537 - mean_squared_logarithmic_error: 0.6790 - det_coeff: -inf - val_loss: 13704.9463 - val_mean_squared_error: 13704.9463 - val_mean_squared_logarithmic_error: 0.7035 - val_det_coeff: -inf\n",
      "Epoch 75/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8456.2471 - mean_squared_error: 8456.2471 - mean_squared_logarithmic_error: 0.6821 - det_coeff: -inf - val_loss: 13622.1475 - val_mean_squared_error: 13622.1475 - val_mean_squared_logarithmic_error: 0.7869 - val_det_coeff: -infrror: 8414.9893 - mean_squared_logarithmic_error: 0.6817 - det_coeff: -i\n",
      "Epoch 76/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8193.5303 - mean_squared_error: 8193.5303 - mean_squared_logarithmic_error: 0.6744 - det_coeff: -inf - val_loss: 13367.5811 - val_mean_squared_error: 13367.5811 - val_mean_squared_logarithmic_error: 0.8139 - val_det_coeff: -infarithmic_error: 0.6437 - det_c - ETA: 5s - loss: 7870.8389 - mean_squared_error: 7870.8389 - mean_squared_logarithmic_error: 0.6537 - det_ - ETA: 5s - loss: 7828.2744 - mean_squared_error: 7828.2744 - mean_squared_logarithmic_error - ETA: 3s - loss: 7944.2295 - mean_squared_error: 7944.2295 - mean_squared_logarithmic_error: 0.6593 - det_coeff:  - ETA: 3s - loss: 7911.8423 - mean_squared_error: 7911.8423 - mean_squared_logarithmic_error: 0.6 - ETA: 2s - loss: 8308.9590 - mean_squared_error: 8308.9590 - me\n",
      "Epoch 77/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8302.3965 - mean_squared_error: 8302.3965 - mean_squared_logarithmic_error: 0.6770 - det_coeff: -inf - val_loss: 13480.1816 - val_mean_squared_error: 13480.1816 - val_mean_squared_logarithmic_error: 0.7555 - val_det_coeff: -inf\n",
      "Epoch 78/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8112.9614 - mean_squared_error: 8112.9614 - mean_squared_logarithmic_error: 0.6742 - det_coeff: -inf - val_loss: 12715.9072 - val_mean_squared_error: 12715.9072 - val_mean_squared_logarithmic_error: 0.7344 - val_det_coeff: -inf 7667.3501 - mean_squared_logarithmic_e\n",
      "Epoch 79/100\n",
      "12250/12250 [==============================] - 15s 1ms/step - loss: 8111.2646 - mean_squared_error: 8111.2646 - mean_squared_logarithmic_error: 0.6693 - det_coeff: -inf - val_loss: 12848.8428 - val_mean_squared_error: 12848.8428 - val_mean_squared_logarithmic_error: 0.7628 - val_det_coeff: -infn_squared_error: 8095.2520 - mean_squared_logarithmic_error: 0.6694 - de\n",
      "Epoch 80/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8025.8755 - mean_squared_error: 8025.8755 - mean_squared_logarithmic_error: 0.6692 - det_coeff: -inf - val_loss: 13120.1143 - val_mean_squared_error: 13120.1143 - val_mean_squared_logarithmic_error: 0.7389 - val_det_coeff: -inf\n",
      "Epoch 81/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7819.9106 - mean_squared_error: 7819.9106 - mean_squared_logarithmic_error: 0.6669 - det_coeff: -inf - val_loss: 13228.3535 - val_mean_squared_error: 13228.3535 - val_mean_squared_logarithmic_error: 0.7515 - val_det_coeff: -infror: 7966.0132 - mean_squared_logarithm\n",
      "Epoch 82/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7832.1284 - mean_squared_error: 7832.1284 - mean_squared_logarithmic_error: 0.6744 - det_coeff: -inf - val_loss: 13936.9873 - val_mean_squared_error: 13936.9873 - val_mean_squared_logarithmic_error: 0.7504 - val_det_coeff: -inf3 - det - ETA: 5s - \n",
      "Epoch 83/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7914.9004 - mean_squared_error: 7914.9004 - mean_squared_logarithmic_error: 0.6705 - det_coeff: -inf - val_loss: 13037.3223 - val_mean_squared_error: 13037.3223 - val_mean_squared_logarithmic_error: 0.7300 - val_det_coeff: -inf\n",
      "Epoch 84/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7729.0259 - mean_squared_error: 7729.0259 - mean_squared_logarithmic_error: 0.6614 - det_coeff: -inf - val_loss: 13286.1396 - val_mean_squared_error: 13286.1396 - val_mean_squared_logarithmic_error: 0.8279 - val_det_coeff: -inf637.6401 - mean_squared_logarithmic_error: 0. - ETA: 3s - loss: 7571.4121 - mean_squared_error: 7571.4121 - mean_squa - ETA: 1s - loss: 7484.7256 - mean_squared_error: 7484.7256 - mean_squared_logarithmic_error: 0.6556 - de - ETA: 0s - loss: 7550.0679 - mean_squared_error: 7550.0679 - mean_squared_logarithmic_error: 0.658\n",
      "Epoch 85/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7657.8999 - mean_squared_error: 7657.8999 - mean_squared_logarithmic_error: 0.6689 - det_coeff: -inf - val_loss: 13601.1836 - val_mean_squared_error: 13601.1836 - val_mean_squared_logarithmic_error: 0.7858 - val_det_coeff: -inf - mean_squared_e - ETA: 5s - loss: 6667.7212 - mean_squared_error: 6667.7212 - mean_squared_logarithmi - ETA: 4s - loss: 7223.3452 - mean_s\n",
      "Epoch 86/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7599.2510 - mean_squared_error: 7599.2510 - mean_squared_logarithmic_error: 0.6687 - det_coeff: -inf - val_loss: 12738.5186 - val_mean_squared_error: 12738.5186 - val_mean_squared_logarithmic_error: 0.7536 - val_det_coeff: -inf\n",
      "Epoch 87/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7532.3691 - mean_squared_error: 7532.3691 - mean_squared_logarithmic_error: 0.6602 - det_coeff: -inf - val_loss: 12927.9102 - val_mean_squared_error: 12927.9102 - val_mean_squared_logarithmic_error: 0.7926 - val_det_coeff: -inf628.2637 - mean_squared_error: 7628.2637 - mean_squared_logarithmic_error: 0.6664 - de - ETA: 1s - loss: 7562.6836 - mean_squared_error: 7562.6836 - mean_squared_logarithmic_error: 0.6651 - det_coe - ETA: 1s - loss: 7484.1509 - mean_squared_error: 7484.1509 - mean_squared_logarit\n",
      "Epoch 88/100\n",
      "12250/12250 [==============================] - 15s 1ms/step - loss: 7538.5098 - mean_squared_error: 7538.5098 - mean_squared_logarithmic_error: 0.6635 - det_coeff: -inf - val_loss: 13291.0869 - val_mean_squared_error: 13291.0869 - val_mean_squared_logarithmic_error: 0.7841 - val_det_coeff: -inf 675 - ETA: 8s - loss: 7449.9375 - mean_squared_error: 7449.9375 - mean_squared_logarithmic_error: 0 - ETA: 7s - loss: 7428.9570 - mean_squared_error: 7428.9570 - mean_squar - ETA: 5s - loss: 7299.0928 - mean_squared_error: 7299.0928 - mean_squared_logarithmic_ - ETA: 3s - loss: 7372.6904 - mean_squared_error: 7372.6904 - mean_squared_logarithmic_error: 0.6568 - det_coeff: - - ETA: 3s - loss: 7395.6411 - mean_squared_error: 7395.6411 - mean_squared_logarithmic_error: 0. - ETA: 2s - loss: 7410.6504 - mean_squared_error: 7410.6504 - mean_squared_logarithmic_error: 0.658 - ETA: 1s - loss: 7514.8384 - mean_squared_error: 7514.8384 - mean_squared_logarithmic_error: 0.6600 - det_coeff: - - ETA: 1s - loss: 7487.4189 - mean_squared_error: 7487.4189 - mean_squared_logarithmic_error: 0.6609 - det_coeff: - - ETA: 1s - loss: 7466.7432 - mean_squared_error: 7466.7432 - mean_squared_logarithmic_error: 0.6\n",
      "Epoch 89/100\n",
      "12250/12250 [==============================] - 15s 1ms/step - loss: 7386.6099 - mean_squared_error: 7386.6099 - mean_squared_logarithmic_error: 0.6528 - det_coeff: -inf - val_loss: 14099.1768 - val_mean_squared_error: 14099.1768 - val_mean_squared_logarithmic_error: 0.7543 - val_det_coeff: -inf mean_squared_error: 9865.3418 - mean_squared_log - ETA: 10s - loss: 7636.5869 - mean_squared_error: 7636.5869 - mean_squared_logarithmic_error: 0. - ETA: 9s - loss: 7109.0703 - mean_squared_error: 7109.0703 - mean_squared_logarithmic_error: 0.6471 - d - ETA: 2s - loss: 7603.0396 - mean_squared_error: 7603.0396 - mean_sq\n",
      "Epoch 90/100\n",
      "12250/12250 [==============================] - 15s 1ms/step - loss: 7451.1885 - mean_squared_error: 7451.1885 - mean_squared_logarithmic_error: 0.6527 - det_coeff: -inf - val_loss: 12891.2324 - val_mean_squared_error: 12891.2324 - val_mean_squared_logarithmic_error: 0.7640 - val_det_coeff: -infor: 7163.9131 - mean_square - ETA: 7s - loss: 6968.5068 - mean_squared_error: 6968.5068 - mean_squared_logarithmic_error: 0.6519 - det_ - ETA: 7s - loss: 6913.5088 - mean_squared_error: 6913.5088 - mean_squared_logarithmic_error: 0.6568 - det_coef - ETA: 6s - loss: 6800.4395 - mean_squared_error: 6800.4395 - mean_squared_logarithmic_error: 0 - ETA: 5s - los\n",
      "Epoch 91/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7276.0156 - mean_squared_error: 7276.0156 - mean_squared_logarithmic_error: 0.6582 - det_coeff: -inf - val_loss: 12479.0820 - val_mean_squared_error: 12479.0820 - val_mean_squared_logarithmic_error: 0.7460 - val_det_coeff: -infuared_error: 8217.4287 - - ETA: 0s - loss: 7344.6636 - mean_squared_error: 7344.6636 - mean_squared_logarithmic_error: 0.6595 - det_coeff\n",
      "Epoch 92/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7212.7954 - mean_squared_error: 7212.7954 - mean_squared_logarithmic_error: 0.6632 - det_coeff: -inf - val_loss: 13088.0049 - val_mean_squared_error: 13088.0049 - val_mean_squared_logarithmic_error: 0.7378 - val_det_coeff: -inf\n",
      "Epoch 93/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7141.4033 - mean_squared_error: 7141.4033 - mean_squared_logarithmic_error: 0.6600 - det_coeff: -inf - val_loss: 12724.9932 - val_mean_squared_error: 12724.9932 - val_mean_squared_logarithmic_error: 0.7149 - val_det_coeff: -inf\n",
      "Epoch 94/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7165.9570 - mean_squared_error: 7165.9570 - mean_squared_logarithmic_error: 0.6476 - det_coeff: -inf - val_loss: 12204.2793 - val_mean_squared_error: 12204.2793 - val_mean_squared_logarithmic_error: 0.7261 - val_det_coeff: -inf mean_squared_error:  - ETA: 3s - loss: 7055.5220 - mean_squared_error: 7055.5220 - mean_squared_logarithmic_error: 0.6437 - det_co - ETA: 3s - loss: 7015.5620 - mean_squared_error: 7015.5620 - mean_squared_logarithmic_error: 0.6467 - det_coeff: - ETA: 2s - loss: 7055.4517 - mean_squared_error: 7055.4517 -\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7205.7935 - mean_squared_error: 7205.7935 - mean_squared_logarithmic_error: 0.6558 - det_coeff: -inf - val_loss: 12468.0908 - val_mean_squared_error: 12468.0908 - val_mean_squared_logarithmic_error: 0.7117 - val_det_coeff: -inf\n",
      "Epoch 96/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7001.9385 - mean_squared_error: 7001.9385 - mean_squared_logarithmic_error: 0.6503 - det_coeff: -inf - val_loss: 12655.1416 - val_mean_squared_error: 12655.1416 - val_mean_squared_logarithmic_error: 0.7551 - val_det_coeff: -inf\n",
      "Epoch 97/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 6961.7334 - mean_squared_error: 6961.7334 - mean_squared_logarithmic_error: 0.6587 - det_coeff: -inf - val_loss: 12182.4082 - val_mean_squared_error: 12182.4082 - val_mean_squared_logarithmic_error: 0.6969 - val_det_coeff: -infan_squared_error: 6920.9702 - mean_squared_logarithmic_e\n",
      "Epoch 98/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7066.4727 - mean_squared_error: 7066.4727 - mean_squared_logarithmic_error: 0.6558 - det_coeff: -inf - val_loss: 15869.4629 - val_mean_squared_error: 15869.4629 - val_mean_squared_logarithmic_error: 0.8256 - val_det_coeff: -inf - mean_squared_logarithmic_error:  - ETA: 6s - loss: 6673.8818 - mean_squared_error: 6673.8818 - mean_squared_logarithmic_err - ETA: 5s - loss: 6420.6 - ETA: 0s - loss: 7058.9131 - mean_squared_error: 7058.9131 - mean_squared_logarithmic_error: 0.6549 - d\n",
      "Epoch 99/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6982.5908 - mean_squared_error: 6982.5908 - mean_squared_logarithmic_error: 0.6585 - det_coeff: -inf - val_loss: 13207.7197 - val_mean_squared_error: 13207.7197 - val_mean_squared_logarithmic_error: 0.7557 - val_det_coeff: -inf627.9360 - mean_squared_error: 662 - ETA: 3s - loss: 6984.8628 - mean_squared_er\n",
      "Epoch 100/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 6878.7114 - mean_squared_error: 6878.7114 - mean_squared_logarithmic_error: 0.6522 - det_coeff: -inf - val_loss: 13384.4180 - val_mean_squared_error: 13384.4180 - val_mean_squared_logarithmic_error: 0.7951 - val_det_coeff: -inf\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pca, y_train, batch_size=2, epochs=100, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:45:14.642906Z",
     "start_time": "2021-05-10T21:45:14.621925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_squared_error', 'mean_squared_logarithmic_error', 'det_coeff', 'val_loss', 'val_mean_squared_error', 'val_mean_squared_logarithmic_error', 'val_det_coeff'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:46:02.672717Z",
     "start_time": "2021-05-10T21:46:02.247916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d09332d640>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEAAAARACAYAAADu/yZPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZSdd33n+c9TdXWvdK/21ZKskhexeZUEGGMbHEJYwmagkw6ZhEAWCAmZCSeZnp7MnGRyTk66Oz1nEk56QpOFBJJOQzIEgrMQSDpgsHFsvAK2MZZsS7Jl2ZIsy1KVVFJVPfOHSsYQY5ekuvd57q3X6xwdl5+qK3/r8N+b7/P7FWVZBgAAAGCQDVU9AAAAAEC3CSAAAADAwBNAAAAAgIEngAAAAAADTwABAAAABp4AAgAAAAy8RtUDnK6VK1eW55xzTtVjAAAAADVx66237ivLctUzfa9vA8g555yTW265peoxAAAAgJooimLH9/qeV2AAAACAgSeAAAAAAANPAAEAAAAGngACAAAADDwBBAAAABh4AggAAAAw8AQQAAAAYOAJIAAAAMDAE0AAAACAgSeAAAAAAANPAAEAAAAGngACAAAADDwBBAAAABh4AggAAAAw8AQQAAAAYOAJIAAAAMDAE0AAAACAgSeAAAAAAANPAAEAAAAGngACAAAADDwBBAAAABh4AggAAAAw8AQQAAAAYOAJIAAAAMDAE0AAAACAgSeAAAAAAANPAAEAAAAGngACAAAADDwBBAAAABh4AggAAAAw8AQQAAAAYOAJIAAAAMDAE0AAAACAgSeAAAAAAANPAAEAAAAGngACAAAADDwBBAAAABh4AggAAAAw8AQQAAAAYOAJIAAAAMDAE0AAAACAgSeAAAAAAANPAAEAAAAGngACAAAADDwBBAAAABh4AkiP/fq1d+Ut/+/1VY8BAAAAc4oA0mPjE1PZ/cTRqscAAACAOUUA6bFOczhjxyaqHgMAAADmFAGkx9qtRsaOTWZqqqx6FAAAAJgzBJAe6zSHkyRHjk9WPAkAAADMHQJIj7VbjSTJqNdgAAAAoGcEkB47uQEyNm4DBAAAAHpFAOmxdtMGCAAAAPSaANJjndb0BsgxGyAAAADQKwJIjz21ATJuAwQAAAB6RQDpMRsgAAAA0HsCSI91bIAAAABAzwkgPdaZvgbXBggAAAD0jgDSY+3pa3DdAgMAAAC9I4D0WKsxlOGhwiswAAAA0EMCSI8VRZF2czij416BAQAAgF4RQCrQaTYy5hUYAAAA6BkBpALt1nBGHYIKAAAAPSOAVKDTbGTMGSAAAADQMwJIBdpNGyAAAADQSwJIBTotZ4AAAABALwkgFWg3hzPmFhgAAADoGQGkAp1mI6M2QAAAAKBnBJAKtFs2QAAAAKCXBJAKnNwAKcuy6lEAAABgThBAKtBuDWeqTMYnpqoeBQAAAOYEAaQCnWYjSTI67hwQAAAA6AUBpALt5nCSZOyYc0AAAACgFwSQCnRa0xsgboIBAACAnhBAKnByA2TUTTAAAADQEwJIBU5ugIzZAAEAAICeEEAq8O1DUG2AAAAAQC8IIBXotE4egmoDBAAAAHpBAKlA++QGiFtgAAAAoCcEkAqc3AAZHbcBAgAAAL0ggFRgfmM4RZGMCSAAAADQEwJIBYaGirTnDXsFBgAAAHpEAKlIu9VwCCoAAAD0iABSkU5z2DW4AAAA0CMCSEXaTRsgAAAA0CsCSEU6LRsgAAAA0CsCSEVsgAAAAEDvCCAV6bTcAgMAAAC9IoBUpN1sZGzcBggAAAD0ggBSkU7TBggAAAD0igBSkXbLGSAAAADQKwJIRTrN4RyfLHNsYqrqUQAAAGDgCSAVaTcbSWILBAAAAHpAAKlIpzWcJM4BAQAAgB4QQCry1AaIm2AAAACg6wSQiixsnQggNkAAAACg+wSQirSbJ16BsQECAAAA3SeAVKRjAwQAAAB6RgCpyFMbIG6BAQAAgK4TQCpycgPksFdgAAAAoOsEkIp8+wwQr8AAAABAtwkgFTl5De6oV2AAAACg6wSQigwPFZk/byhjDkEFAACArhNAKtRpNjLqDBAAAADoOgGkQu3WsA0QAAAA6AEBpEI2QAAAAKA3BJAKtZs2QAAAAKAXBJAKdVoNt8AAAABADwggFWo3hzM2bgMEAAAAuk0AqVCnaQMEAAAAekEAqZBbYAAAAKA3BJAKuQUGAAAAekMAqVC72cj4xFQmJqeqHgUAAAAGmgBSoU5rOEkydtxrMAAAANBNAkiF2s1GkrgJBgAAALpMAKnQyQ0QN8EAAABAdwkgFerYAAEAAICeEEAq1LYBAgAAAD0hgFTo5AaIq3ABAACguwSQCn37DBCvwAAAAEA3CSAV+vYtMDZAAAAAoJsEkAo99QqMDRAAAADoKgGkQguaJ16BsQECAAAA3SWAVKjZGEpzeMgGCAAAAHSZAFKxdms4Y67BBQAAgK4SQCrWaTYyOm4DBAAAALpJAKlYu2kDBAAAALpNAKlYu9VwBggAAAB0mQBSsU5z2C0wAAAA0GUCSMXaTRsgAAAA0G0CSMU6boEBAACArhNAKtZ2CwwAAAB0nQBSsY5bYAAAAKDrBJCKtVuNjB2bzNRUWfUoAAAAMLAEkIotbA0nSY4c9xoMAAAAdIsAUrF2s5EkGfUaDAAAAHSNAFKxzvQGyJiDUAEAAKBrBJCK2QABAACA7hNAKtY5GUBsgAAAAEDXCCAVa0+/AmMDBAAAALpHAKnYyQ0QZ4AAAABA9wggFWs3bYAAAABAtwkgFeu0Tm6ACCAAAADQLQJIxb69AeIVGAAAAOgWAaRircZQhoeKjHkFBgAAALpGAKlYURRpN4ddgwsAAABdJIDUQKfZsAECAAAAXSSA1EC7NewMEAAAAOgiAaQGOs2GW2AAAACgiwSQGmg3bYAAAABANwkgNdBpOQMEAAAAukkAqYF2czhjboEBAACArhFAaqDTbGTUBggAAAB0jQBSA51WwwYIAAAAdJEAUgOd1nBGj02kLMuqRwEAAICBJIDUQLvZyFSZjE9MVT0KAAAADCQBpAY6reEkyei4c0AAAACgGwSQGmg3G0mSsWPOAQEAAIBuEEBqoNM8sQFy2AYIAAAAdMVzBpCiKDYURfGFoijuKYrirqIofnH6+a8XRfFwURR3TP95w9M+8ytFUWwriuLeoihe97TnLy6K4uvT3/vdoiiK6eetoij+Yvr5TUVRnDP7v2p9tVsnN0AEEAAAAOiGmWyATCT55bIsX5Tk8iTvL4rigunv/U5Zlpun//x9kkx/7x1JLkzy+iQfKopiePrn/2uS9yZ53vSf108//+kkB8qy3JTkd5L81pn/av3j5AbIqKtwAQAAoCueM4CUZflIWZa3TX99KMk9SdY/y0euSfKJsizHy7J8IMm2JJcVRbE2yeKyLG8sT9z3+qdJ3vq0z3xs+utPJnn1ye2QueDbZ4DYAAEAAIBuOKUzQKZfTdmS5KbpR79QFMXXiqL446Iolk0/W59k19M+9tD0s/XTX3/38+/4TFmWE0kOJlnxDP/99xZFcUtRFLfs3bv3VEavtW/fAmMDBAAAALphxgGkKIqFSf4qyQfKsnwyJ15nOT/J5iSPJPl/Tv7oM3y8fJbnz/aZ73xQln9QluVLyrJ8yapVq2Y6eu3ZAAEAAIDumlEAKYpiXk7Ejz8vy/JTSVKW5aNlWU6WZTmV5A+TXDb94w8l2fC0j5+dZPf087Of4fl3fKYoikaSJUkeP51fqB89tQHiGlwAAADoipncAlMk+UiSe8qy/O2nPV/7tB97W5JvTH99bZJ3TN/scm5OHHZ6c1mWjyQ5VBTF5dN/508k+czTPvOu6a9/KMk/T58TMifMbwynKJIx1+ACAABAVzRm8DNXJnlnkq8XRXHH9LP/I8mPFkWxOSdeVXkwyc8mSVmWdxVF8ZdJ7s6JG2TeX5blydWGn0vy0SQLknx2+k9yIrD8WVEU23Ji8+MdZ/Zr9ZehoSLtecM2QAAAAKBLnjOAlGV5fZ75jI6/f5bP/GaS33yG57ckuegZnh9N8sPPNcsga7cazgABAACALjmlW2Donk5z2C0wAAAA0CUCSE20mzZAAAAAoFsEkJrotGyAAAAAQLcIIDVhAwQAAAC6RwCpiYWthltgAAAAoEsEkJpoN4czNm4DBAAAALpBAKmJjg0QAAAA6BoBpCbazWFngAAAAECXCCA10Wk1cnyyzLGJqapHAQAAgIEjgNREuzmcJBl1DggAAADMOgGkJjrNRpJk1GswAAAAMOsEkJpot05sgIw5CBUAAABmnQBSE09tgHgFBgAAAGadAFITJ88AsQECAAAAs08AqYlOywYIAAAAdIsAUhM2QAAAAKB7BJCaeGoDxC0wAAAAMOsEkJp4agNk3AYIAAAAzDYBpCbaTRsgAAAA0C0CSE0MDxWZP2/IGSAAAADQBQJIjXSaDbfAAAAAQBcIIDXSbg3bAAEAAIAuEEBqxAYIAAAAdIcAUiOdVsMGCAAAAHSBAFIj7eawW2AAAACgCwSQGuk0GxkbtwECAAAAs00AqZF2ywYIAAAAdIMAUiOdpjNAAAAAoBsEkBppt4bdAgMAAABdIIDUSKfZyPjEVCYmp6oeBQAAAAaKAFIj7eZwkmTUazAAAAAwqwSQGum0GkmSMQehAgAAwKwSQGrkqQ0QV+ECAADArBJAaqTTtAECAAAA3SCA1Ei7ZQMEAAAAukEAqREbIAAAANAdAkiNdFpugQEAAIBuEEBqpH1yA2TcBggAAADMJgGkRk6+AmMDBAAAAGaXAFIjC6avwbUBAgAAALNLAKmRZmMozeEhGyAAAAAwywSQmmm3ht0CAwAAALNMAKmZTrOR0XEbIAAAADCbBJCa6dgAAQAAgFkngNRMu9lwBggAAADMMgGkZjqtYbfAAAAAwCwTQGrGBggAAADMPgGkZjpNZ4AAAADAbBNAaqbdamTUKzAAAAAwqwSQmuk0h12DCwAAALNMAKmZdrORI8cnMzlVVj0KAAAADAwBpGY6reEkyZHjtkAAAABgtgggNdNuNpLEVbgAAAAwiwSQmjm5AeIqXAAAAJg9AkjNnNwAcRMMAAAAzB4BpGY6J1+BsQECAAAAs0YAqZn2U6/A2AABAACA2SKA1MxTGyDjNkAAAABgtgggNdNu2gABAACA2SaA1Eyn5RpcAAAAmG0CSM18ewPEKzAAAAAwWwSQmmk1hjI8VGTMKzAAAAAwawSQmimKIp3mcEYdggoAAACzRgCpoU6rYQMEAAAAZpEAUkPt5rAzQAAAAGAWCSA11Gk13AIDAAAAs0gAqSEbIAAAADC7BJAa6jSdAQIAAACzSQCpoXar4RYYAAAAmEUCSA2duAbXBggAAADMFgGkhtrNRsacAQIAAACzRgCpoU5rOKPHJlKWZdWjAAAAwEAQQGqo3WykLJOjx6eqHgUAAAAGggBSQ53WcJJk1E0wAAAAMCsEkBpqNxtJkjE3wQAAAMCsEEBqqNO0AQIAAACzSQCpoXZregNEAAEAAIBZIYDU0FMbIF6BAQAAgFkhgNTQU2eA2AABAACAWSGA1NDJW2AOHRVAAAAAYDYIIDW0ZvH8JMmeg0crngQAAAAGgwBSQ/PnDWfN4lZ2PD5W9SgAAAAwEASQmhpZ3s5OAQQAAABmhQBSUyPLO9m5XwABAACA2SCA1NTI8nb2PHk0R4+7ChcAAADOlABSUxtXtJMkDx2wBQIAAABnSgCpqQ3LTwQQ54AAAADAmRNAaurkBsgO54AAAADAGRNAampFp5l2c9gGCAAAAMwCAaSmiqLIyPJ2dgkgAAAAcMYEkBobWd72CgwAAADMAgGkxkaWt7Pz8bGUZVn1KAAAANDXBJAa27iinfGJqTx2aLzqUQAAAKCvCSA15ipcAAAAmB0CSI1tXNFJ4ipcAAAAOFMCSI2tX7ogQ4UNEAAAADhTAkiNNRtDWbtkQXbuH616FAAAAOhrAkjNnbwJBgAAADh9AkjNbVwhgAAAAMCZEkBqbsPydvYdPpbR8YmqRwEAAIC+JYDU3MYVrsIFAACAMyWA1NzIcgEEAAAAzpQAUnMbl3eSJDv3CyAAAABwugSQmlvSnpfF8xs2QAAAAOAMCCB9YOOKTnYIIAAAAHDaBJA+MLK8nV0CCAAAAJw2AaQPjKxo56EDY5mcKqseBQAAAPqSANIHRpa3c3yyzCMHj1Q9CgAAAPQlAaQPbHQVLgAAAJwRAaQPbDgZQFyFCwAAAKdFAOkD65YuSGOosAECAAAAp0kA6QPDQ0XOXrbAVbgAAABwmgSQPrHBVbgAAABw2gSQPrFxRTs7nAECAAAAp0UA6RMjy9s5eOR4Do4dr3oUAAAA6DsCSJ8YWd5J4ipcAAAAOB0CSJ8YOXkVrgACAAAAp0wA6RMjK04EkB2Pj1Y8CQAAAPQfAaRPLGw1sqLTdBMMAAAAnAYBpI+MuAkGAAAATosA0kdGlredAQIAAACnQQDpIxuXt7P7iSM5NjFV9SgAAADQVwSQPrJheTtTZbL7iSNVjwIAAAB9RQDpIxtXdJK4ChcAAABOlQDSR0aWn7wKVwABAACAUyGA9JHVi1ppNYZchQsAAACnSADpI0NDRTYsb2fH/tGqRwEAAIC+IoD0mY3L29n5uENQAQAA4FQIIH1mw/J2du4fTVmWVY8CAAAAfUMA6TMbV7Qzemwyj48eq3oUAAAA6BsCSJ9xEwwAAACcOgGkz2xccSKAuAkGAAAAZk4A6TNnL5veANkvgAAAAMBMCSB9Zv684Zy1eH522gABAACAGRNA+tDI8nZ22gABAACAGRNA+tCG5W0bIAAAAHAKBJA+tHFFO3uePJqjxyerHgUAAAD6ggDSh05ehfvQAVsgAAAAMBMCSB8aWeEmGAAAADgVAkgfOrkB4hwQAAAAmBkBpA+t6DTTaQ4LIAAAADBDAkgfKorixE0wXoEBAACAGRFA+tTGFa7CBQAAgJkSQPrUyPITAWRqqqx6FAAAAKg9AaRPjazoZHxiKnsPj1c9CgAAANSeANKnTt4E4ypcAAAAeG4CSJ/a6CpcAAAAmDEBpE+tW7ogQ0Wyc/9o1aMAAABA7QkgfarZGMq6pQtsgAAAAMAMCCB9bGR5OzsEEAAAAHhOAkgfO3dlJ9sfO+wqXAAAAHgOAkgfu3TD0jx5dCL373MOCAAAADwbAaSPbR1ZmiS5beeBiicBAACAehNA+th5Kxdm8fxGbhdAAAAA4FkJIH1saKjIlpFluX3nE1WPAgAAALUmgPS5LSNLc++jh3Lo6PGqRwEAAIDaEkD63NaRZSnL5M5dB6seBQAAAGpLAOlzm0eWpijiHBAAAAB4FgJIn1s8f142rVroJhgAAAB4FgLIANg6siy373oiZVlWPQoAAADUkgAyALZuXJonxo7n/n2jVY8CAAAAtSSADICtI8uSxHW4AAAA8D0IIAPg/FULs2h+wzkgAAAA8D0IIANgaKjI5g1Lc9sOAQQAAACeiQAyILaOLMu3Hj2Uw+MTVY8CAAAAtSOADIgtI0szVSZf2+UcEAAAAPhuAsiA2LLhxEGozgEBAACAf00AGRBL2vOyafXC3OYmGAAAAPhXBJABsnVkaW7feSBlWVY9CgAAANSKADJAtowsy4Gx43lw/1jVowAAAECtCCADZOvI9DkgrsMFAACA7yCADJDnrV6YRa2Gg1ABAADguwggA2RoqMilG5bmdgehAgAAwHcQQAbM1pGl+eaeJzM6PlH1KAAAAFAbAsiA2bJxWabK5M6HbIEAAADASQLIgNmyYWmSeA0GAAAAnkYAGTBL282ct6qT2x2ECgAAAE8RQAbQ1pFluW3nEynLsupRAAAAoBYEkAG0dWRZHh89lh37x6oeBQAAAGpBABlAW0amzwHZ5TUYAAAASASQgfT8NYuysNXIbTschAoAAACJADKQhoeKXLphSW5zECoAAAAkEUAG1taRZfnmnkMZOzZR9SgAAABQOQFkQG0ZWZrJqTJfe+hg1aMAAABA5QSQAbVlw7Ik8RoMAAAARAAZWMs6zZy3suMgVAAAAIgAMtA2jyzNHbsOpCzLqkcBAACASgkgA2zryLLsO3wsux4/UvUoAAAAUCkBZIBtHXEOCAAAACQCyEB7wVmL0m4OCyAAAADMeQLIABseKnLp2Utz+04HoQIAADC3CSADbuvGpbnnkSdz5Nhk1aMAAABAZQSQAbd1ZFkmpsp87SFbIAAAAMxdAsiA2zqyLI2hIv9w156qRwEAAIDKCCADblmnmTdesjafvOWhHB6fqHocAAAAqIQAMge8+4pzcmh8Ip+67aGqRwEAAIBKCCBzwJaRZbl0w9J89CsPZmqqrHocAAAA6DkBZI74ySvOyf17R/PlbfuqHgUAAAB6TgCZI95w8dqsWtTKR294oOpRAAAAoOcEkDmi2RjKj71sJF+4d28e2Dda9TgAAADQUwLIHPI/vWwk84aLfOwrD1Y9CgAAAPSUADKHrF40P2+6ZF0+eetDOXT0eNXjAAAAQM8IIHPMu684J4fHJ/JXt7oSFwAAgLlDAJljLt2wNFtGluZjN+5wJS4AAABzhgAyB737inPywL7RXHff3qpHAQAAgJ4QQOagH7xobVYvauWjNzxY9SgAAADQEwLIHNRsDOXHL9+Y6761N9v3Hq56HAAAAOg6AWSO+tHLRtIcHsqfuhIXAACAOUAAmaNWLWrlTZeudSUuAAAAc4IAMof95BXnZvTYZD7pSlwAAAAGnAAyh1189pK8eOOyfOwrD7oSFwAAgIEmgMxx777inDy4fyzXfcuVuAAAAAwuAWSOe/1FZ2XN4lb+xGGoAAAADDABZI6bNzyUd16+MV/61t5se8yVuAAAAAwmAYS84+SVuDc+WPUoAAAA0BUCCFm5sJU3XrI2n7794UxMTlU9DgAAAMw6AYQkyatftDqHjk7k6w8frHoUAAAAmHUCCEmSK85fmSS5Ydu+iicBAACA2SeAkCRZ3mnmwnWLc70AAgAAwAASQHjKVZtW5rYdT2Ts2ETVowAAAMCsEkB4ypWbVubY5FS++uCBqkcBAACAWSWA8JSXnrM8zeEh54AAAAAwcAQQnrKgOZwXb1yW6+8TQAAAABgsAgjf4arnrczdjzyZ/YfHqx4FAAAAZs1zBpCiKDYURfGFoijuKYrirqIofnH6+fKiKP6xKIr7pv+57Gmf+ZWiKLYVRXFvURSve9rzFxdF8fXp7/1uURTF9PNWURR/Mf38pqIozpn9X5WZuHLTietwb7x/f8WTAAAAwOyZyQbIRJJfLsvyRUkuT/L+oiguSPK/J/kfZVk+L8n/mP73TH/vHUkuTPL6JB8qimJ4+u/6r0nem+R5039eP/38p5McKMtyU5LfSfJbs/C7cRouXr8ki+Y3nAMCAADAQHnOAFKW5SNlWd42/fWhJPckWZ/kmiQfm/6xjyV56/TX1yT5RFmW42VZPpBkW5LLiqJYm2RxWZY3lmVZJvnT7/rMyb/rk0lefXI7hN4aHipyxfkrcr0AAgAAwAA5pTNApl9N2ZLkpiRryrJ8JDkRSZKsnv6x9Ul2Pe1jD00/Wz/99Xc//47PlGU5keRgkhXP8N9/b1EUtxRFccvevXtPZXROwVWbVmbX40eyc/9Y1aMAAADArJhxACmKYmGSv0rygbIsn3y2H32GZ+WzPH+2z3zng7L8g7IsX1KW5UtWrVr1XCNzmk6eA2ILBAAAgEExowBSFMW8nIgff16W5aemHz86/VpLpv/52PTzh5JseNrHz06ye/r52c/w/Ds+UxRFI8mSJI+f6i/D7Dh3ZSfrlsx3DggAAAADYya3wBRJPpLknrIsf/tp37o2ybumv35Xks887fk7pm92OTcnDju9efo1mUNFUVw+/Xf+xHd95uTf9UNJ/nn6nBAqUBRFrti0Mjds35epKf8zAAAA0P9msgFyZZJ3Jvn+oijumP7zhiT/KclriqK4L8lrpv89ZVneleQvk9yd5B+SvL8sy8npv+vnkvxRThyMuj3JZ6effyTJiqIotiX5pUzfKEN1rtq0Mk+MHc/djzzb204AAADQHxrP9QNlWV6fZz6jI0le/T0+85tJfvMZnt+S5KJneH40yQ8/1yz0zhWbTpxBe/22fblo/ZKKpwEAAIAzc0q3wDB3rF40Py9Ys8g5IAAAAAwEAYTv6cpNK3PzA4/n6PHJ5/5hAAAAqDEBhO/pquetyPjEVG7bcaDqUQAAAOCMCCB8T5eduyKNoSLXew0GAACAPieA8D0tbDWyZWSpc0AAAADoewIIz+rKTSvztYcP5uDY8apHAQAAgNMmgPCsrtq0MmWZ3Hi/LRAAAAD6lwDCs7p0w9J0msPOAQEAAKCvCSA8q3nDQ7n8vBW5Ydv+qkcBAACA0yaA8Jyu3LQyD+wbzUMHxqoeBQAAAE6LAMJzuup5K5MkX7EFAgAAQJ8SQHhOz1u9MKsWtXLDdueAAAAA0J8EEJ5TURS5atPK3LBtX8qyrHocAAAAOGUCCDNy5aaV2Xf4WO599FDVowAAAMApE0CYkSs3rUiSXH+f12AAAADoPwIIM7J2yYKcv6qTG7YJIAAAAPQfAYQZu2rTytz0wOM5NjFV9SgAAABwSgQQZuzKTSszdmwyt+88UPUoAAAAcEoEEGbs8vNXpDk8lM/f/WjVowAAAMApEUCYscXz5+X7X7g6n7ljdyYmvQYDAABA/xBAOCVv3bI++w6P54bt+6seBQAAAGZMAOGUvOqFq7Jkwbx8+raHqh4FAAAAZkwA4ZS0GsN54yVr87m7Hs3o+ETV4wAAAMCMCCCcsrdvWZ8jxyfzubv2VD0KAAAAzIgAwil78cZl2bB8QT59+8NVjwIAAAAzIoBwyoqiyNs2r88N2/blsSePVj0OAAAAPCcBhNPy1i3rM1Um1965u+pRAAAA4DkJIJyW81YtzKUbluZTt3kNBgAAgPoTQDhtb9u8Lnc/8mTu3XOo6lEAAADgWQkgnLY3X7ouw0OFw1ABAACoPQGE07ZiYStXP39VPnPHw5maKqseBwAAAL4nAYQz8rYt6/PIwaP5lwf2Vz0KAAAAfE8CCGfkNResycJWI592GHXq5qEAACAASURBVCoAAAA1JoBwRubPG84PXnRWPvuNPTl6fLLqcQAAAOAZCSCcsbdtWZ/D4xP5x7sfrXoUAAAAeEYCCGfs8vNWZO2S+flrt8EAAABQUwIIZ2xoqMhbNq/Ldd/am/2Hx6seBwAAAP4VAYRZ8fYtZ2diqszffu2RqkcBAACAf0UAYVa84KxFedHaxfmU12AAAACoIQGEWfP2Letz564ncv/ew1WPAgAAAN9BAGHWvGXzugwVcRgqAAAAtSOAMGvWLJ6fKzetzKfveDhlWVY9DgAAADxFAGFWvXXz+ux6/Ehu3XGg6lEAAADgKQIIs+r1F52VBfOG82mvwQAAAFAjAgizqtNq5HUXrsm1d+7OoaPHqx4HAAAAkgggdMFPXnluDh2dyMdv3ln1KAAAAJBEAKELLt2wNFduWpE/+vIDGZ+YrHocAAAAEEDojp+7elMeOzSeT93mLBAAAACqJ4DQFVduWpFLzl6S379ueyanXIkLAABAtQQQuqIoivzc1efnwf1j+Ydv7Kl6HAAAAOY4AYSuee2FZ+W8lZ186IvbUpa2QAAAAKiOAELXDA8Ved/V5+eu3U/my/ftq3ocAAAA5jABhK5665b1OWvx/Hzoi9uqHgUAAIA5TAChq5qNofzMK87Nv9z/eG7beaDqcQAAAJijBBC67kcvG8mSBfPy4S9ur3oUAAAA5igBhK7rtBp51xXn5PN3P5r7Hj1U9TgAAADMQQIIPfHuK87JgnnD+fB191c9CgAAAHOQAEJPLO80847LNuQzdzych584UvU4AAAAzDECCD3zM684L0nyh1+yBQIAAEBvCSD0zPqlC/LWLevzia/uzOOjx6oeBwAAgDlEAKGn3nf1eRmfmMpHb3ig6lEAAACYQwQQemrT6kV57QVr8rEbd+Tw+ETV4wAAADBHCCD03PuuPj8HjxzPJ27eWfUoAAAAzBECCD23ZWRZXn7eivzhl+/P+MRk1eMAAAAwBwggVOLnX3V+Hn1yPH95y0NVjwIAAMAcIIBQias2rcxl5y7PB//xW3ny6PGqxwEAAGDACSBUoiiK/OobL8jjY8fye1/YVvU4AAAADDgBhMpcfPaS/JutZ+dPrn8wO/ePVT0OAAAAA0wAoVL/7nUvSGO4yH/87D1VjwIAAMAAE0Co1JrF8/O+q8/PZ7+xJzfdv7/qcQAAABhQAgiVe88rzsu6JfPzG393d6amyqrHAQAAYAAJIFRuQXM4//4HX5hvPPxk/uo21+ICAAAw+wQQauEtl67LlpGl+c+fuzej4xNVjwMAAMCAEUCohaIo8qtvuiB7D43nw9dtr3ocAAAABowAQm1sHVmWazavyx986f48/MSRqscBAABggAgg1Mr/9voXJkl+67PfrHgSAAAABokAQq2sX7og733lebn2zt25dceBqscBAABgQAgg1M77rj4/qxe18ht/61pcAAAAZocAQu10Wo38u9e9IHfseiJ/87XdVY8DAADAABBAqKV/s/XsXLR+cX7rs9/MkWOTVY8DAABAnxNAqKWhoSK/9qYLs/vg0fzhl++vehwAAAD6nABCbV127vL84EVn5cPXbc8TY8eqHgcAAIA+JoBQax/4gedn7NhkPvqVB6seBQAAgD4mgFBrLzhrUV5zwZr8yQ0P5vD4RNXjAAAA0KcEEGrv/a/alINHjue/37Sj6lEAAADoUwIItbd5w9JctWll/vDLD+TocTfCAAAAcOoEEPrCz7/q/Ow9NJ5P3vpQ1aMAAADQhwQQ+sLLz1uRLSNL8+Hrtuf45FTV4wAAANBnBBD6QlEUef/3bcpDB47kb+7cXfU4AAAA9BkBhL7x6hetzgvPWpQPfXF7pqbKqscBAACgjwgg9I2iKPLzr9qUbY8dzufvfrTqcQAAAOgjAgh95Y0Xr805K9r5vS9sS1naAgEAAGBmBBD6yvBQkfddfX6+/vDBfPm+fVWPAwAAQJ8QQOg7b9u6Pmctnp/f+8K2qkcBAACgTwgg9J1WYzjvfeV5uemBx3PLg49XPQ4AAAB9QAChL73jsg1Z3mnaAgEAAGBGBBD6UrvZyE9deU6+cO/e3LX7YNXjAAAAUHMCCH3rnS8/J4tajXzoi9urHgUAAICaE0DoW0sWzMs7X74xf//1R7J97+GqxwEAAKDGBBD62k9ddW6aw0P5sC0QAAAAnoUAQl9bubCVH71sJJ++/eF8c8+TVY8DAABATQkg9L33vPK8tBpDef0Hv5wf+6N/ybV37s7R45NVjwUAAECNFGVZVj3DaXnJS15S3nLLLVWPQU3sOXg0/98tu/IXt+zKQweOZGl7Xt6+5ey847INef6aRVWPBwAAQA8URXFrWZYvecbvCSAMkqmpMjds35dPfHVXPn/XnhyfLLNlZGl+9KUjeeMla9NpNaoeEQAAgC4RQJiT9h8ez6dvfzgfv3lntu8dTac5nPe88rx84AeeX/VoAAAAdMGzBRBngDCwVixs5WdecV7+6Zeuziff9/K89Nzl+eA/3Zddj49VPRoAAAA9JoAw8IqiyEvOWZ7fuOaiJMnffG13xRMBAADQawIIc8aG5e28eOOyXHuHAAIAADDXCCDMKddsXpdv7jmUe/ccqnoUAAAAekgAYU55w8VrMzxU5No7H656FAAAAHpIAGFOWbmwlSs3rcxn7tidfr0BCQAAgFMngDDnXHPpujx04Ehu2/lE1aMAAADQIwIIc85rL1yTVmMo197hNRgAAIC5QgBhzlk0f15+4EVr8ndffyQTk1NVjwMAAEAPCCDMSW++dF32HT6Wr2zfX/UoAAAA9IAAwpz0fS9YlUXzG/nMHburHgUAAIAeEECYk+bPG84PXnRWPnfXnhw9Pln1OAAAAHSZAMKcdc3m9Tk8PpF//uZjVY8CAABAlwkgzFmXn7ciqxa18hm3wQAAAAw8AYQ5a3ioyJsuWZsv3Ls3B48cr3ocAAAAukgAYU67ZvP6HJuYyufu2lP1KAAAAHSRAMKcdunZS7JxRTvXug0GAABgoAkgzGlFUeSaS9flK9v35bEnj1Y9DgAAAF0igDDnvWXzukyVyd9+7ZGqRwEAAKBLBBDmvE2rF+WCtYtz7Z1egwEAABhUAggkuWbzutyx64ns2D9a9SgAAAB0gQACSd586bokcRgqAADAgBJAIMm6pQty2TnL89d3PJyyLKseBwAAgFkmgMC0t2xel+17R3P3I09WPQoAAACzTACBaW+4eG0aQ4XDUAEAAAaQAALTlneaeeXzV+Vv7tidqSmvwQAAAAwSAQSe5prN67L74NFcv21f1aMAAAAwiwQQeJofeNGarF0yPz/7Z7fmr29/uOpxAAAAmCUCCDxNp9XIZ95/ZS5evyQf+Is78muf+UaOTUxVPRYAAABnSACB77J68fz8+Xtelve84tz86Y078m9//8bsfuJI1WMBAABwBgQQeAbzhofyf77xgnzox7bmvkcP5U3/5frc4FwQAACAviWAwLN4w8Vrc+3/fFVWdJp550duyu99YZsbYgAAAPqQAALP4fxVC/PX778yb7xkXf7vz92b9/7ZLTl45HjVYwEAAHAKBBCYgU6rkd99x+b8+psvyBfv3Zs3/5frc9fug1WPBQAAwAwJIDBDRVHk3Veem7/42cszPjGZH/7wjfnqg49XPRYAAAAzIIDAKXrxxuX5m1+4KmctmZ93//HNuUUEAQAAqD0BBE7D6sXz84n3XJ41S+bnXSIIAABA7QkgcJqeiiCLT0SQW3eIIAAAAHUlgMAZWL14fj7+3hMR5Cc+IoIAAADUlQACZ2jNdARZvXh+3vXHX82tOw5UPRIAAADfRQCBWbBm8fx8/D2XZ9Wi1vTrMCIIAABAnQggMEvOWnIigqxc2My7/vjm3LZTBAEAAKgLAQRm0VlLTrwOs2JhMz/xEREEAACgLgQQmGVrlyzIJ6YjyLs+cnPu2PVE1SMBAADMeQIIdMHaJQvy8fdcnmWdE6/DfHPPk1WPBAAAMKcJINAl65YuyJ//zMsyf95QfvyPbs6D+0arHgkAAGDOEkCgizYsb+e//fTLMjk1lR/7o5uy+4kjVY8EAAAwJwkg0GXPW7Mof/pTL8uTR47nxz9yU/YdHq96JAAAgDlHAIEeuPjsJfnIu1+a3U8cyU985OYcPHK86pEAAADmFAEEeuSyc5fnwz/+4tz32KH89Ee/mrFjE1WPBAAAMGcIINBD3/eC1fngj2zJbTsP5Gf/7NaMT0xWPRIAAMCcIIBAj73xkrX5T2+/JF++b19+8eN3ZGJyquqRAAAABp4AAhX4ty/dkF990wX5h7v25N//1dczNVVWPRIAAMBAa1Q9AMxVP33VuTl09Hg++E/3Zf68ofxfb74wzYYmCQAA0A0CCFToF1/9vBw5Npnf/9L9ueXBA/nPP3RJLt2wtOqxAAAABo7/uxkqVBRFfuUNL8ofv/slOXjkeN72oRvyH/7+nhw97nBUAACA2SSAQA18/wvX5PO/9Mr8yEtH8gdfuj+v/+CXctP9+6seCwAAYGAIIFATi+fPy398+8X57z/zskyWZX7kD/4lv/rX38jh8YmqRwMAAOh7AgjUzBWbVuZzH3hlfurKc/PfbtqR1/72dfnivY9VPRYAAEBfE0CghtrNRn7tzRfkk++7Iu1WI+/+k6/ml//yTtsgAAAAp0kAgRp78cZl+bv/5ar8wqs25VO3P5QPf3F71SMBAAD0JQEEaq7VGM7/+roX5OXnrcg/3LWn6nEAAAD6kgACfeK1F6zJtscOZ/vew1WPAgAA0HcEEOgTr73wrCTJ52yBAAAAnDIBBPrEuqULcsnZS/L5ux6tehQAAIC+I4BAH3ntBWtyx64nsufg0apHAQAA6CsCCPSR102/BvOP99gCAQAAOBUCCPSRTasX5tyVnXzeOSAAAACnRACBPlIURV574ZrcuH1/Do4dr3ocAACAviGAQJ953YVnZWKqzBfufazqUQAAAPqGAAJ9ZvPZS7N6Uct1uAAAAKdAAIE+MzRU5DUXrMl139qbo8cnqx4HAACgLwgg0Ided+FZGTs2mevv21f1KAAAAH1BAIE+dPl5K7JofsNrMAAAADMkgEAfajaG8v0vXJ1/uufRTExOVT0OAABA7Qkg0Kded+FZOTB2PLfsOFD1KAAAALUngECfuvr5q9JsDHkNBgAAYAYEEOhTnVYjr9i0Mp+/69GUZTnjz01NlfnYVx7MrsfHujgdAMD/z959h1ddHX4c/5x7b9bNngRIGGHvdZHlQKviqlvcgnugtrWttWpra1tH67YOHOCo27r3BgUEAsgeYQlhZofs5N7v7w9SfyArhCQn9+b9ep773Mv5jnzuP5rnk/M9BwBaFwoQIIiN65euTcWVWrq5tMHXPP7Nat3x3lLd+vbiZkwGAAAAAK0LBQgQxH7RJ00uI322bFuDzp+xOl8PfL5K7eMj9W1OvrLXFzZzQgAAAABoHShAgCCWHBMhX5ckfdaAdUC2llTpxlcWqFtqjN6/4XClxITrwS9WtUBKAAAAALCPAgQIcuP6pWvF1h36saB8n+fU+gO6/uX5qqz164mLhiolJkLXHNVNM1YXaPbaghZMCwAAAAB2UIAAQe74vu0kSZ8t3fdjMP/8ZIWyfyzSPWcNVPe0WEnShSM6KzU2glkgAAAAANoEChAgyGUmedW3fdw+t8P9ZMkWPf3tOl0yqrNOHdThp/GocLeuPaqbvl9bqJlr8lsqLgAAAABYQQEChIDj+7XTvA1FyttRvdv4+vxy/f6NRRqUEa/bTu6zx3UXjOiktNgIPfR5zkFtpQsAAAAAwYYCBAgB4/qly3GkL5b//2MwVbV+XfvSfLlcRo9dOFQRHvce10WGuTXp6O6as75QM9ewFggAAACA0EUBAoSA3umx6pTk3e0xmDveXarlW0r10LmDlZHo3ee15w7PVHpcpB78fBWzQAAAAACELAoQIAQYY3R833aaubpAO6pq9Xr2Rr2WvVE3HNNdR/dO2++1kWFuTTqmu7J/LNK3OawFAgAAACA0UYAAIWJc/3TV+AN6ctoa/emdJRrdLVm/PrZng64d78tQh/hIPfgFs0AAAAAAhCYKECBEDO2UqJSYcD329RoleMP0yPlD5HaZBl0b4dk5C2TBhmJ9syqvmZMCAAAAQMujAAFChNtldFzfdLldRv++YKhSYiIO6vpzhmWqY0KUHmItEAAAAAAhiAIECCG3nNhb719/uIZ3STroa8M9Lt1wTHctzC3R1yu3N0M6AAAAALCHAgQIIfFRYerbIa7R1581LEOZSVF68PMcZoEAAAAACCkUIAB+EuZ26YZjemjxphJ9sZxZIAAAAABCBwUIgN2cOaSjOid79SBrgQAAAAAIIRQgAHbjcbt04zE9tGxLqT5dus12HAAAAABoEhQgAPZw2uAO6poSrQc+X6mqWr/tOAAAAABwyChAAOzB43bptpP6aNW2Mt385iIehQEAAAAQ9ChAAOzVsX3b6ffjeum9hZv10Bc5tuMAAAAAwCHx2A4AoPW6bmw3rc0r18Nf5igrNVqnDe5oOxIAAAAANAozQADskzFGd585QCO6Jun3byzSvB8LbUcCAAAAgEahAAGwX+Eel568aJg6JkbpqhfmaUNBhe1IAAAAAHDQKEAAHFBidLieneBTXcDRZc/PVUllre1IAAAAAHBQKEAANEhWaoyevGiY1ueX6/qX56vWH7AdCQAAAAAajAIEQION6pasu84coG9z8vWX95ayPS4AAACAoMEuMAAOynhfptbmlevJaWuUlRqjyw/vajsSAAAAABwQBQiAg3bzuF5an1+uv3+4TJ2TvDq2bzvbkQAAAABgv3gEBsBBc7mMHjx3sAZ0jNeNry7Qotxi25EAAAAAYL8oQAA0SlS4W89c4lOiN1wXPD1bs9YU2I4EAAAAAPtEAQKg0dLiIvXmtaPUISFSE6bM0SdLttiOBAAAAAB7RQEC4JC0j4/S61ePUv+Ocbrupfl6efYG25EAAAAAYA8UIAAOWYI3XC9dMVJH9UzVrW8v1qNf5rBFLgAAAIBWhQIEQJOICnfrqUt8OnNIR93/+Sr99f1lCgQoQQAAAAC0DmyDC6DJhLlduu+cQUqKDtcz361TQXmN7j9nkMI9dK0AAAAA7KIAAdCkXC6j207uo5TYCN3z8QoVV9ToyYuGKTqC/9wAAAAAsIc/ywJocsYYXXNUN/3z7IGasTpfFzwzW4XlNbZjAQAAAGjDKEAANJvxvkxNvtinFVtKdfpjM/Tx4i0sjgoAAADACgoQAM3quL7t9NIVIxTucenal+brtMdmaMbqfNuxAAAAALQxFCAAmp2vS5I+/fWR+tfZA5W/o1oXPjNbFz7zvRZuLLYdDQAAAEAbccACxBgzxRiz3RizZJexvxhjNhljfqh/nbTLsT8aY1YbY1YaY8btMj7MGLO4/tgjxhhTPx5hjHmtfny2MaZL035FAK2B22V0ji9TX/1urP50Sl8t37JDpz02Q9f+Z55Wby+zHQ8AAABAiGvIDJDnJJ2wl/EHHccZXP/6SJKMMX0lnSepX/01jxtj3PXnPyHpKkk96l//u+flkoocx+ku6UFJ9zbyuwAIApFhbl1+eFdN+/1Y/eoXPTR9VZ6Of3Ca/vDmIm0urrQdDwAAAECIOmAB4jjOdEmFDbzfaZJedRyn2nGcdZJWSzrMGNNeUpzjOLOcnSsgviDp9F2ueb7+85uSfvG/2SEAQldsZJh+c1xPTb/5aE0c3VVvL9iksfd9ow8XbbEdDQAAAEAIOpQ1QK43xiyqf0QmsX6so6SNu5yTWz/Wsf7zz8d3u8ZxnDpJJZKS9/YDjTFXGWOyjTHZeXl5hxAdQGuRHBOhP/+yr7763VHqkx6r295ZrPyyatuxAAAAAISYxhYgT0jqJmmwpC2S7q8f39vMDWc/4/u7Zs9Bx3nKcRyf4zi+1NTUg0sMoFXLSPTqvnMGqby6Tn//YJntOAAAAABCTKMKEMdxtjmO43ccJyDpaUmH1R/KlZS5y6kZkjbXj2fsZXy3a4wxHknxavgjNwBCSI92sbp2bHe988NmTVvFLC8AAAAATadRBUj9mh7/c4ak/+0Q856k8+p3dumqnYudznEcZ4ukHcaYkfXre1wi6d1drplQ//lsSV/VrxMCoA2adHQ3ZaVG67a3F6uips52HAAAAAAhoiHb4L4iaZakXsaYXGPM5ZL+Wb+l7SJJR0v6jSQ5jrNU0uuSlkn6RNIkx3H89be6VtIz2rkw6hpJH9ePPysp2RizWtJNkm5pqi8HIPhEeNy6+4wByi2q1ENf5NiOAwAAACBEmGCdbOHz+Zzs7GzbMQA0kz++tUivzd2o964/XP07xtuOAwAAACAIGGPmOY7j29uxQ9kFBgCazS0n9lFyTIRueWuR6vwB23EAAAAABDkKEACtUnxUmP7yy35asqlUz81cbzsOAAAAgCBHAQKg1TppQLp+0TtN93+2ShsLK2zHAQAAABDEKEAAtFrGGP3t9P5yGen2d5YoWNcsAgAAAGAfBQiAVq1DQpR+N66Xpq3K03sLN9uOAwAAACBIUYAAaPUuGdVFgzITdOf7y1RcUWM7DgAAAIAgRAECoNVzu4zuOXOASipr9Y8Pl9uOAwAAACAIUYAACAp92sfpyiOz9Ma8XM1cnW87DgAAAIAgQwECIGj86hc91DnZq1veWqzCch6FAQAAANBwFCAAgkZkmFsPjB+kbaVVumTKbJVW1dqOBAAAACBIUIAACCrDOifpyYuGaeXWHbps6lxV1NTZjgQAAAAgCFCAAAg6R/dO00PnDtH8DUW6+sV5qq7z244EAAAAoJWjAAEQlE4e2F73nDVQ3+bk68ZXFqjOH7AdCQAAAEArRgECIGiN92Xqjl/21adLt+n3by5SIODYjgQAAACglfLYDgAAh+LSMV1VXl2n+z5bpegIt/52Wn8ZY2zHAgAAANDKUIAACHqTju6usmq/npy2RtERHt1yQm9KEAAAAAC7oQABEPSMMfrDCb1UVl2rydPWKjbCo+uP6WE7FgAAAIBWhAIEQEgwxujOU/urotpf/ziMR5eO6brfa/wBR0aSy8VsEQAAACDUUYAACBkul9E/zx6o8po6/fX9ZXrx+x9V53dU5w+oxu+oLhBQnd9RjT+gOn9AAUfqEB+p/1wxQlmpMbbjAwAAAGhGxnGCc9cEn8/nZGdn244BoBWqrvPrvk9XanNxlcLcRh63S2Ful8LcRmFulzxuozCXS26X0Yvf/yhvuFtvXTtaaXGRtqMDAAAAOATGmHmO4/j2eowCBEBbtnBjsc5/+nt1SvLq9WtGKS4yzHYkAAAAAI20vwLE1dJhAKA1GZSZoMkXD9OavDJd+Xy2qmr9tiMBAAAAaAYUIADavCN6pOq+cwZp9rpC/erVBfIHgnNmHAAAAIB9owABAEmnDe6oO37ZV58u3abb31miYH08EAAAAMDesQsMANS7dExX5e2o1uPfrFFabIR+c1xP25EAAAAANBEKEADYxe/H9VJ+WbUe/jJHKbERunhkZ9uRAAAAADQBChAA2IUxRnedMUCF5TX687tLlBwdrpMGtLcdCwAAAMAhYg0QAPgZj9ulR88fqmGdEvXrV3/QzDX5tiMBAAAAOEQUIACwF1Hhbj07Ybi6pHh11QvztHxLqe1IAAAAAA4BBQgA7EO8N0wvXDZCER6X7v54he04AAAAAA4BBQgA7Ed6fKQuO7yrpq/KYxYIAAAAEMQoQADgAC4c0UnecLee/nat7SgAAAAAGokCBAAOIMEbrvG+TL33w2ZtKam0HQcAAABAI1CAAEADXH54VwUcR8/NWG87CgAAAIBGoAABgAbITPLqpAHt9fLsDdpRVWs7DgAAAICDRAECAA101ZFZ2lFdp9fmbrQdBQAAAMBBogABgAYamJGgkVlJmvLdOtX6A7bjAAAAADgIFCAAcBCuOjJLm0uq9OGiLbajAAAAADgIFCAAcBDG9kxTj7QYTZ6+Vo7j2I4DAAAAoIEoQADgILhcRlcekaXlW0o1Y3WB7TgAAAAAGogCBAAO0mlDOig1NkKTp6+xHQUAAABAA1GAAMBBivC4NXF0F32bk6/lW0ptxwEAAADQABQgANAIF43oLG+4W09PX2s7CgAAAIAGoAABgEaI94bp3OGZem/hZm0pqbQdBwAAAMABUIAAQCNdNqarHElTZ6y3HQUAAADAAVCAAEAjZSZ5ddKA9np59gaVVtXajgMAAABgPyhAAOAQXHVElsqq6/TanI22owAAAADYDwoQADgEAzLiNSorWVNmrFOtP2A7DgAAAIB9oAABgEN01VFZ2lJSpQ8WbbYdBQAAAMA+eGwHAIBgN7Znqnq2i9HDX+TI43LpyB6piveG2Y4FAAAAYBcUIABwiIwxuvWkPvrVqz/ohlcWyGWkIZ0SNbZnqsb2SlO/DnFyuYztmAAAAECbZhzHsZ2hUXw+n5OdnW07BgD8xB9w9MPGYk1buV3frMrTotwSSVJKTISO7Jmio3ul6YgeKUrwhltOCgAAAIQmY8w8x3F8ez1GAQIAzSNvR7W+zcnTNyvzND0nT8UVtXIZ6daT+uiKI7JsxwMAAABCzv4KEB6BAYBmkhoboTOHZujMoRnyBxwtzC3Wv79arbs/XqHBmQnydUmyHREAAABoM9gFBgBagNtlNLRToh4+b7AyEqN04ysLVFReYzsWAAAA0GZQgABAC4qNDNOj5w9RXlm1fv/mIgXrY4gAAABAsKEAAYAWNjAjQbec2EdfLN+mqTPW244DAAAAtAkUIABgwWVjuujYPmm6++PlWly/WwwAAACA5kMBAgAWGGP0r7MHKSUmQte/Ml87qmptRwIAAABCGgUIAFiSGB2uR84fotyiSt329hLWAwEAAACaEQUIAFg0vEuSfnNsD723cLNez95oOw4AAAAQsihAAMCyFl2DZAAAIABJREFUa8d215juybrjvaVatW2H7TgAAABASKIAAQDL3C6jB88drJgIj65/eb4qa/y2IwEAAAAhhwIEAFqBtNhIPTB+sFZtK9OdHyy1HQcAAAAIOR7bAQAAOx3ZM1XXju2mJ75ZoyGZiRrcKUHFFbUqqqhRSUWtiitrVFxRq+LKWpVU1Kq0qlZnDOmoM4dm2I4OAAAAtHoUIADQitx0XE/NXlugm/+7aK/HPS6jBG+4ErxhqvMHdNPrC7Vy6w7dfEJvuV2mhdMCAAAAwYMCBABakTC3S1MmDtdny7YpOtyjBG+Y4qPClOANU4I3XNHhbhmzs+io9Qf01/eXavL0tVqbX66Hzh2s6Aj+sw4AAADsjXEcx3aGRvH5fE52drbtGABgleM4en7met35wTL1So/TsxN86pAQZTsWAAAAYIUxZp7jOL69HWMRVAAIYsYYTRzTVVMmDtfGwgqd9tgM/bCx2HYsAAAAoNWhAAGAEDC2V5reum60IsNcOnfyLH2waLPtSAAAAECrQgECACGiZ7tYvXPdGA3oGK/rX16gR77MUbA+5ggAAAA0NQoQAAghyTEReunKETpzaEc98Pkq/fq1H1RV67cdCwAAALCO7QIAIMREeNy6/5xB6pYao399ulIbCys0ZeJwJXjDbUcDAAAArGEGCACEIGOMJh3dXU9cOFRLNpfqvKe+V96OatuxAAAAAGsoQAAghJ04oL2mThyuHwsqNH7yLG0qrrQdCQAAALCCAgQAQtyY7in6zxWHKb+sWuOfnKX1+eW2IwEAAAAtjgIEANqAYZ2T9MqVI1VZ69c5k2dp5dYdtiMBAAAALYoCBADaiP4d4/XaVSPlMtK5T83Sotxi25EAAACAFkMBAgBtSI92sXrj6tGKifDogqdna866QtuRAAAAgBZBAQIAbUynZK/evGa02sVF6JIpszVtVZ7tSAAAAECzowABgDYoPT5Sr109SlkpMbry+Wx9smSr7UgAAABAs6IAAYA2KiUmQq9cNVL9O8Zp0svz9Ub2RtuRAAAAgGZDAQIAbVh8VJhevHyERmUl6/dvLtLDX+TIcRzbsQAAAIAmRwECAG1cdIRHUyYO11lDM/TgF6t085uLVOsP2I4FAAAANCmP7QAAAPvCPS7dd85AZSRG6eEvc7S1tEqPXzhUsZFhtqMBAAAATYIZIAAASZIxRr85rqf+efZAzVpToHOenKWtJVW2YwEAAABNggIEALCb8b5MTb10uHKLKnXG4zO0Ymup7UgAAADAIaMAAQDs4YgeqXrjmlFyHOmcJ2bpu5x825EAAACAQ0IBAgDYqz7t4/T2pNHqmBiliVPnsE0uAAAAghoFCABgn9rHR+n1a0ZpZP02uY98mWM7EgAAANAoFCAAgP2KiwzT1EuH68whHfXA56s0a02B7UgAAADAQaMAAQAcUJjbpbvOHKAO8ZG6++PlCgQc25EAAACAg0IBAgBokMgwt357fC8tyi3RB4u32I4DAAAAHBQKEABAg50xpKP6tI/TPz9Zoeo6v+04AAAAQINRgAAAGszlMrr1pN7KLarUi7N+tB0HAAAAaDAKEADAQTmiR6qO7JmqR79arZKKWttxAAAAgAahAAEAHLQ/nthbpVW1evyb1bajAAAAAA1CAQIAOGh92sfprKEZmjpzvXKLKmzHAQAAAA6IAgQA0Ci/Pb6njKT7P1tlOwoAAABwQBQgAIBGaR8fpcsP76q3F2zSkk0ltuMAAAAA+0UBAgBotGvGdlNSdLju+mi5HMexHQcAAADYJwoQAECjxUWG6cZjumvmmgJNW5VnOw4AAACwTxQgAIBDcsGIzuqS7NXdH62QP8AsEAAAALROFCAAgEMS7nHp5hN6a+W2Hfrv/FzbcQAAAIC9ogABAByyE/una0inBN3/2UpV1vhtxwEAAAD2QAECADhkxhjdelIfbSut1pQZ62zHAQAAAPZAAQIAaBLDuyTp+L7t9MQ3a7Quv1ylVbWqrvOzOwwAAABaBY/tAACA0PGHE3vr+Aen6+j7vtltPMLjUrjHpQiPWxEelyLCXGofH6k/ndJXvdPj7IQFAABAm2KC9S9zPp/Pyc7Oth0DAPAzCzYUacmmElXXBXa+av2q9gdUXVv/7zq/auoC+n5tgUqr6nTLCb01cXQXuVzGdnQAAAAEOWPMPMdxfHs7xgwQAECTGtIpUUM6JR7wvPyyat3y30W684Nl+nrldt1/ziClxUW2QEIAAAC0RawBAgCwIiUmQk9f4tM/zuivuesLNe6h6fp06VbbsQAAABCiKEAAANYYY3ThiM764IYj1DExSle/OE9/fGuRKmrqbEcDAABAiKEAAQBY1z0tRm9dO0bXju2mV+du1MmPfKeFG4ttxwIAAEAIoQABALQK4R6X/nBCb71y5UhV1/p11hMz9e+vcuQPBOdi3QAAAGhdKEAAAK3KyKxkffzrI3XSgPa677NV+vVrPyhYdywDAABA68EuMACAVic+KkyPnD9EvdJj9a9PV6prSrRuOq6n7VgAAAAIYhQgAIBW67qx3fRjQbke+TJHWSnROn1IR9uRAAAAEKR4BAYA0GoZY/T30wdoZFaSbn5zkbLXF9qOBAAAgCBFAQIAaNXCPS49edGwn7bJ3VhYYTsSAAAAghAFCACg1UvwhuvZCT7VBRxd9txclVbV2o4EAACAIEMBAgAIClmpMXrioqFal1+uSS/NV50/YDsSAAAAgggFCAAgaIzulqJ/nNFf3+bk66/vL2N7XAAAADQYu8AAAILKucM7aW1euSZPX6us1GhdOqar7UgAAAAIAhQgAICg84cTemtdfrn+9sEydU726pje7WxHAgAAQCvHIzAAgKDjchk9dN5g9WkfpxteXqAVW0ttRwIAAEArRwECAAhK3nCPnp0wXDGRHl3+XLa2l1bZjgQAAIBWjAIEABC00uMj9eyE4Sosr9Hlz2eroqbOdiQAAAC0UhQgAICg1r9jvB49f4iWbi7Rja8skD/AzjAAAADYEwUIACDoHdu3nf5yaj99sXy77nx/KdvjAgAAYA/sAgMACAmXjOqiDQUVeua7deqUHK3LD2d7XAAAAPw/ChAAQMi49aQ+yi2q1N8/XKaOCVE6oX+67UgAAABoJXgEBgAQMlwuowfPHaxBGQn69WsLtGBDke1IAAAAaCUoQAAAISUq3K1nJviUGhuhK57P1oaCCtuRAAAA0ApQgAAAQk5KTISmTjxMdQFHE5+bo+KKGtuRAAAAYBkFCAAgJHVPi9FTFw9TbmGlrn5xnqrr/LYjAQAAwCIKEABAyBqRlax/nTNQs9cV6g9vLmJ7XAAAgDaMXWAAACHttMEdtbGwQvd9tkrzNxQrNTZCSdHhSo4OV1L9KzkmXEnREUqODldGYpQSvOG2YwMAAKCJUYAAAELepKO7Kyrco/kbilRYVqMNBRVasKFYRRU18gd2nxUSGebSS1eM0LDOSZbSAgAAoDmYYJ0O7PP5nOzsbNsxAABBzHEclVbWqaC8WoXlNSoor9FdHy1XebVf710/Rh0SomxHBAAAwEEwxsxzHMe3t2OsAQIAaLOMMYr3hikrNUa+Lkka1y9dz1ziU1WtX1e+kK3KGhZOBQAACBUUIAAA7KJHu1g9ev4QLdtSqt+9uZCFUwEAAEIEBQgAAD9zdO803XJCb324aIse/Wq17TgAAABoAiyCCgDAXlx1ZJZWbt2hBz5fpZ7tYnRC//a2IwEAAOAQMAMEAIC9MMborjMHaHBmgn7z2kIt21xqOxIAAAAOAQUIAAD7EBnm1lMXD1N8VJiufCFb+WXVtiMBAACgkShAAADYj7S4SD11yTDll1Xruv/MV01dwHYkAAAANAIFCAAABzAwI0H/PHug5qwv1J/fXcLOMAAAAEGIRVABAGiA0wZ31KptO/TY12vUOz1WE8d0tR0JAAAAB4ECBACABvrtcb20aluZ/vbhchWU16hv+zh1S4tR52SvIjxu2/EAAACwHxQgAAA0kMtl9OC5g3XZc3P16Ferfxp3u4w6JXnVLTVa3VJj1C0tRt1SY9SzXYxiI8MsJgYAAMD/UIAAAHAQYiI8ev3qUaqoqdPavHKtySvT6u1lWpNXpjXbyzV9Vb5q/DsXSo2N9OidSWPULTXGcmoAAABQgAAA0AjecI/6d4xX/47xu43X+QPKLarUqm079Ns3Fuq2txfrlStHyhhjKSkAAAAkdoEBAKBJedwudUmJ1vH90vXHE/vo+7WFemNeru1YAAAAbR4FCAAAzeS84ZnydU7UPz5crvyyattxAAAA2jQKEAAAmonLZXT3mQNUUVOnv32wzHYcAACANo0CBACAZtSjXayuHdtd7/6wWdNW5dmOAwAA0GZRgAAA0MyuG9tNWSnRuu3txaqoqbMdBwAAoE2iAAEAoJlFhrl115kDlFtUqYe/yLEdBwAAoE2iAAEAoAWMzErWub5MPfPdOi3dXGI7DgAAQJtDAQIAQAv540m9legN0x/fWix/wLEdBwAAoE2hAAEAoIUkeMP1p1P6alFuiZ6fud52HAAAgDaFAgQAgBZ06qAOOqpnqu77bKU2FVfajgMAANBmUIAAANCCjDH6++n9FXAc3fHuEjkOj8IAAAC0BAoQAABaWGaSVzcd11NfLN+uT5ZstR0HAACgTaAAAQDAgsvGdFXf9nG6472lKqmstR0HAAAg5HlsBwAAoC3yuF2656wBOv2xGTr83q/UPS1G3VNj1K3+vXtajDKTvHK7jO2oAAAAIYECBAAASwZmJOiZCT59tWK7Vm8v09cr8/TGvNyfjoe7XeqaEq3uaTHq3zFeF4/qrJgI/tcNAADQGCZYF1/z+XxOdna27RgAADSpkoparc4r05rtZbu9/1hQoXZxEfrzKf100oB0GcPMEAAAgJ8zxsxzHMe3t2P8GQkAgFYk3humYZ0TNaxz4m7j8zcU6fa3l2jSy/N1ZM9U3XlqP3VJibaUEgAAIPiwCCoAAEFgaKdEvXf9GN3xy76a/2ORjn9ouh78fJWqav22owEAAAQFChAAAIKEx+3SpWO66qvfHqVx/dL18Jc5GvfQdH2zcrvtaAAAAK0eBQgAAEEmLS5Sj54/RP+5fITcxmji1Lm67qV52lJSaTsaAABAq8UiqAAABLHqOr+enr5Wj361Wm6X0dheqUqKDldSdISSvGFKiolQcnS4Er3hSo7Z+R7u4e8fAAAgNLEIKgAAISrC49b1x/TQaYM76t5PVmj5llIVlteouLJW+/obR0ZilJ662Ke+HeJaNiwAAIBFzAABACAE+QOOiitqVFj+/6+C8hoVldfo5TkbVF0X0GtXjVSPdrG2owIAADQZZoAAANDGuF1GyTERSo6J2OPYKYM6aPzkWbrgmdl67aqRykqNsZAQAACgZfEQMAAAbUzXlGi9fMUIBQKOLnh6tjYUVNiOBAAA0OwoQAAAaIN6tIvVf64Yoao6v85/+nttKmYHGQAAENooQAAAaKP6tI/Ti5eNUGlVrS54+nttK62yHQkAAKDZUIAAANCGDciI1/OXHab8HdW64Onvlbej2nYkAACAZkEBAgBAGze0U6KmXnqYNhdX6aJnZquwvMZ2JAAAgCZHAQIAAHRY1yQ9O8Gn9QXluvjZ2SqpqLUdCQAAoElRgAAAAEnS6O4pmnzxMOVsK9MlU+doRxUlCAAACB0UIAAA4Cdje6XpsQuHaummEv3ujYW24wAAADQZChAAALCb4/q2003H99SnS7fpy+XbbMcBAABoEhQgAABgD1ccnqUeaTG6472lqqzx244DAABwyChAAADAHsI9Lv399P7KLarUo1/l2I4DAABwyChAAADAXo3IStZZQzP01PS1ytm2w3YcAACAQ0IBAgAA9unWk3orOsKj299ZIsdxbMcBAABoNAoQAACwT8kxEbrlxN6ava5Qb83fZDsOAABAo1GAAACA/TrXl6mhnRL0j4+Wq7iixnYcAACARqEAAQAA++VyGf399AEqqazVvZ+stB0HAACgUShAAADAAfXtEKdLR3fRK3M2aN6PRbbjAAAAHDQKEAAA0CC/Pq6n0uMidfs7S1TnD9iOAwAAcFAoQAAAQIPERHj0l1P7avmWUj03c73tOAAAAAeFAgQAADTYuH7pOrpXqh78fJW2lFTajgMAANBgFCAAAKDBjDH666n9VRdwdOf7y2zHAQAAaDAKEAAAcFA6JXt14y966OMlW/X1yu224wAAADQIBQgAADhoVx6RpW6p0brtrcV6bsY6rdhaqkDAsR0LAABgnzy2AwAAgOAT7nHpX+cM0q9eXaC/1D8KkxQdrhFdkzQyK1kjs5LVIy1GLpexnBQAAGAn4zjB+dcan8/nZGdn244BAECbt7GwQt+vLdD3awv1/doCbSreuTjqroXI8f3aqX18lOWkAAAg1Blj5jmO49vrMQoQAADQlPZWiIS5jc4elqFrjuqmzsnRtiMCAIAQRQECAACsWZdfrinfrdNr2RtV5w/o1EEdNOno7urRLtZ2NAAAEGIoQAAAgHXbS6v09Ldr9dLsDaqo8euEfum6/pju6t8x3nY0AAAQIihAAABAq1FUXqOpM9Zp6sz12lFVp7G9UnX90d3l65JkOxoAAAhyFCAAAKDVKa2q1YuzftSz361TYXmNRndL1qPnD1FyTITtaAAAIEjtrwBxtXQYAAAASYqLDNOko7vruz8crdtP7qN5Pxbp4mfnqKSi1nY0AAAQgihAAACAVd5wj644IkuTLx6mnO07NGHqHJVV19mOBQAAQgwFCAAAaBXG9krTvy8YqsWbSnT5c3NVWeNv1H02Flbo6elrVVxR08QJAQBAMKMAAQAArca4ful6YPwgzVlfqKv/M0/VdQ0vQRzH0X/n5erEh7/VPz5arl/cP01vzc9VsK53BgAAmhYFCAAAaFVOG9xR9545UNNX5en6lxeo1h844DUlFbW64ZUF+u0bC9W3fZymXjpcmUle3fT6Ql3w9GytyStrgeQAAKA1YxcYAADQKj0/c73ueG+pfjmogx46d7DcLrPX82atKdBvX/9B23dU6zfH9dQ1R3WT22UUCDh6ec4G3fvJClXXBnTNUVm67ujuigxzt/A3AQAALWV/u8B4WjoMAABAQ0wY3UUVNX7d+8kKRYW5dM+ZA+XapQSpqQvogc9XafL0NeqSHK23rhutgRkJPx13uYwuGtlZ4/ql6x8fLtMjX63Wuws362+n9deRPVNtfCUAAGARBQgAAGi1rh3bTZU1dXrkq9WKCnPrL6f2kzFGq7eX6devLdCSTaU6/7BM/emUvvKG7/3XmtTYCD103hCd48vU7e8s0SVT5uiUge3151P6Ki0usoW/EQAAsIUCBAAAtGq/Oa6nKmr8eua7dYoK9ygzKUp/+2CZosLcmnzxMI3rl96g+4zpnqKPf3WEJk9bq8e+Wa1pK/N0eI8UBRxH/oDq353d3gMBKcEbpr+d3l/tKEsAAAhqrAECAABaPcdxdPs7S/TS7A2SpCN6pOj+cwY1egbHuvxy3fXRcq3LL5fbGLlcRm6XfvrsMqb+s7Qot0SZiV69fvUoxXvDmvJrAQCAJra/NUAoQAAAQFAIBBw99GWOUmPCdeGIzrutB9KcZq7O18SpczUwI14vXj5CUeEsogoAQGu1vwKEbXABAEBQcLmMbjqupy4e1aXFyg9JGt09RQ+dN1jzNhRp0svzG7QtLwAAaH0oQAAAAA7gpAHt9ffT++urFdv1h/8uUiAQnDNoAQBoy1gEFQAAoAEuHNFZhWU1uv/zVUryhuu2k/vImJabiQIAAA4NBQgAAEADXX9MdxWU1+iZ79YpJTZC1xzVzXYkAADQQBQgAAAADWSM0Z9P6avC8hrd8/EKJXnDNX54pu1YAACgAShAAAAADoLLZXTfOYNUXFmrW95apHhvmMb1S7cdCwAAHACLoAIAABykcI9LT140VAMzEnTDKws0e22B7UgAAOAADliAGGOmGGO2G2OW7DKWZIz53BiTU/+euMuxPxpjVhtjVhpjxu0yPswYs7j+2COmftUwY0yEMea1+vHZxpguTfsVAQAAmp433KOpE4erU5JXVzyfraWbS2xHAgAA+9GQGSDPSTrhZ2O3SPrScZwekr6s/7eMMX0lnSepX/01jxtj3PXXPCHpKkk96l//u+flkoocx+ku6UFJ9zb2ywAAALSkxOhwvXDZYYqN9Gji1LnaWFhhOxIAANiHAxYgjuNMl1T4s+HTJD1f//l5SafvMv6q4zjVjuOsk7Ra0mHGmPaS4hzHmeU4jiPphZ9d8797vSnpF4Y95QAAQJDokBCl5y87TDV1AV0yZY4KyqptRwIAAHvR2DVA2jmOs0WS6t/T6sc7Stq4y3m59WMd6z//fHy3axzHqZNUIil5bz/UGHOVMSbbGJOdl5fXyOgAAABNq0e7WE2Z6NPm4kpd9txclVfX2Y4EAAB+pqkXQd3bzA1nP+P7u2bPQcd5ynEcn+M4vtTU1EZGBAAAaHrDOifp3xcM1eJNJZr08nzV+gO2IwEAgF00tgDZVv9Yi+rft9eP50rK3OW8DEmb68cz9jK+2zXGGI+keO35yA0AAECrd1zfdvrHGQP0zco83fLfxdr55C8AAGgNGluAvCdpQv3nCZLe3WX8vPqdXbpq52Knc+ofk9lhjBlZv77HJT+75n/3OlvSVw6/LQAAgCB1/mGd9Jtje+q/83P1r09X2o4DAADqeQ50gjHmFUljJaUYY3Il3SHpHkmvG2Mul7RB0jmS5DjOUmPM65KWSaqTNMlxHH/9ra7Vzh1loiR9XP+SpGclvWiMWa2dMz/Oa5JvBgAAYMmNv+iubTuq9Pg3a5QWG6GJY7o2+c8or65TdMQBf5UDAAD1TLBOtvD5fE52drbtGAAAAHvlDzi69j/z9PnybXr0/CE6ZWCHQ75nIODoi+XbNHn6Wi3cWKxnJw7XUT1ZFw0AgP8xxsxzHMe3t2NNvQgqAAAAJLldRo+cP0S+zom66bWFmrkmv9H3qq7z69U5G3Tsg9N01YvztK20SplJXv3q1QXKLapowtQAAIQuChAAAIBmEhnm1jOXDFeXFK+ufmGelm0uPajrSypr9fg3q3X4vV/rlrcWKyrMrUfOH6JvfjdWUyYOl9/v6LqX5quq1n/gmwEA0MbxCAwAAEAz21xcqbOemKnKWr98nRPVPj5K7RMi1T4+Uu3jo9QhPkrt4iMU4XFLkraUVGrKd+v08uwNKq/x64geKbr6yG4a0z1ZO9eT3+nTpVt19YvzdMGITrrrjAG2vh4AAK3G/h6BYeUsAACAZtYhIUovXn6Y7v1kpTYWVmju+iKVVNbucV5KTITaxUVo5dYdciSdMrC9rjwiS/07xu/1vuP6peuao7rpyWlrNLRTos4eltHM3wQAgODFDBAAAAALyqvrtKWkSltLqrS5pFJbiqu0paRSW0qqlJUarcvGdFVmkveA96nzB3Txs3M0f0OR3rputPp12HtZAgBAW7C/GSAUIAAAAEEuv6xaJz/yrSI8br1//eGK94bZjgQAgBXsAgMAABDCUmIi9PiFQ7W5uFK/feMHBQLB+QcuAACaEwUIAABACBjWOUm3n9xHXyzfriemrbEdBwCAVocCBAAAIERMGN1Fpw7qoPs/W6nvcvJtxwEAoFWhAAEAAAgRxhjdc9YAdU+L0Y2vLtDm4krbkQAAaDUoQAAAAEKIN9yjJy4appq6gK57ab6q6/y2IwEA0CpQgAAAAISYbqkx+tfZA/XDxmLd9PpCVdZQggAAQAECAAAQgk4c0F63nNhbHy3eotMfm6E1eWW2IwEAYBUFCAAAQIi65qhuev7Sw5RXVq1TH/1OHyzabDsSAADWUIAAAACEsCN7purDGw9Xr/RYXf/yAv3lvaWqqQvYjgUAQIujAAEAAAhx7eOj9NrVo3T54V313Mz1Gj95ljaxQwwAoI2hAAEAAGgDwtwu/emUvnriwqFavb1MJz/yrb5eud12LAAAWgwFCAAAQBty4oD2ev+Gw5UeF6lLp87V/Z+tlD/g2I4FAECz89gOAAAAgJbVNSVa70waoz+/u0SPfrVa3+bkq3OyV5U1flXVBVRV61d1rV+VtX5V1db/uy6g4/u20z1nDZTbZWx/BQAADhoFCAAAQBsUGebWP88eJF+XJD329WoVVdQo0uNWZJhLkWFuJXjDlV7/OSrMrfIav96Ylyu3y+juMwfIGEoQAEBwoQABAABow8b7MjXel9mgczsnefXvr1crwRuuW07s3czJAABoWhQgAAAAaJDfHt9TRRU1enLaGiV4w3TNUd1sRwIAoMEoQAAAANAgxhjdeVp/lVTW6p6PVyghKkznHdbJdiwAABqEAgQAAAAN5nYZPTB+sHZU1enWtxcrPipMJw5obzsWAAAHxDa4AAAAOCjhHpeeuGiohnRK1K9e/UHf5eTbjgQAwAFRgAAAAOCgecM9mjJhuLJSo3XVi9lasKHokO7nOI7Kquu0sbBCSzaV6NucPH29crtq6gJNlBgA0NYZx3FsZ2gUn8/nZGdn244BAADQpm0vrdLZT85SSWWt3rhmlHq2i93reYGAo7X5ZVq4sUSLN5VoU3GliitqVFxRq6KKWpVU1qjWv+fvpR3iI3Xt0d013pehCI+7ub8OACDIGWPmOY7j2+sxChAAAAAcig0FFTr7yZkyRnrzmtHKSIxSblGlFuYWa1FuiRZuLNbSzaUqq66TJHnD3eqU5FWCN0yJ3nAleMOU4A1XQtTu/y6prNWT09Zo3o9FSo+L1LVju+nc4ZmKDKMIAQDsHQUIAAAAmtWKraUa/+QshbldCjiOiipqJUnhbpf6dIjToIx4DegYr0GZCeqWGiO3yzTovo7jaOaaAj38RY7mrC9UWmyErjmqmy4Y0YkiBACwBwoQAAAANLv5G4r00Bc56hAfqQEZ8RqUkaCe7WImobvOAAAeSElEQVQV7jn0Zeccx9H3awv18Jer9P3aQqXEROiao7J0wYhO8oazsSEAYCcKEAAAAISM2WsL9MhXOZqxukDJ0eE6cUC6OiV5lZHoVWaiVxmJUUrwhsmYhs0yAQCEjv0VINTlAAAACCojspL1UlaystcX6rGvV+u9HzartKput3NiIjzKSIyqf3nVo12MxvsyFeZmE0QAaKsoQAAAABCUfF2SNPXSwyRJJZW1yi2qUG5RZf2rQhsLd75/v7ZQZdV1WrKpVHed0Z+ZIQDQRlGAAAAAIOjFR4UpPipe/TrE73HMcRz989OVeuKbNeqdHqsJo7u0fEAAgHXMAQQAAEBIM8bo98f30rF90nTnB8v0XU6+7UgAAAsoQAAAABDyXC6jh84bou6pMbrupXlal19uOxIAoIVRgAAAAKBNiInw6JkJPnncLl3+/FyVVNbajgQAaEEUIAAAAGgzMpO8euLCodpQUKEbXlmgOn/AdiQAQAuhAAEAAECbMiIrWX8/vb+mr8rTXR+tsB0HANBC2AUGAAAAbc55h3XSym07NGXGOvVKj9G5wzvZjgQAaGbMAAEAAECbdNtJfXREjxTd/s4SzVlX2KBr6vwBFZbXNHMyAEBzMI7j2M7QKD6fz8nOzrYdAwAAAEGspLJWZzw2Q8WVtXp30hhlJnl3O15eXacfNhZr7vpCZa8v0oINRSqv8evqI7N08wm95XYZS8kBAHtjjJnnOI5vr8coQAAAANCWrc0r0+mPzVD7+Cg9efEwLdtcqrnrCzXvxyIt21Iqf8CRMVLv9DgN75Ko8mq//js/V8f2SdND5w1RTARPlQNAa0EBAgAAAOzHtzl5mjh1rvyBnb8bR4a5NCQzUb4uifJ1SdKQTgmKiwz76fwXZq3XX99fpu6pMXpmgm+PmSMAADsoQAAAAIAD+HzZNv1YUC5flyT16xCnMPf+l8v7NidPk16arzC3S09ePEzDuyS1UFIAwL5QgAAAAADNYG1emS5/Plubiip115kDdPawDNuRAKBN218Bwi4wAAAAQCNlpcbonevGaHjXRP3ujYW6+6PlPz1GAwBoXShAAAAAgEMQ7w3Tc5cepotHdtbk6Wt19YvZKquusx0LAPAzFCAAAADAIQpzu/S30/vrztP66euVeTrr8ZnaWFhhOxYAYBcUIAAAAEATuWRUFz136XBtKanUCQ9N19QZ63gkBgBaCQoQAAAAoAkd0SNVH954hIZ2TtRf31+mMx6foSWbSmzHAoA2jwIEAAAAaGKZSV69cNlheuT8IdpcXKnTHpuhf3y4TOWsDQIA1lCAAAAAAM3AGKNTB3XQlzeN1Xhfpp7+dp2Of3C6vly+rcH3yNtRrc+XbdP6/PJmTAoAbYNxnOB8JtHn8znZ2dm2YwAAAAANMnd9oW59a7FytpfppAHpuuOX/dQuLvKn47X+gJZvKdX8H4s0f0Ox5m8oUm5RpSQpNsKj/143Wj3bxdqKDwBBwRgzz3Ec316PUYAAAAAALaOmLqCnv12rh7/MUbjbpWuOytKOqjrN31CkRbklqq4LSJLS4yI1tHOChnZKVPe0GN385iKFuV16e9JopcVGHuCnAEDbRQECAAAAtCLr88t1+ztL9N3qfIW7XerXMU5DMhN/Kj06JETtdv7i3BKNnzxLPdvF6NWrRikq3G0pOQC0bhQgAAAAQCvjOI5+LKhQenykIsMOXGh8tnSrrv7PPI3rm67HLxwql8u0QEoACC77K0BYBBUAAACwwBijLinRDSo/JOn4fum6/eS++mTpVt37yYpmTgcAocdjOwAAAACAhrlsTBetzy/X5Olr1Tk5WheM6GQ7EgAEDQoQAAAAIEgYY3THL/tqY1GF/vTuEmUkRunInqm2YwFAUOARGAAAACCIeNwu/fuCoeqRFqPrXpqvlVt32I4EAEGBAgQAAAAIMjERHk2ZOFzecLcue26utpdW2Y4EAK0ej8AAAAAAQahDQpSenTBc4yfP0hUvZOvVq0bKG777r/clFbVam1+m9QXlWpdXrnUFFSqtrJXLSC5jZMzOx2pcRjIycrl2/js2wqNfHdtD7eOj9vHTASD4UIAAAAAAQWpARrweOX+IrnoxW9e9NF++zolam1+u9fnlWpdfrqKK2p/OdRmpY2KUkrzhciQFHEeOIwWcnVvy7vzsKOA42lRcqTnrC/X61aOUEhNh7wsCQBMyjuPYztAoPp/Pyc7Oth0DAAAAsG7Kd+t05/+1d9/RUdb5Hsc/v8mkJxMCKSSBAIFESUCKdFksiCgquLtXBXt3XddlLceju9e7es+9brmW1V33KioWQLFeRRcVbICu9BISIPSSRgIhISE987t/THRRIQRNMpkn79c/k3lmnpnvc84XzsxnfuX9TZKknp4w9Y2LUL+4KPU76rZ39wiFulu35e7KXWW6ZvYK9YuL0vybxygmIrg9yweANmOMWWOtHXHMxwhAAAAAgMBXcrhWkaFuRYa2zSDvpVtLddNLq5WZ7NHcm0Yr6ge8bkV1g97fWKifDkv53vQcAGgPLQUgLIIKAAAAOECCJ6zNwg9JmpARr79dMUwbCyp000urVNvQdFLnr9xVpilPLtPv/i9H976ZrUD94RWAcxCAAAAAADim87J66rHLhmjFrjL9Yu4a1Td6T3hOY5NXjy3equmzvpI7yOjK0al6P7tIL3y5u/0LBoAWMA4NAAAAwHFNG5qi6vom3f/2Rs2cv05/nTFM7qBj/466r6xaM+ev09q95fr58F56aFqWIkOCVFJZp4cXbtZpvWI0om/3Dr4CAPBhBAgAAACAFs0YlaoHLsrUBznFuvetbHm935/O8u76Ak15Ypm27a/SE9OH6tHLhigq1C1jjB65dIhSYsP1y3lrVVJZ64crAAACEAAAAACtcOP4frprUobeXlug/1iQ882aHlV1jbrr9fWaOX+9MnpGa+HMn2ja0JRvnRsTHqynrzpdh2sbdMcr69TYdOKpNADQ1pgCAwAAAKBV7jhngI7UN+qZJTsVGeLWBYOTNHP+Ot/Ul4npuuOcAcedHjMwyaOHfzpYd72+Qf/zUZ7unzKwg6sH0NURgAAAAABoFWOM7jv/VFXXNemZpTs1a9lOJceE67Vbx2pkK9b2+NnwXlq795CeWbpTw1K76fxBSa1+7/pGr9bsOaSRfWOPG7IAQEsIQAAAAAC0mjFGD03NUnCQS1V1DfrdhZmKCQ9u9fkPXJSpjQWHdc8b2UpPjFb/+KgWn+/1Wr2XXahHF23V3rJqTcpM1F9nDFNYcNCPvRQAXYwJ1P24R4wYYVevXu3vMgAAAACcpMLyGl345DLFR4fqndvPUETI93+XtdZqydZS/fnDPG0qOqyBSR79JD1Os5bu1Ni0Hnr22hGKCuX3XADfZoxZY60dcazHGDsGAAAAoEMldwvXkzOGaVtJle57a6O++6Ps2r2HNH3Wcl33wipV1jXoielD9Y87xuu3UwbqL5cP1crdZbri2eUqO1LvpysAEIiITAEAAAB0uJ+kx+vuSRl6ZNFWnd4nVteO66vtJZX684d5WrRpv+KiQvTQ1CzNGJWqEPe/fre9ZFiKokLduv2Vtbr06X9q7k2jlRQT7scrARAomAIDAAAAwC+8Xqtb5qzW53mlmjyopz7YWKSIELdumZCmG8f3U2QLU1xW7Dyom15aLU94sObcOEppJ1hLBEDXwBQYAAAAAJ2Oy2X06GVDlRIbrsW5+3X9Gf209N6z9euJ6S2GH5I0Oq2HXr1ljGobmnTp018pp6Cig6oGEKgYAQIAAADAr8qr61Xf5FVCdNhJn7uztEpXPbdClbWNev66kRrV78Tb8QJwLkaAAAAAAOi0ukWE/KDwQ5LS4qP05m3jlOAJ1dXPr9CnW/a3cXUAnIIRIAAAAAAC3sGqOl33wiptLjqs68b1VXRYsFzGN83GGCnIGLmM72+XMQoNdmniqYnqGfPDghcAnVNLI0AIQAAAAAA4QmVtg371yjot2VraqucHuYwmZyXq6jF9NSatu4wx7VwhgPbWUgDCNrgAAAAAHCE6LFgv3TBK1lpZK3mtlbf59uv7TdbKeqXSqjq9vnqfXlu1Tws3FisjMUpXj+2rnzZvswvAeRgBAgAAAKDLqm1o0oINhXr5q93KKTisqFC3fj48RVeP7aMBCdH+Lg/ASWIKDAAAAAC0wFqrdfvKNeerPfpHdpHqm7wa17+H7jgnXWP79/B3eQBaiQAEAAAAAFrpQFWdXlu1T/OW71FJZZ2eunK4Jmf19HdZAFqBbXABAAAAoJXiokJ1+9kD9NGdEzS4V4xun7dWizexvS4Q6AhAAAAAAOAYvl5UNSslRr+ct0afbCYEAQIZAQgAAAAAHIcnLFgv3zBKA5M8um3uWn26hRAECFQEIAAAAADQgpjwYM25YbRO6RmtX8xZq8/yStrlfRqbvMrOL1eTNzDXaQQ6OwIQAAAAADiBmIhgzblxlNITo3TrnDVasrW0zV67qKJGjy/eqjP+9Kmm/u1L3fHqWtU1NrXZ6wPwIQABAAAAgFboFhGieTeN1oD4KN388mot/REhSJPX6rO8Et300mqd8cdP9eSn2zQwyaNbJqRp4cZiXTd7lSprG9qwegBsgwsAAAAAJ+HQkXrNeHa5dh04ouevHanx6XGtPre0sk6vr96nV1fuVf6hGsVFheiyEb01Y1SqenePkCS9s65A97yxQaf0jNaL149SfHRoe10K4DgtbYNLAAIAAAAAJ6nsSL2ueHa5dh88otnXjtS4Ab4QpLahSZW1jaqsbdDhr29rfLfLth/QRznFavRajU3roSvHpOq8zJ4KcX9/YP7neSW6be5aJXhCNeeG0UrtEdHRlwgEJAIQAAAAAGhjB6vqdMWzK7TrwBF5wt06XNuo+kbvcZ8fEx6sfzu9l2aMStWAhKgTvv66vYd0/YurFBzk0kvXj1JmsqctywcciQAEAAAAANrBgao6PfHxNjV6rTxhbnnCgxUd5pYnzHcbHRYsT7jvNj4q9JijPVqyvaRSVz+/UlW1jXr22hEak9ajna4EcAYCEAAAAAAIUIXlNbpm9krtLavWk9OH6fxBPf1dEtBptRSAsAsMAAAAAHRiyd3C9catY5WV7NEv563R/JV7/V0SEJAIQAAAAACgk4uN9G3BOyEjXve9vVEPLsjV9pJKf5cFBBSmwAAAAABAgGho8uqBd3L0+up98lopM8mjqUOTdfGQZKV0C/d3eYDfsQYIAAAAADhISWWt/pFdpAUbCrVub7kkaUSfWE0dmqwpg5MUFxXq5woB/yAAAQAAAACH2nuwWu9lF2rB+kLl7a9UkMtoXP8emjokWRMHJqp7ZIi/SwQ6DAEIAAAAAHQBW4oPa8H6Qi3YUKj8QzUyRhrau5vOykjQ2afGa1ByjFwu4+8ygXZDAAIAAAAAXYi1Vtn5Ffosr0Sf55VqQ365rJXiokI0ISNeZ5+SoAnp8YqJCPZ3qUCbIgABAAAAgC7sYFWdlm4r1ed5pVqytVTl1Q1yGWl4aqzOGZigCwYlqV9cpL/LBH40AhAAAAAAgCSpyWu1fl+5luSV6LO8Um0sqJAkDUzyaMqgnrpgcJIGJET5uUrghyEAAQAAAAAcU0F5jT7MKdYHG4u0es8hSVJGYpQuGJSkKYOTlJEYJWNYNwSBgQAEAAAAAHBCxRW1+ii3WAs3Fmnl7jJZK6XFR2pSZqKiQ92qa/SqrtGr+kav6hqbVNfg/eZYXWOTMhKjdc95pyg8JMjfl4IuigAEAAAAAHBSSivr9FFusT7IKdLynWVq8loZI4W5gxTidinU7VJosEshQS6FuoMUHGSUXVChAfFReurK4cpIjPb3JaALIgABAAAAAPxg9Y1eGSO5XabF6TBfbDug37y2TlV1jfrPaYN06em9mD6DDtVSAOLq6GIAAAAAAIElxO1ScJDrhGHG+PQ4Lfz1TzQ8NVb3vpmtu17foCN1jR1UJdAyAhAAAAAAQJtJ8IRpzo2jdee5GXp3fYEu/usX2lR4uFXnWmuVnV+uRz7K06ylO9TkDcwZC+ic3P4uAAAAAADgLEEuo5nnpmtUv+6aOX+dLvn7l/r9xZm6YlTq90aRNDZ5tXJ3mRbl7tei3GIVVtTKZSSvlVbuKtMT04cpMpSvrvjxWAMEAAAAANBuDlTV6c7X1mvZtgO68LQk/fFngxUc5NKybQf0UW6xPtm8X4eqGxTqdmlCRrwmZ/XUxFMT9F52oR5ckKvMZI+ev3akEj1h/r4UBAAWQQUAAAAA+I3Xa/X00h16dNFW9YgMUWVto2oamuQJc2viwERNzkrUhIx4RYR8e6THZ1tK9KtX1soTHqzZ143UwCSPn64AgYIABAAAAADgd6t2l+nxxVuVFh+pyVk9NSath4KDWl6aMrewQje+uFqVtQ166srhOuuUhA6qFoGIAAQAAAAAELCKK2p1w4urlLe/Ug9OzdLVY/r4uyR0UmyDCwAAAAAIWD1jwvTGL8bqzIx4PfBOjv7r/U3sEIOTRgACAAAAAOj0IkPdevaaEbpuXF8998Uu3TZ3jarrG/1dFgIIAQgAAAAAICAEuYwenJql31+cqY8379f0Wcv1xbYDamjy+rs0BAA2UwYAAAAABJTrz+in3rERuvO19brq+RXyhLl19qkJmpSZqDMz4hUdFuzvEtEJsQgqAAAAACAg1dQ3adm2Ui3etF+fbClR2ZF6hQS5NLZ/D03KTNSkzEQlesL8XSY6ELvAAAAAAAAcrclrtWbPIS3eVKxFm/Zrz8FqSdKQ3t00OStRF5+WrN7dI9q9jiN1jSqqqFFaXJRcLtPu74dvIwABAAAAAHQZ1lptK6nS4k37tSi3WBvyKyRJp/eJ1bShyZoyOElxUaE/+n0qahqUW1ih3ILDyimsUE5BhXYeOCJrpYtOS9JfLh8qdxBLb3YkAhAAAAAAQJe1r6xaCzYU6r0NhdpSXKkgl9EZA+I0dUiyJmcltrhmiLVW5dUNKiivUUF5jbaXVCm3sEI5BYe1t6z6m+clxYQpKzlGg1I8qqlv0jNLdxKC+AEBCAAAAAAAkvKKK7VgQ4HeXV+o/EM1CnG7NPHUBF0wOEnWWuUfqlFhc9hRcMh3W13f9K3XSO0eoUEpnubAI0ZZyZ7vjSh5ZskO/eGDLYQgHYwABAAAAACAo1hrtW5fuRasL9T72YU6UFX/zWOxEcFKiQ1XSrdwJXfz3faKDVdKtwil9ohQTHjrdpkhBOl4LQUgbIMLAAAAAOhyjDEanhqr4amx+vcLByqn8LCiQoOU3C1cESFt81X51jP7S5L+8MEWSSIE8TMCEAAAAABAl+YOcmlo727t8tq3ntlfxkgPL9wiK+kJQhC/IQABAAAAAKAd3TLBNxLk4YW+kSBtGYJU1DRo9he7VFheo5+f3kuj+3WXMWy/eywEIAAAAAAAtLO2DkGq6hr1whe7NGvZTlXWNioq1K031uQrPSFKV45O1c9O7yVPC7vbdEUEIAAAAAAAdIC2CEFq6pv08le79fSSHTpU3aBJmYm689wM9YuL1HvZhZq3fI8efG+T/vRhni4ZlqwrR/fRoJSYtr6UgMQuMAAAAAAAdKBZS3fo4YVbNKJPrM7MiNegXjEalByj+OjQ455T29CkV1fu1VOf7dCBqjqdmRGvuyZlaMgx1i7Jzi/X3OV7tGBDoWobvBqW2k1Xje6jC09LUlhwUHtemt+xDS4AAAAAAJ3InK92a/aXu7XrwJFvjvX0hGlQikeDUnyByOBeMYqNCNEba/bpb59uV1FFrcam9dDd52VoRN/uJ3yPiuoGvbU2X3NX7NHO0iPqFhGs68f10/Xj+zp2egwBCAAAAAAAnVBlbYNyCw8rp6BCuYWHtbGgQjtKq/T1V/VQt0t1jV6d3idWd0/K0LgBcSf9HtZafbXjoGZ/uVsfb96vmPBg3TIhTdeN66vIUGetjEEAAgAAAABAgDhS16jNRb5QZEfpEZ0zMEFnZcS3ye4uG/Mr9PjHW/XplhJ1jwzRrRPSdM3YvgoPccbUGAIQAAAAAADwjXV7D+nxj7dp6dZSxUWF6raz+uvK0akBv0YIAQgAAAAAAPieVbvL9PjirfrnjoNK9ITq9rMH6PKRvRXqDswgpKUA5IdvOgwAAAAAAALayL7d9crNY/TqzWPUp3uk/uPdXJ372BLVNjT5u7Q256zVTgAAAAAAwEkb27+HxqSN0ZfbD2pTUUXAT4U5FgIQAAAAAAAgY4zGp8dpfPrJ7zQTCJgCAwAAAAAAHI8ABAAAAAAAOB4BCAAAAAAAcDwCEAAAAAAA4HgEIAAAAAAAwPEIQAAAAAAAgOMRgAAAAAAAAMcjAAEAAAAAAI5HAAIAAAAAAByPAAQAAAAAADgeAQgAAAAAAHA8AhAAAAAAAOB4BCAAAAAAAMDxCEAAAAAAAIDjEYAAAAAAAADHIwABAAAAAACORwACAAAAAAAcjwAEAAAAAAA4HgEIAAAAAABwPAIQAAAAAADgeAQgAAAAAADA8QhAAAAAAACA4xGAAAAAAAAAxyMAAQAAAAAAjkcAAgAAAAAAHI8ABAAAAAAAOB4BCAAAAAAAcDwCEAAAAAAA4HgEIAAAAAAAwPEIQAAAAAAAgOMRgAAAAAAAAMcjAAEAAAAAAI5HAAIAAAAAAByPAAQAAAAAADgeAQgAAAAAAHA8AhAAAAAAAOB4BCAAAAAAAMDxCEAAAAAAAIDjEYAAAAAAAADHIwABAAAAAACORwACAAAAAAAcjwAEAAAAAAA4HgEIAAAAAABwPAIQAAAAAADgeAQgAAAAAADA8QhAAAAAAACA4xlrrb9r+EGMMaWS9vi7jh8oTtIBfxcBdDD6Hl0RfY+uiL5HV0XvoyvqjH3fx1obf6wHAjYACWTGmNXW2hH+rgPoSPQ9uiL6Hl0RfY+uit5HVxRofc8UGAAAAAAA4HgEIAAAAAAAwPEIQPxjlr8LAPyAvkdXRN+jK6Lv0VXR++iKAqrvWQMEAAAAAAA4HiNAAAAAAACA4xGAdDBjzPnGmDxjzHZjzH3+rgdoD8aY3saYz4wxm40xucaYmc3HuxtjFhtjtjXfxvq7VqAtGWOCjDHrjDHvN9+n5+F4xphuxpg3jTFbmv/fH0vvw+mMMXc2f8bJMca8aowJo+/hNMaY2caYEmNMzlHHjtvnxpj7m7/n5hljJvun6pYRgHQgY0yQpKckXSApU9IMY0ymf6sC2kWjpLuttQMljZF0e3Ov3yfpE2ttuqRPmu8DTjJT0uaj7tPz6AqekPShtfZUSUPk+zdA78OxjDEpkn4taYS1dpCkIEnTRd/DeV6UdP53jh2zz5s/60+XlNV8zt+bv/92KgQgHWuUpO3W2p3W2npJ8yVN83NNQJuz1hZZa9c2/10p34fhFPn6/aXmp70k6RL/VAi0PWNML0kXSnruqMP0PBzNGOORNEHS85Jkra231paL3ofzuSWFG2PckiIkFYq+h8NYa5dKKvvO4eP1+TRJ8621ddbaXZK2y/f9t1MhAOlYKZL2HXU/v/kY4FjGmL6ShklaISnRWlsk+UISSQn+qwxoc3+RdK8k71HH6Hk4XZqkUkkvNE//es4YEyl6Hw5mrS2Q9IikvZKKJFVYaxeJvkfXcLw+D4jvugQgHcsc4xjb8MCxjDFRkt6S9Btr7WF/1wO0F2PMRZJKrLVr/F0L0MHckoZL+l9r7TBJR8Swfzhc85oH0yT1k5QsKdIYc5V/qwL8LiC+6xKAdKx8Sb2Put9LvuFygOMYY4LlCz/mWWvfbj683xiT1Px4kqQSf9UHtLEzJE01xuyWb3rjOcaYuaLn4Xz5kvKttSua778pXyBC78PJzpW0y1pbaq1tkPS2pHGi79E1HK/PA+K7LgFIx1olKd0Y088YEyLfIjEL/FwT0OaMMUa++eCbrbWPHfXQAknXNv99raR3O7o2oD1Ya++31vay1vaV7//2T621V4meh8NZa4sl7TPGnNJ8aKKkTaL34Wx7JY0xxkQ0f+aZKN96Z/Q9uoLj9fkCSdONMaHGmH6S0iWt9EN9LTLWdrpRKY5mjJki3zzxIEmzrbX/7eeSgDZnjBkvaZmkjfrXegi/lW8dkNclpcr34eFSa+13F1YCApox5ixJ91hrLzLG9BA9D4czxgyVb/HfEEk7JV0v349s9D4cyxjzkKTL5dv5bp2kmyRFib6HgxhjXpV0lqQ4Sfsl/V7SOzpOnxtjfifpBvn+XfzGWvuBH8puEQEIAAAAAABwPKbAAAAAAAAAxyMAAQAAAAAAjkcAAgAAAAAAHI8ABAAAAAAAOB4BCAAAAAAAcDwCEAAAAAAA4HgEIAAAAAAAwPEIQAAAAAAAgOP9P6jxzDIjiZ5AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:01:26.198794Z",
     "start_time": "2021-05-10T20:01:25.495334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 8415.242815932415 EVS: 0.791611134779733 R2: 0.7910709893715125\n",
      "Test Score: MSE: 13037.545496267461 EVS: 0.6541490753629551 R2: 0.6540937355663705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, explained_variance_score,r2_score, mean_squared_log_error\n",
    "\n",
    "pred_train = model.predict(X_train_pca)\n",
    "print(\"Train score:\", \"MSE:\",mean_squared_error(y_train,pred_train),\"EVS:\",explained_variance_score(y_train,pred_train),\"R2:\",r2_score(y_train,pred_train))\n",
    "\n",
    "pred = model.predict(X_test_pca)\n",
    "print(\"Test Score:\", \"MSE:\", mean_squared_error(y_test,pred),\"EVS:\",explained_variance_score(y_test,pred),\"R2:\",r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:21:17.817638Z",
     "start_time": "2021-05-10T23:21:17.762183Z"
    }
   },
   "outputs": [],
   "source": [
    "# validation curve\n",
    "input_layer = Input(shape=(X_test_pca.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model_val = Model(inputs=input_layer, outputs=output)\n",
    "model_val.compile(loss=\"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\",\"mean_squared_logarithmic_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:30:31.568962Z",
     "start_time": "2021-05-10T23:21:18.937208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 43976.4219 - mean_squared_error: 43976.4219 - mean_squared_logarithmic_error: 2.1982 - val_loss: 41613.6094 - val_mean_squared_error: 41613.6094 - val_mean_squared_logarithmic_error: 2.3911\n",
      "Epoch 2/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42895.8672 - mean_squared_error: 42895.8672 - mean_squared_logarithmic_error: 2.1235 - val_loss: 40832.8398 - val_mean_squared_error: 40832.8398 - val_mean_squared_logarithmic_error: 2.1783\n",
      "Epoch 3/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42793.2578 - mean_squared_error: 42793.2578 - mean_squared_logarithmic_error: 2.1334 - val_loss: 40763.9922 - val_mean_squared_error: 40763.9922 - val_mean_squared_logarithmic_error: 2.1721 43307.4805 - mean_squared_error: 43307.4805 - mean_squared_logari - ETA: 2s - loss: 44543.2461 - mean_squared_error: 44543.2461 - mean_squared_logarithmic_er - ETA: 1s - loss: 44864.9883 - mean_squared_error: 44864.9883 - \n",
      "Epoch 4/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42726.9766 - mean_squared_error: 42726.9766 - mean_squared_logarithmic_error: 2.1418 - val_loss: 40992.4570 - val_mean_squared_error: 40992.4570 - val_mean_squared_logarithmic_error: 2.0086\n",
      "Epoch 5/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42606.9688 - mean_squared_error: 42606.9688 - mean_squared_logarithmic_error: 2.1377 - val_loss: 40857.7891 - val_mean_squared_error: 40857.7891 - val_mean_squared_logarithmic_error: 2.0899\n",
      "Epoch 6/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42561.0664 - mean_squared_error: 42561.0664 - mean_squared_logarithmic_error: 2.1361 - val_loss: 40934.6719 - val_mean_squared_error: 40934.6719 - val_mean_squared_logarithmic_error: 2.2548\n",
      "Epoch 7/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42460.4375 - mean_squared_error: 42460.4375 - mean_squared_logarithmic_error: 2.1341 - val_loss: 40726.9102 - val_mean_squared_error: 40726.9102 - val_mean_squared_logarithmic_error: 2.0443\n",
      "Epoch 8/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42473.3477 - mean_squared_error: 42473.3477 - mean_squared_logarithmic_error: 2.1438 - val_loss: 40892.3906 - val_mean_squared_error: 40892.3906 - val_mean_squared_logarithmic_error: 2.1176 - loss: 43079.0039 - mean_squared_error: 43079.0039 - mean_squared_logarithmic - ETA: 0s - loss: 42906.5508 - mean_squared_error: 42906.5508 - mean_squared_logarithmic\n",
      "Epoch 9/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42426.2656 - mean_squared_error: 42426.2656 - mean_squared_logarithmic_error: 2.1411 - val_loss: 40858.2578 - val_mean_squared_error: 40858.2578 - val_mean_squared_logarithmic_error: 2.2687\n",
      "Epoch 10/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42383.8008 - mean_squared_error: 42383.8008 - mean_squared_logarithmic_error: 2.1412 - val_loss: 40951.0625 - val_mean_squared_error: 40951.0625 - val_mean_squared_logarithmic_error: 2.3029\n",
      "Epoch 11/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42344.3906 - mean_squared_error: 42344.3906 - mean_squared_logarithmic_error: 2.1393 - val_loss: 40839.6055 - val_mean_squared_error: 40839.6055 - val_mean_squared_logarithmic_error: 2.1575 - loss: 52664.8398 - mean_squared_error: 52664.8398 - mean_squared_logarithmic_error: 2.19 - ETA: 3s - loss: 51908.7344 - mean_squared_error: 51908.7344 - mean_squared_logarithmic_error - ETA: 3s - loss: 47831.2148 - mean_squared_error: 47831.2148 - mean_squared_logarithmic_erro - ETA: 2s - loss: 42410.6602 - mean_squared_error: 42410.6602 - mean_squared_logari - ETA: 2s - loss: 41799.5547 - mean_squared_error: 41799.5547 \n",
      "Epoch 12/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42328.1875 - mean_squared_error: 42328.1875 - mean_squared_logarithmic_error: 2.1505 - val_loss: 40752.2148 - val_mean_squared_error: 40752.2148 - val_mean_squared_logarithmic_error: 2.0543quared_error: 44191.2031 - mean_squared_logar - ETA: 0s - loss: 42830.2969 - mean_squared_error: 42830.2969 - mean_squared_logarithmic_err\n",
      "Epoch 13/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42316.8594 - mean_squared_error: 42316.8594 - mean_squared_logarithmic_error: 2.1386 - val_loss: 40753.8047 - val_mean_squared_error: 40753.8047 - val_mean_squared_logarithmic_error: 2.084036.6758 - mean_squared_error: 41236.6758 - mean_squar - ETA: 0s - loss: 41536.3711 - mean_squared_error: 41536.3711 - mean_squared_logarith\n",
      "Epoch 14/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42237.5547 - mean_squared_error: 42237.5547 - mean_squared_logarithmic_error: 2.1344 - val_loss: 41288.5391 - val_mean_squared_error: 41288.5391 - val_mean_squared_logarithmic_error: 2.4149\n",
      "Epoch 15/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42243.2031 - mean_squared_error: 42243.2031 - mean_squared_logarithmic_error: 2.1565 - val_loss: 40892.1953 - val_mean_squared_error: 40892.1953 - val_mean_squared_logarithmic_error: 1.9487ss: 42489.0898 - mean_squared_error: 42489.0898 - mean_squared_lo\n",
      "Epoch 16/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42187.0742 - mean_squared_error: 42187.0742 - mean_squared_logarithmic_error: 2.1440 - val_loss: 40848.9023 - val_mean_squared_error: 40848.9023 - val_mean_squared_logarithmic_error: 2.1269\n",
      "Epoch 17/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42182.9844 - mean_squared_error: 42182.9844 - mean_squared_logarithmic_error: 2.1445 - val_loss: 40946.3945 - val_mean_squared_error: 40946.3945 - val_mean_squared_logarithmic_error: 2.1263\n",
      "Epoch 18/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 42131.3125 - mean_squared_error: 42131.3125 - mean_squared_logarithmic_error: 2.1373 - val_loss: 41285.5977 - val_mean_squared_error: 41285.5977 - val_mean_squared_logarithmic_error: 2.3377.5898 - mean_squared_error: 417\n",
      "Epoch 19/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42081.6875 - mean_squared_error: 42081.6875 - mean_squared_logarithmic_error: 2.1424 - val_loss: 40911.2656 - val_mean_squared_error: 40911.2656 - val_mean_squared_logarithmic_error: 2.12229.0469 - mean_squared_error: 43789.0469 -  - ETA: 0s - loss: 43487.6992 - mean_squared_error: 43487.6992 - mean_squared_logarithmic_error: 2.14 - ETA: 0s - loss: 43468.4414 - mean_squared_error: 43468.4414 - mean_squared_logarith\n",
      "Epoch 20/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42017.4961 - mean_squared_error: 42017.4961 - mean_squared_logarithmic_error: 2.1317 - val_loss: 41238.9961 - val_mean_squared_error: 41238.9961 - val_mean_squared_logarithmic_error: 2.3591738.6055 - mean_squared_erro\n",
      "Epoch 21/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42011.0039 - mean_squared_error: 42011.0039 - mean_squared_logarithmic_error: 2.1438 - val_loss: 41050.7773 - val_mean_squared_error: 41050.7773 - val_mean_squared_logarithmic_error: 2.1614\n",
      "Epoch 22/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41989.6758 - mean_squared_error: 41989.6758 - mean_squared_logarithmic_error: 2.1325 - val_loss: 41495.4648 - val_mean_squared_error: 41495.4648 - val_mean_squared_logarithmic_error: 2.4264\n",
      "Epoch 23/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42029.8867 - mean_squared_error: 42029.8867 - mean_squared_logarithmic_error: 2.1459 - val_loss: 40930.3125 - val_mean_squared_error: 40930.3125 - val_mean_squared_logarithmic_error: 2.11703s - loss: 42948.7070 - mean_squared_error: 42948.7070 - mean_squared_logarithmic_erro - ETA: 3s - loss: 45324.9375 - mean_squa\n",
      "Epoch 24/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41900.4258 - mean_squared_error: 41900.4258 - mean_squared_logarithmic_error: 2.1324 - val_loss: 41119.2227 - val_mean_squared_error: 41119.2227 - val_mean_squared_logarithmic_error: 2.2191 39632.7930 - mean_squared_ - ETA: 0s - loss: 41879.2227 - mean_squared_error: 41879.2227 - mean_squared_logarithmic_error: 2.13\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5250/5250 [==============================] - 5s 1ms/step - loss: 41823.1562 - mean_squared_error: 41823.1562 - mean_squared_logarithmic_error: 2.1331 - val_loss: 41562.9180 - val_mean_squared_error: 41562.9180 - val_mean_squared_logarithmic_error: 2.3307\n",
      "Epoch 26/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 41801.4609 - mean_squared_error: 41801.4609 - mean_squared_logarithmic_error: 2.1322 - val_loss: 41083.3828 - val_mean_squared_error: 41083.3828 - val_mean_squared_logarithmic_error: 2.1390ean_squared_error: 42066.5781 - mean_squared_logarithmic_error: \n",
      "Epoch 27/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41841.4727 - mean_squared_error: 41841.4727 - mean_squared_logarithmic_error: 2.1346 - val_loss: 41297.2734 - val_mean_squared_error: 41297.2734 - val_mean_squared_logarithmic_error: 2.1575\n",
      "Epoch 28/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41661.0547 - mean_squared_error: 41661.0547 - mean_squared_logarithmic_error: 2.1270 - val_loss: 41172.5781 - val_mean_squared_error: 41172.5781 - val_mean_squared_logarithmic_error: 2.1151 - mean_squared_error: 42386.6445 - mean_squared_logarithmic_error: 2.122 - ETA: 1s - loss: 42494.1719 - mean_squared_error: 42494.1719 - mean\n",
      "Epoch 29/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41499.7930 - mean_squared_error: 41499.7930 - mean_squared_logarithmic_error: 2.1118 - val_loss: 42223.9922 - val_mean_squared_error: 42223.9922 - val_mean_squared_logarithmic_error: 2.4722\n",
      "Epoch 30/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41524.8828 - mean_squared_error: 41524.8828 - mean_squared_logarithmic_error: 2.1326 - val_loss: 41204.6523 - val_mean_squared_error: 41204.6523 - val_mean_squared_logarithmic_error: 2.0363\n",
      "Epoch 31/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 41370.9258 - mean_squared_error: 41370.9258 - mean_squared_logarithmic_error: 2.1196 - val_loss: 41350.9961 - val_mean_squared_error: 41350.9961 - val_mean_squared_logarithmic_error: 1.9545\n",
      "Epoch 32/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41354.4766 - mean_squared_error: 41354.4766 - mean_squared_logarithmic_error: 2.1070 - val_loss: 41445.8711 - val_mean_squared_error: 41445.8711 - val_mean_squared_logarithmic_error: 2.2591\n",
      "Epoch 33/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 41240.5000 - mean_squared_error: 41240.5000 - mean_squared_logarithmic_error: 2.1141 - val_loss: 41677.2266 - val_mean_squared_error: 41677.2266 - val_mean_squared_logarithmic_error: 2.2804\n",
      "Epoch 34/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41120.4570 - mean_squared_error: 41120.4570 - mean_squared_logarithmic_error: 2.1120 - val_loss: 41728.8281 - val_mean_squared_error: 41728.8281 - val_mean_squared_logarithmic_error: 2.1289: 39886.6016 - mean_squared_error: 39886.6016 - mean_squared - ETA: 0s - loss: 41532.9062 - mean_squared_error: 41532.9062 - mean_squared_logarithmic_error: 2\n",
      "Epoch 35/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 41015.5508 - mean_squared_error: 41015.5508 - mean_squared_logarithmic_error: 2.1081 - val_loss: 41750.4805 - val_mean_squared_error: 41750.4805 - val_mean_squared_logarithmic_error: 2.1303\n",
      "Epoch 36/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 40747.5977 - mean_squared_error: 40747.5977 - mean_squared_logarithmic_error: 2.0940 - val_loss: 42034.9375 - val_mean_squared_error: 42034.9375 - val_mean_squared_logarithmic_error: 2.3222\n",
      "Epoch 37/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 40741.1836 - mean_squared_error: 40741.1836 - mean_squared_logarithmic_error: 2.1004 - val_loss: 42056.1484 - val_mean_squared_error: 42056.1484 - val_mean_squared_logarithmic_error: 2.2535 - mean_squared_error: 41328.5781 - mean\n",
      "Epoch 38/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 40472.9609 - mean_squared_error: 40472.9609 - mean_squared_logarithmic_error: 2.0959 - val_loss: 42314.0039 - val_mean_squared_error: 42314.0039 - val_mean_squared_logarithmic_error: 2.3115\n",
      "Epoch 39/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 40345.8203 - mean_squared_error: 40345.8203 - mean_squared_logarithmic_error: 2.1006 - val_loss: 41938.7969 - val_mean_squared_error: 41938.7969 - val_mean_squared_logarithmic_error: 2.2115\n",
      "Epoch 40/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 40252.5977 - mean_squared_error: 40252.5977 - mean_squared_logarithmic_error: 2.0972 - val_loss: 41986.3828 - val_mean_squared_error: 41986.3828 - val_mean_squared_logarithmic_error: 2.0486\n",
      "Epoch 41/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 40035.8633 - mean_squared_error: 40035.8633 - mean_squared_logarithmic_error: 2.0724 - val_loss: 42527.4023 - val_mean_squared_error: 42527.4023 - val_mean_squared_logarithmic_error: 2.2082 - mean_squared_logarithmic_error: 2.07\n",
      "Epoch 42/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 39716.0273 - mean_squared_error: 39716.0273 - mean_squared_logarithmic_error: 2.0764 - val_loss: 42265.3750 - val_mean_squared_error: 42265.3750 - val_mean_squared_logarithmic_error: 2.1944ss: 36303.0430 - mean_sq\n",
      "Epoch 43/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 39652.9922 - mean_squared_error: 39652.9922 - mean_squared_logarithmic_error: 2.0759 - val_loss: 42939.9414 - val_mean_squared_error: 42939.9414 - val_mean_squared_logarithmic_error: 2.1620 loss: 40020.6602 - mean_squared_error: 40020.6602 - mean_squared_logarithmic_err - ETA: 2s - loss: 40239.5117 - mean_squared_error: 402 - ETA: 0s - loss: 40488.9688 - mean_squared_error: 40488.9688 - mean_squared_logarithmic_e\n",
      "Epoch 44/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 39183.7891 - mean_squared_error: 39183.7891 - mean_squared_logarithmic_error: 2.0538 - val_loss: 42443.6719 - val_mean_squared_error: 42443.6719 - val_mean_squared_logarithmic_error: 2.2418\n",
      "Epoch 45/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 39241.5469 - mean_squared_error: 39241.5469 - mean_squared_logarithmic_error: 2.0758 - val_loss: 42311.2031 - val_mean_squared_error: 42311.2031 - val_mean_squared_logarithmic_error: 2.0350\n",
      "Epoch 46/100\n",
      "5250/5250 [==============================] - 5s 977us/step - loss: 39025.8164 - mean_squared_error: 39025.8164 - mean_squared_logarithmic_error: 2.0488 - val_loss: 43429.6992 - val_mean_squared_error: 43429.6992 - val_mean_squared_logarithmic_error: 2.4232ean_squared_error: 36537.2344 - mean_squared_logari - ETA: 0s - loss: 38239.8203 - mean_squared_error: 38239.8203 - mean_squared_logarithmic_error: 2.\n",
      "Epoch 47/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 38430.0781 - mean_squared_error: 38430.0781 - mean_squared_logarithmic_error: 2.0533 - val_loss: 44149.3086 - val_mean_squared_error: 44149.3086 - val_mean_squared_logarithmic_error: 2.3161\n",
      "Epoch 48/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 38271.8984 - mean_squared_error: 38271.8984 - mean_squared_logarithmic_error: 2.0394 - val_loss: 42898.8984 - val_mean_squared_error: 42898.8984 - val_mean_squared_logarithmic_error: 2.0408\n",
      "Epoch 49/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 38153.6172 - mean_squared_error: 38153.6172 - mean_squared_logarithmic_error: 2.0439 - val_loss: 43639.9492 - val_mean_squared_error: 43639.9492 - val_mean_squared_logarithmic_error: 2.2259\n",
      "Epoch 50/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 37846.6484 - mean_squared_error: 37846.6484 - mean_squared_logarithmic_error: 2.0315 - val_loss: 45351.2266 - val_mean_squared_error: 45351.2266 - val_mean_squared_logarithmic_error: 2.2809\n",
      "Epoch 51/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 37593.9062 - mean_squared_error: 37593.9062 - mean_squared_logarithmic_error: 2.0198 - val_loss: 43914.3203 - val_mean_squared_error: 43914.3203 - val_mean_squared_logarithmic_error: 2.2992\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5250/5250 [==============================] - 6s 1ms/step - loss: 37631.0938 - mean_squared_error: 37631.0938 - mean_squared_logarithmic_error: 2.0238 - val_loss: 45659.2383 - val_mean_squared_error: 45659.2383 - val_mean_squared_logarithmic_error: 2.24237082.4141 - me\n",
      "Epoch 53/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 37439.3672 - mean_squared_error: 37439.3672 - mean_squared_logarithmic_error: 2.0173 - val_loss: 46933.0117 - val_mean_squared_error: 46933.0117 - val_mean_squared_logarithmic_error: 2.32369531 - mean_squared_error: 38075.95\n",
      "Epoch 54/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 37240.0859 - mean_squared_error: 37240.0859 - mean_squared_logarithmic_error: 2.0220 - val_loss: 47590.1797 - val_mean_squared_error: 47590.1797 - val_mean_squared_logarithmic_error: 2.2908.4102 - mean_squared_error: 33926.4102\n",
      "Epoch 55/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 36817.5898 - mean_squared_error: 36817.5898 - mean_squared_logarithmic_error: 2.0115 - val_loss: 46349.2656 - val_mean_squared_error: 46349.2656 - val_mean_squared_logarithmic_error: 2.2306oss: 39801.8984 - mean_squared_error: 39801.8984 - mean_squared_logarithmic_error: 2.1 - ETA: 3s - loss: 38613.0781 - mean_squared_error: 38613.0781 - mean_squared_logarithmic_error: 2.079 - ETA: 3s - loss: 38609.1406 - mean_squared_erro - ETA: 0s - loss: 36648.8477 - mean_squared_error: 36648.8477 - mean_squared_logarithmic_error\n",
      "Epoch 56/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 37125.0547 - mean_squared_error: 37125.0547 - mean_squared_logarithmic_error: 2.0009 - val_loss: 43517.5078 - val_mean_squared_error: 43517.5078 - val_mean_squared_logarithmic_error: 2.2608\n",
      "Epoch 57/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 36765.9961 - mean_squared_error: 36765.9961 - mean_squared_logarithmic_error: 2.0042 - val_loss: 45138.0781 - val_mean_squared_error: 45138.0781 - val_mean_squared_logarithmic_error: 2.2455\n",
      "Epoch 58/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 36419.9727 - mean_squared_error: 36419.9727 - mean_squared_logarithmic_error: 1.9976 - val_loss: 46828.2188 - val_mean_squared_error: 46828.2188 - val_mean_squared_logarithmic_error: 2.3001\n",
      "Epoch 59/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 36317.5469 - mean_squared_error: 36317.5469 - mean_squared_logarithmic_error: 1.9987 - val_loss: 45835.2930 - val_mean_squared_error: 45835.2930 - val_mean_squared_logarithmic_error: 2.0177\n",
      "Epoch 60/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 36473.2891 - mean_squared_error: 36473.2891 - mean_squared_logarithmic_error: 1.9930 - val_loss: 44375.7812 - val_mean_squared_error: 44375.7812 - val_mean_squared_logarithmic_error: 2.2146- loss: 35274.4062 - mean_squared_error: 35274.4062 - mean_squared_logarithmic_error: 1. - ETA: 1s - loss: 35422.8398 - mean_squared_error: 35422.8398 - mean_squared_logar\n",
      "Epoch 61/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 36174.6602 - mean_squared_error: 36174.6602 - mean_squared_logarithmic_error: 1.9897 - val_loss: 45199.8711 - val_mean_squared_error: 45199.8711 - val_mean_squared_logarithmic_error: 2.3914\n",
      "Epoch 62/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 35881.7969 - mean_squared_error: 35881.7969 - mean_squared_logarithmic_error: 1.9834 - val_loss: 44152.1211 - val_mean_squared_error: 44152.1211 - val_mean_squared_logarithmic_error: 2.2749.7539 - mean_squared_error: 38497.7539 - mean_square - ETA: 1s - loss: 36541.1797 - mean_squared_error: 36541.1797 - mean\n",
      "Epoch 63/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 35940.9375 - mean_squared_error: 35940.9375 - mean_squared_logarithmic_error: 1.9928 - val_loss: 46473.1016 - val_mean_squared_error: 46473.1016 - val_mean_squared_logarithmic_error: 2.2342\n",
      "Epoch 64/100\n",
      "5250/5250 [==============================] - 5s 988us/step - loss: 35732.3242 - mean_squared_error: 35732.3242 - mean_squared_logarithmic_error: 1.9765 - val_loss: 50286.1875 - val_mean_squared_error: 50286.1875 - val_mean_squared_logarithmic_error: 2.2024\n",
      "Epoch 65/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 35430.0547 - mean_squared_error: 35430.0547 - mean_squared_logarithmic_error: 1.9827 - val_loss: 46009.5859 - val_mean_squared_error: 46009.5859 - val_mean_squared_logarithmic_error: 2.3123\n",
      "Epoch 66/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 35418.1914 - mean_squared_error: 35418.1914 - mean_squared_logarithmic_error: 1.9740 - val_loss: 44857.5117 - val_mean_squared_error: 44857.5117 - val_mean_squared_logarithmic_error: 2.0955750.7070 - mean_squared_loga\n",
      "Epoch 67/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 35285.4102 - mean_squared_error: 35285.4102 - mean_squared_logarithmic_error: 1.9621 - val_loss: 44788.4766 - val_mean_squared_error: 44788.4766 - val_mean_squared_logarithmic_error: 2.1328 loss: 36650.0898 - mean_squared_error: 36650.0898 - mean_squared_logarithmic_er - ETA: 3s - loss: 35856.3320 - mean_squared_error: 35856.3320 - mean_ - ETA: 1s - loss: 37328.6484 - mean_squared_error: 37328.6484 - mean_\n",
      "Epoch 68/100\n",
      "5250/5250 [==============================] - 5s 979us/step - loss: 35034.9805 - mean_squared_error: 35034.9805 - mean_squared_logarithmic_error: 1.9502 - val_loss: 48718.8555 - val_mean_squared_error: 48718.8555 - val_mean_squared_logarithmic_error: 2.3447\n",
      "Epoch 69/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 35349.1797 - mean_squared_error: 35349.1797 - mean_squared_logarithmic_error: 1.9600 - val_loss: 48005.7930 - val_mean_squared_error: 48005.7930 - val_mean_squared_logarithmic_error: 2.3451\n",
      "Epoch 70/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 35190.2734 - mean_squared_error: 35190.2734 - mean_squared_logarithmic_error: 1.9512 - val_loss: 45839.1602 - val_mean_squared_error: 45839.1602 - val_mean_squared_logarithmic_error: 2.2770\n",
      "Epoch 71/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 34801.7852 - mean_squared_error: 34801.7852 - mean_squared_logarithmic_error: 1.9490 - val_loss: 45778.2930 - val_mean_squared_error: 45778.2930 - val_mean_squared_logarithmic_error: 2.2767\n",
      "Epoch 72/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 34711.1055 - mean_squared_error: 34711.1055 - mean_squared_logarithmic_error: 1.9515 - val_loss: 45185.7812 - val_mean_squared_error: 45185.7812 - val_mean_squared_logarithmic_error: 2.1897\n",
      "Epoch 73/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 35111.6602 - mean_squared_error: 35111.6602 - mean_squared_logarithmic_error: 1.9572 - val_loss: 48783.3516 - val_mean_squared_error: 48783.3516 - val_mean_squared_logarithmic_error: 2.2841\n",
      "Epoch 74/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 33961.5430 - mean_squared_error: 33961.5430 - mean_squared_logarithmic_error: 1.9312 - val_loss: 45856.3359 - val_mean_squared_error: 45856.3359 - val_mean_squared_logarithmic_error: 2.220532216.3965 - mean_squared_error: 32216.3965 - mean_squared_logarithmic_error: 1.90 - ETA: 1s - loss: 32401.7441 - mean_squared_error: 32401.7441 - mean_squared_logarithmic_err - ETA: 1s - loss: 33057.2422 - mean_squared_error: 33057.2422 - mean_squared_lo\n",
      "Epoch 75/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 34560.3828 - mean_squared_error: 34560.3828 - mean_squared_logarithmic_error: 1.9364 - val_loss: 45251.7109 - val_mean_squared_error: 45251.7109 - val_mean_squared_logarithmic_error: 2.2142quared_logarithmic_error: 1.936\n",
      "Epoch 76/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 34299.6172 - mean_squared_error: 34299.6172 - mean_squared_logarithmic_error: 1.9339 - val_loss: 45470.0703 - val_mean_squared_error: 45470.0703 - val_mean_squared_logarithmic_error: 2.4235\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5250/5250 [==============================] - 6s 1ms/step - loss: 34172.4570 - mean_squared_error: 34172.4570 - mean_squared_logarithmic_error: 1.9471 - val_loss: 48215.6016 - val_mean_squared_error: 48215.6016 - val_mean_squared_logarithmic_error: 2.26621.1211 - mean_squared_logari\n",
      "Epoch 78/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33626.3594 - mean_squared_error: 33626.3594 - mean_squared_logarithmic_error: 1.9182 - val_loss: 47201.6758 - val_mean_squared_error: 47201.6758 - val_mean_squared_logarithmic_error: 2.351529236.0156 - mean_squared_error: 29236.015 - ETA: 1s - loss: 33583.3008 - mean_squared_error: 33583.3008 - mean_squared\n",
      "Epoch 79/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33988.2930 - mean_squared_error: 33988.2930 - mean_squared_logarithmic_error: 1.9291 - val_loss: 47567.8477 - val_mean_squared_error: 47567.8477 - val_mean_squared_logarithmic_error: 2.3982\n",
      "Epoch 80/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 34025.4570 - mean_squared_error: 34025.4570 - mean_squared_logarithmic_error: 1.9244 - val_loss: 46663.8555 - val_mean_squared_error: 46663.8555 - val_mean_squared_logarithmic_error: 2.2673\n",
      "Epoch 81/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33909.4805 - mean_squared_error: 33909.4805 - mean_squared_logarithmic_error: 1.9277 - val_loss: 45730.0430 - val_mean_squared_error: 45730.0430 - val_mean_squared_logarithmic_error: 2.2129\n",
      "Epoch 82/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 33493.5938 - mean_squared_error: 33493.5938 - mean_squared_logarithmic_error: 1.9200 - val_loss: 48380.0117 - val_mean_squared_error: 48380.0117 - val_mean_squared_logarithmic_error: 2.3653\n",
      "Epoch 83/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33450.9414 - mean_squared_error: 33450.9414 - mean_squared_logarithmic_error: 1.9129 - val_loss: 46487.3086 - val_mean_squared_error: 46487.3086 - val_mean_squared_logarithmic_error: 2.23335000 - mean_squared_error: 33392.5000 - mean_squared_logarithmic_er\n",
      "Epoch 84/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33757.9688 - mean_squared_error: 33757.9688 - mean_squared_logarithmic_error: 1.9218 - val_loss: 47105.9336 - val_mean_squared_error: 47105.9336 - val_mean_squared_logarithmic_error: 2.170234076.5586 - mean_squared_error: 34076.5586 - mean_squared_logarithmic_error:\n",
      "Epoch 85/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33093.0703 - mean_squared_error: 33093.0703 - mean_squared_logarithmic_error: 1.9038 - val_loss: 44567.9414 - val_mean_squared_error: 44567.9414 - val_mean_squared_logarithmic_error: 2.1468\n",
      "Epoch 86/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 33169.4961 - mean_squared_error: 33169.4961 - mean_squared_logarithmic_error: 1.9165 - val_loss: 47282.2695 - val_mean_squared_error: 47282.2695 - val_mean_squared_logarithmic_error: 2.2949mean_squared_error: \n",
      "Epoch 87/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32949.6562 - mean_squared_error: 32949.6562 - mean_squared_logarithmic_error: 1.9099 - val_loss: 47032.5156 - val_mean_squared_error: 47032.5156 - val_mean_squared_logarithmic_error: 2.21592734 - mean_squared_error: 32744.2734 - mean_squared_logarithmic_error - ETA: 1s - loss: 32747.4004 - mean_squared_error: 32747.4004 - mean_sq\n",
      "Epoch 88/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33133.7148 - mean_squared_error: 33133.7148 - mean_squared_logarithmic_error: 1.9164 - val_loss: 47563.5039 - val_mean_squared_error: 47563.5039 - val_mean_squared_logarithmic_error: 2.1906\n",
      "Epoch 89/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33067.9023 - mean_squared_error: 33067.9023 - mean_squared_logarithmic_error: 1.8958 - val_loss: 46237.4883 - val_mean_squared_error: 46237.4883 - val_mean_squared_logarithmic_error: 2.2726red_error: 34\n",
      "Epoch 90/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 33149.7539 - mean_squared_error: 33149.7539 - mean_squared_logarithmic_error: 1.9019 - val_loss: 48887.2969 - val_mean_squared_error: 48887.2969 - val_mean_squared_logarithmic_error: 2.2261ss: 33132.3242 - mean_squared_error: 33132.3242 - mean_squared_logarithm\n",
      "Epoch 91/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32405.5527 - mean_squared_error: 32405.5527 - mean_squared_logarithmic_error: 1.8971 - val_loss: 45932.3945 - val_mean_squared_error: 45932.3945 - val_mean_squared_logarithmic_error: 2.1947ean_squared_error: 34549.7383 - mean_squared_logarithmic_error: 1. - ETA: 2s - loss: 34726.7188 - mean_squared_error: 34726.71\n",
      "Epoch 92/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32758.3750 - mean_squared_error: 32758.3750 - mean_squared_logarithmic_error: 1.8958 - val_loss: 47571.6914 - val_mean_squared_error: 47571.6914 - val_mean_squared_logarithmic_error: 2.1767\n",
      "Epoch 93/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 32743.4219 - mean_squared_error: 32743.4219 - mean_squared_logarithmic_error: 1.8833 - val_loss: 47514.9414 - val_mean_squared_error: 47514.9414 - val_mean_squared_logarithmic_error: 2.146634793.4570 - mean_squared_error: 34793.4570 \n",
      "Epoch 94/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32085.9648 - mean_squared_error: 32085.9648 - mean_squared_logarithmic_error: 1.8942 - val_loss: 46645.2734 - val_mean_squared_error: 46645.2734 - val_mean_squared_logarithmic_error: 2.1727\n",
      "Epoch 95/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32482.2637 - mean_squared_error: 32482.2637 - mean_squared_logarithmic_error: 1.8889 - val_loss: 48604.4297 - val_mean_squared_error: 48604.4297 - val_mean_squared_logarithmic_error: 2.2597\n",
      "Epoch 96/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 32066.3340 - mean_squared_error: 32066.3340 - mean_squared_logarithmic_error: 1.8790 - val_loss: 47642.4180 - val_mean_squared_error: 47642.4180 - val_mean_squared_logarithmic_error: 2.1822\n",
      "Epoch 97/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32179.9902 - mean_squared_error: 32179.9902 - mean_squared_logarithmic_error: 1.8666 - val_loss: 49024.4883 - val_mean_squared_error: 49024.4883 - val_mean_squared_logarithmic_error: 2.2759\n",
      "Epoch 98/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 31578.2832 - mean_squared_error: 31578.2832 - mean_squared_logarithmic_error: 1.8719 - val_loss: 48708.2500 - val_mean_squared_error: 48708.2500 - val_mean_squared_logarithmic_error: 2.2419\n",
      "Epoch 99/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 32097.5215 - mean_squared_error: 32097.5215 - mean_squared_logarithmic_error: 1.8716 - val_loss: 47578.4766 - val_mean_squared_error: 47578.4766 - val_mean_squared_logarithmic_error: 2.1388\n",
      "Epoch 100/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32097.2441 - mean_squared_error: 32097.2441 - mean_squared_logarithmic_error: 1.8797 - val_loss: 48931.0664 - val_mean_squared_error: 48931.0664 - val_mean_squared_logarithmic_error: 2.2400\n"
     ]
    }
   ],
   "source": [
    "history_val = model_val.fit(X_test_pca, y_train, batch_size=2, epochs=100, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:55:29.141393Z",
     "start_time": "2021-05-10T23:55:29.134414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_squared_error', 'mean_squared_logarithmic_error', 'val_loss', 'val_mean_squared_error', 'val_mean_squared_logarithmic_error'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_val.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:56:15.558370Z",
     "start_time": "2021-05-10T23:56:15.293151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b3528ab430>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_val.history['mean_squared_error'])\n",
    "plt.plot(history_train.history['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:23:35.933634Z",
     "start_time": "2021-05-10T21:17:03.759534Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.77287256 0.75611395 0.75767496]\n",
      "CV accuracy: 0.762 +/- 0.008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n",
    "                         X=X_train_pca,\n",
    "                         y=y_train,\n",
    "                         cv=3,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:39:09.952954Z",
     "start_time": "2021-05-10T21:23:36.971524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.81833149 0.79541575 0.77822127 0.7775064  0.7816467 ]\n",
      "CV accuracy: 0.790 +/- 0.015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n",
    "                         X=X_train_pca,\n",
    "                         y=y_train,\n",
    "                         cv=5,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation curve vs learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:44:14.704462Z",
     "start_time": "2021-05-10T21:39:10.452298Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-2e5e1d59944f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                 learning_curve(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n\u001b[0m\u001b[0;32m      6\u001b[0m                                \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[1;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times)\u001b[0m\n\u001b[0;32m   1277\u001b[0m                 \u001b[0mtrain_test_proportions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_train_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1279\u001b[1;33m         out = parallel(delayed(_fit_and_score)(\n\u001b[0m\u001b[0;32m   1280\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1281\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    387\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \"\"\"\n\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores =\\\n",
    "                learning_curve(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n",
    "                               X=X_train_pca,\n",
    "                               y=y_train,\n",
    "                               train_sizes=np.linspace(0.1, 1.0, 4),\n",
    "                               cv=None,\n",
    "                               n_jobs=1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/06_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:44:14.709448Z",
     "start_time": "2021-05-10T21:17:11.097Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "                estimator=RandomForestRegressor(max_depth=None, random_state=42), \n",
    "                X=X_train, \n",
    "                y=y_train, \n",
    "                cv=None)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, \n",
    "         color='blue', marker='o', \n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(param_range, train_mean + train_std,\n",
    "                 train_mean - train_std, alpha=0.15,\n",
    "                 color='blue')\n",
    "\n",
    "plt.plot(param_range, test_mean, \n",
    "         color='green', linestyle='--', \n",
    "         marker='s', markersize=5, \n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(param_range, \n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std, \n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/06_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make it pipeline and apply to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "430.219px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
