{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the copy based on copy1, to conduct PCA before regression.** <br>\n",
    "Due to large dimension and computing capacity, must reduce dimension before doing regression.<br>\n",
    "Last version, failed to run RFE for feature selection. RFE is better when choosing a few features from a relatively small feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:13.655776Z",
     "start_time": "2021-05-10T22:55:13.649792Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\lzowe\\OneDrive - The City College of New York\\CCNY_Course\\Applied_Machine_Learning_and_Data_Mining\\codes\\project-product-price-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:15.442980Z",
     "start_time": "2021-05-10T22:55:13.982090Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from final.feature_extraction.vectorization import text_vectorizaion\n",
    "from final.dimension_reduction.feature_reduction import dimension_reduction\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.rcParams['figure.constrained_layout.use'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data processed using Tokenizing and tf-idf algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:25.896724Z",
     "start_time": "2021-05-10T22:55:18.343105Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/DSEI21000-S21/project-product-price-prediction/main/data/random_samples/stratified_sampling_clean_text_data_by_price_whigh_sz50000_1619835594.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:25.960604Z",
     "start_time": "2021-05-10T22:55:25.947595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 34)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:26.114192Z",
     "start_time": "2021-05-10T22:55:26.007430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_upper_char_count</th>\n",
       "      <th>item_name_stopword_count</th>\n",
       "      <th>item_name_punctuation_count</th>\n",
       "      <th>item_name_number_count</th>\n",
       "      <th>item_name_after_word_count</th>\n",
       "      <th>item_name_after_char_count</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.373508e+05</td>\n",
       "      <td>26.583180</td>\n",
       "      <td>150.390920</td>\n",
       "      <td>5.667798</td>\n",
       "      <td>1.876040</td>\n",
       "      <td>12.577260</td>\n",
       "      <td>7.67970</td>\n",
       "      <td>5.850200</td>\n",
       "      <td>0.499880</td>\n",
       "      <td>18.323300</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794540</td>\n",
       "      <td>0.192960</td>\n",
       "      <td>0.414340</td>\n",
       "      <td>0.177680</td>\n",
       "      <td>4.236300</td>\n",
       "      <td>24.381740</td>\n",
       "      <td>5.845573</td>\n",
       "      <td>1.991820</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>108.41749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.251891e+05</td>\n",
       "      <td>28.205148</td>\n",
       "      <td>161.300927</td>\n",
       "      <td>0.782677</td>\n",
       "      <td>5.826971</td>\n",
       "      <td>28.114883</td>\n",
       "      <td>10.36772</td>\n",
       "      <td>8.336725</td>\n",
       "      <td>1.229061</td>\n",
       "      <td>18.691275</td>\n",
       "      <td>...</td>\n",
       "      <td>5.226287</td>\n",
       "      <td>0.463088</td>\n",
       "      <td>0.828128</td>\n",
       "      <td>0.422508</td>\n",
       "      <td>1.535705</td>\n",
       "      <td>8.740065</td>\n",
       "      <td>1.210724</td>\n",
       "      <td>0.896911</td>\n",
       "      <td>0.484564</td>\n",
       "      <td>198.75487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.726685e+05</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>5.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.353620e+05</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>5.642857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.102881e+06</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>6.020944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482519e+06</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>761.000000</td>\n",
       "      <td>104.00000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_id  item_description_bef_word_count  \\\n",
       "count  5.000000e+04                     50000.000000   \n",
       "mean   7.373508e+05                        26.583180   \n",
       "std    4.251891e+05                        28.205148   \n",
       "min    1.900000e+01                         1.000000   \n",
       "25%    3.726685e+05                         8.000000   \n",
       "50%    7.353620e+05                        17.000000   \n",
       "75%    1.102881e+06                        34.000000   \n",
       "max    1.482519e+06                       206.000000   \n",
       "\n",
       "       item_description_bef_char_count  item_description_bef_avg_word_len  \\\n",
       "count                     50000.000000                       50000.000000   \n",
       "mean                        150.390920                           5.667798   \n",
       "std                         161.300927                           0.782677   \n",
       "min                           1.000000                           1.000000   \n",
       "25%                          46.000000                           5.210526   \n",
       "50%                          97.000000                           5.642857   \n",
       "75%                         191.000000                           6.020944   \n",
       "max                        1007.000000                          19.600000   \n",
       "\n",
       "       item_description_upper_word_count  item_description_upper_char_count  \\\n",
       "count                       50000.000000                       50000.000000   \n",
       "mean                            1.876040                          12.577260   \n",
       "std                             5.826971                          28.114883   \n",
       "min                             0.000000                           0.000000   \n",
       "25%                             0.000000                           2.000000   \n",
       "50%                             0.000000                           5.000000   \n",
       "75%                             1.000000                          12.000000   \n",
       "max                           178.000000                         761.000000   \n",
       "\n",
       "       item_description_stopword_count  item_description_punctuation_count  \\\n",
       "count                      50000.00000                        50000.000000   \n",
       "mean                           7.67970                            5.850200   \n",
       "std                           10.36772                            8.336725   \n",
       "min                            0.00000                            0.000000   \n",
       "25%                            1.00000                            1.000000   \n",
       "50%                            4.00000                            3.000000   \n",
       "75%                           10.00000                            8.000000   \n",
       "max                          104.00000                          308.000000   \n",
       "\n",
       "       item_description_number_count  item_description_after_word_count  ...  \\\n",
       "count                   50000.000000                       50000.000000  ...   \n",
       "mean                        0.499880                          18.323300  ...   \n",
       "std                         1.229061                          18.691275  ...   \n",
       "min                         0.000000                           1.000000  ...   \n",
       "25%                         0.000000                           7.000000  ...   \n",
       "50%                         0.000000                          12.000000  ...   \n",
       "75%                         1.000000                          23.000000  ...   \n",
       "max                        57.000000                         175.000000  ...   \n",
       "\n",
       "       item_name_upper_char_count  item_name_stopword_count  \\\n",
       "count                50000.000000              50000.000000   \n",
       "mean                     4.794540                  0.192960   \n",
       "std                      5.226287                  0.463088   \n",
       "min                      0.000000                  0.000000   \n",
       "25%                      2.000000                  0.000000   \n",
       "50%                      3.000000                  0.000000   \n",
       "75%                      6.000000                  0.000000   \n",
       "max                     37.000000                  6.000000   \n",
       "\n",
       "       item_name_punctuation_count  item_name_number_count  \\\n",
       "count                 50000.000000            50000.000000   \n",
       "mean                      0.414340                0.177680   \n",
       "std                       0.828128                0.422508   \n",
       "min                       0.000000                0.000000   \n",
       "25%                       0.000000                0.000000   \n",
       "50%                       0.000000                0.000000   \n",
       "75%                       1.000000                0.000000   \n",
       "max                      12.000000                9.000000   \n",
       "\n",
       "       item_name_after_word_count  item_name_after_char_count  \\\n",
       "count                50000.000000                50000.000000   \n",
       "mean                     4.236300                   24.381740   \n",
       "std                      1.535705                    8.740065   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      3.000000                   18.000000   \n",
       "50%                      4.000000                   25.000000   \n",
       "75%                      5.000000                   32.000000   \n",
       "max                     13.000000                   42.000000   \n",
       "\n",
       "       item_name_after_avg_word_len  item_condition_id      shipping  \\\n",
       "count                  50000.000000       50000.000000  50000.000000   \n",
       "mean                       5.845573           1.991820      0.376700   \n",
       "std                        1.210724           0.896911      0.484564   \n",
       "min                        1.000000           1.000000      0.000000   \n",
       "25%                        5.000000           1.000000      0.000000   \n",
       "50%                        5.750000           2.000000      0.000000   \n",
       "75%                        6.500000           3.000000      1.000000   \n",
       "max                       26.000000           5.000000      1.000000   \n",
       "\n",
       "             price  \n",
       "count  50000.00000  \n",
       "mean     108.41749  \n",
       "std      198.75487  \n",
       "min        3.00000  \n",
       "25%       20.00000  \n",
       "50%       50.00000  \n",
       "75%       90.00000  \n",
       "max     2009.00000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:26.208962Z",
     "start_time": "2021-05-10T22:55:26.165009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 34 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   train_id                             50000 non-null  int64  \n",
      " 1   clean_item_description               50000 non-null  object \n",
      " 2   item_description_bef_word_count      50000 non-null  float64\n",
      " 3   item_description_bef_char_count      50000 non-null  float64\n",
      " 4   item_description_bef_avg_word_len    50000 non-null  float64\n",
      " 5   item_description_upper_word_count    50000 non-null  float64\n",
      " 6   item_description_upper_char_count    50000 non-null  float64\n",
      " 7   item_description_stopword_count      50000 non-null  float64\n",
      " 8   item_description_punctuation_count   50000 non-null  float64\n",
      " 9   item_description_number_count        50000 non-null  float64\n",
      " 10  item_description_after_word_count    50000 non-null  float64\n",
      " 11  item_description_after_char_count    50000 non-null  float64\n",
      " 12  item_description_after_avg_word_len  50000 non-null  float64\n",
      " 13  clean_item_name                      50000 non-null  object \n",
      " 14  item_name_bef_word_count             50000 non-null  float64\n",
      " 15  item_name_bef_char_count             50000 non-null  float64\n",
      " 16  item_name_bef_avg_word_len           50000 non-null  float64\n",
      " 17  item_name_upper_word_count           50000 non-null  float64\n",
      " 18  item_name_upper_char_count           50000 non-null  float64\n",
      " 19  item_name_stopword_count             50000 non-null  float64\n",
      " 20  item_name_punctuation_count          50000 non-null  float64\n",
      " 21  item_name_number_count               50000 non-null  float64\n",
      " 22  item_name_after_word_count           50000 non-null  float64\n",
      " 23  item_name_after_char_count           50000 non-null  float64\n",
      " 24  item_name_after_avg_word_len         50000 non-null  float64\n",
      " 25  item_condition_id                    50000 non-null  int64  \n",
      " 26  category_name                        50000 non-null  object \n",
      " 27  brand_name                           50000 non-null  object \n",
      " 28  shipping                             50000 non-null  int64  \n",
      " 29  price                                50000 non-null  float64\n",
      " 30  c1                                   50000 non-null  object \n",
      " 31  c2                                   50000 non-null  object \n",
      " 32  c3                                   50000 non-null  object \n",
      " 33  price_bin                            50000 non-null  object \n",
      "dtypes: float64(23), int64(3), object(8)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:26.271760Z",
     "start_time": "2021-05-10T22:55:26.257761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42039,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean_item_name.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:26.333561Z",
     "start_time": "2021-05-10T22:55:26.306633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>clean_item_description</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>new tags</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Athletic Apparel/Shirts &amp; Tops</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>women</td>\n",
       "      <td>athletic apparel</td>\n",
       "      <td>shirts &amp; tops</td>\n",
       "      <td>(10, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>nastasya every hills lipstick fashion</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Lips</td>\n",
       "      <td>Anastasia Beverly Hills</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>beauty</td>\n",
       "      <td>makeup</td>\n",
       "      <td>lips</td>\n",
       "      <td>(20, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>brand new tags taken bag pictures</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jeans/Leggings</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>women</td>\n",
       "      <td>jeans</td>\n",
       "      <td>leggings</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>bought calves bit large frowned good condition...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>boots</td>\n",
       "      <td>(80, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>brand new box size 7youth859womens</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>athletic</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                             clean_item_description  \\\n",
       "0    806824                                           new tags   \n",
       "1    772820              nastasya every hills lipstick fashion   \n",
       "2   1423115                  brand new tags taken bag pictures   \n",
       "3    405853  bought calves bit large frowned good condition...   \n",
       "4   1172086                 brand new box size 7youth859womens   \n",
       "\n",
       "   item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0                              3.0                             13.0   \n",
       "1                              6.0                             42.0   \n",
       "2                             11.0                             54.0   \n",
       "3                             35.0                            188.0   \n",
       "4                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  ...  \\\n",
       "0                                 0.0                            0.0  ...   \n",
       "1                                 0.0                            0.0  ...   \n",
       "2                                 0.0                            0.0  ...   \n",
       "3                                 7.0                            1.0  ...   \n",
       "4                                 3.0                            0.0  ...   \n",
       "\n",
       "   item_name_after_avg_word_len  item_condition_id  \\\n",
       "0                      5.250000                  1   \n",
       "1                     10.000000                  1   \n",
       "2                      6.166667                  1   \n",
       "3                      5.333333                  3   \n",
       "4                      4.000000                  1   \n",
       "\n",
       "                          category_name               brand_name  shipping  \\\n",
       "0  Women/Athletic Apparel/Shirts & Tops                     Nike         1   \n",
       "1                    Beauty/Makeup/Lips  Anastasia Beverly Hills         0   \n",
       "2                  Women/Jeans/Leggings                  LuLaRoe         0   \n",
       "3                     Women/Shoes/Boots                   Hunter         0   \n",
       "4                  Women/Shoes/Athletic                     Nike         0   \n",
       "\n",
       "   price      c1                c2             c3  price_bin  \n",
       "0   15.0   women  athletic apparel  shirts & tops   (10, 15]  \n",
       "1   22.0  beauty            makeup           lips   (20, 25]  \n",
       "2   54.0   women             jeans       leggings   (50, 60]  \n",
       "3   84.0   women             shoes          boots   (80, 90]  \n",
       "4   56.0   women             shoes       athletic   (50, 60]  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Feature extraction and dimension selection\n",
    " \n",
    " For Item-discription feature: <br>\n",
    " using Jin's function to, firstly, do feature-extraction, increasing up to 14230 new few features <br>\n",
    " secondly, do dimenstion-reduction <br>\n",
    " finally, left 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:26.395393Z",
     "start_time": "2021-05-10T22:55:26.383454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corners bottom great shape lips smells markings inside cleanthere small water mark indicated third photo comes dusting'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean_item_description[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:28.438872Z",
     "start_time": "2021-05-10T22:55:26.459222Z"
    }
   },
   "outputs": [],
   "source": [
    "description_feature,  description_feature_name = text_vectorizaion(df, text_col = \"clean_item_description\", \n",
    "                                                                   tfidf = True, min_df=10, max_features=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:55:28.628255Z",
     "start_time": "2021-05-10T22:55:28.617327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 14230)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:11.265703Z",
     "start_time": "2021-05-10T23:13:33.374083Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dimension_reduction(description_feature.toarray(), method = 'SVD', n_comp = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:11.846208Z",
     "start_time": "2021-05-10T23:14:11.817233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:11.969822Z",
     "start_time": "2021-05-10T23:14:11.923945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.316579</td>\n",
       "      <td>0.226464</td>\n",
       "      <td>-0.093895</td>\n",
       "      <td>-0.145724</td>\n",
       "      <td>-0.160602</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>-0.018079</td>\n",
       "      <td>0.090897</td>\n",
       "      <td>0.191936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>-0.001485</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.003074</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>-0.002302</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004530</td>\n",
       "      <td>-0.028973</td>\n",
       "      <td>-0.005179</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>-0.009895</td>\n",
       "      <td>-0.007188</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>-0.015531</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>-0.014289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.282559</td>\n",
       "      <td>0.198734</td>\n",
       "      <td>-0.108191</td>\n",
       "      <td>-0.022313</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>-0.093215</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>-0.023777</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015969</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>-0.018547</td>\n",
       "      <td>-0.024160</td>\n",
       "      <td>-0.009791</td>\n",
       "      <td>-0.001747</td>\n",
       "      <td>-0.040102</td>\n",
       "      <td>-0.014540</td>\n",
       "      <td>-0.014426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.087350</td>\n",
       "      <td>-0.138583</td>\n",
       "      <td>-0.028884</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>-0.041196</td>\n",
       "      <td>-0.030511</td>\n",
       "      <td>0.157942</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.034407</td>\n",
       "      <td>-0.004016</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>-0.017683</td>\n",
       "      <td>0.013241</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.037753</td>\n",
       "      <td>0.027355</td>\n",
       "      <td>0.001946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.407447</td>\n",
       "      <td>0.230953</td>\n",
       "      <td>-0.090664</td>\n",
       "      <td>-0.028016</td>\n",
       "      <td>-0.120191</td>\n",
       "      <td>-0.079091</td>\n",
       "      <td>0.052895</td>\n",
       "      <td>-0.152945</td>\n",
       "      <td>-0.178799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017753</td>\n",
       "      <td>-0.004733</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>-0.006419</td>\n",
       "      <td>-0.024270</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.011555</td>\n",
       "      <td>-0.009351</td>\n",
       "      <td>0.008839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000323  0.316579  0.226464 -0.093895 -0.145724 -0.160602 -0.003326   \n",
       "1  0.000036  0.006363 -0.001485 -0.000307 -0.003074  0.008711  0.000234   \n",
       "2  0.000307  0.282559  0.198734 -0.108191 -0.022313 -0.049015 -0.093215   \n",
       "3  0.000196  0.087350 -0.138583 -0.028884 -0.007236 -0.041196 -0.030511   \n",
       "4  0.000409  0.407447  0.230953 -0.090664 -0.028016 -0.120191 -0.079091   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0 -0.018079  0.090897  0.191936  ...  0.001181 -0.000930  0.002708 -0.008270   \n",
       "1 -0.001263 -0.002302  0.001763  ... -0.004530 -0.028973 -0.005179  0.011471   \n",
       "2  0.013357 -0.023777  0.027220  ... -0.015969  0.005385  0.000088 -0.018547   \n",
       "3  0.157942  0.007499  0.001800  ...  0.011864  0.034407 -0.004016  0.005074   \n",
       "4  0.052895 -0.152945 -0.178799  ... -0.017753 -0.004733  0.017481 -0.006419   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.001943  0.007046  0.001599  0.009947  0.004283  0.001286  \n",
       "1 -0.009895 -0.007188 -0.006494 -0.015531  0.010362 -0.014289  \n",
       "2 -0.024160 -0.009791 -0.001747 -0.040102 -0.014540 -0.014426  \n",
       "3 -0.017683  0.013241  0.002016  0.037753  0.027355  0.001946  \n",
       "4 -0.024270  0.015141  0.005037  0.011555 -0.009351  0.008839  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cid = pd.DataFrame(data.copy()) #df for cleaned item description transforming to new features\n",
    "df_cid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating new features df_cid and previous df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:12.129397Z",
     "start_time": "2021-05-10T23:14:12.050607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Athletic Apparel/Shirts &amp; Tops</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>women</td>\n",
       "      <td>athletic apparel</td>\n",
       "      <td>shirts &amp; tops</td>\n",
       "      <td>(10, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Lips</td>\n",
       "      <td>Anastasia Beverly Hills</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>beauty</td>\n",
       "      <td>makeup</td>\n",
       "      <td>lips</td>\n",
       "      <td>(20, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jeans/Leggings</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>women</td>\n",
       "      <td>jeans</td>\n",
       "      <td>leggings</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>boots</td>\n",
       "      <td>(80, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>athletic</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0    806824                              3.0                             13.0   \n",
       "1    772820                              6.0                             42.0   \n",
       "2   1423115                             11.0                             54.0   \n",
       "3    405853                             35.0                            188.0   \n",
       "4   1172086                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  \\\n",
       "0                                 0.0                            0.0   \n",
       "1                                 0.0                            0.0   \n",
       "2                                 0.0                            0.0   \n",
       "3                                 7.0                            1.0   \n",
       "4                                 3.0                            0.0   \n",
       "\n",
       "   item_description_after_word_count  ...  item_name_after_avg_word_len  \\\n",
       "0                                2.0  ...                      5.250000   \n",
       "1                                5.0  ...                     10.000000   \n",
       "2                                6.0  ...                      6.166667   \n",
       "3                               17.0  ...                      5.333333   \n",
       "4                                5.0  ...                      4.000000   \n",
       "\n",
       "   item_condition_id                         category_name  \\\n",
       "0                  1  Women/Athletic Apparel/Shirts & Tops   \n",
       "1                  1                    Beauty/Makeup/Lips   \n",
       "2                  1                  Women/Jeans/Leggings   \n",
       "3                  3                     Women/Shoes/Boots   \n",
       "4                  1                  Women/Shoes/Athletic   \n",
       "\n",
       "                brand_name  shipping  price      c1                c2  \\\n",
       "0                     Nike         1   15.0   women  athletic apparel   \n",
       "1  Anastasia Beverly Hills         0   22.0  beauty            makeup   \n",
       "2                  LuLaRoe         0   54.0   women             jeans   \n",
       "3                   Hunter         0   84.0   women             shoes   \n",
       "4                     Nike         0   56.0   women             shoes   \n",
       "\n",
       "              c3  price_bin  \n",
       "0  shirts & tops   (10, 15]  \n",
       "1           lips   (20, 25]  \n",
       "2       leggings   (50, 60]  \n",
       "3          boots   (80, 90]  \n",
       "4       athletic   (50, 60]  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.copy()\n",
    "df1.drop(\"clean_item_description\", inplace=True,axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:12.287015Z",
     "start_time": "2021-05-10T23:14:12.242094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 33 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   train_id                             50000 non-null  int64  \n",
      " 1   item_description_bef_word_count      50000 non-null  float64\n",
      " 2   item_description_bef_char_count      50000 non-null  float64\n",
      " 3   item_description_bef_avg_word_len    50000 non-null  float64\n",
      " 4   item_description_upper_word_count    50000 non-null  float64\n",
      " 5   item_description_upper_char_count    50000 non-null  float64\n",
      " 6   item_description_stopword_count      50000 non-null  float64\n",
      " 7   item_description_punctuation_count   50000 non-null  float64\n",
      " 8   item_description_number_count        50000 non-null  float64\n",
      " 9   item_description_after_word_count    50000 non-null  float64\n",
      " 10  item_description_after_char_count    50000 non-null  float64\n",
      " 11  item_description_after_avg_word_len  50000 non-null  float64\n",
      " 12  clean_item_name                      50000 non-null  object \n",
      " 13  item_name_bef_word_count             50000 non-null  float64\n",
      " 14  item_name_bef_char_count             50000 non-null  float64\n",
      " 15  item_name_bef_avg_word_len           50000 non-null  float64\n",
      " 16  item_name_upper_word_count           50000 non-null  float64\n",
      " 17  item_name_upper_char_count           50000 non-null  float64\n",
      " 18  item_name_stopword_count             50000 non-null  float64\n",
      " 19  item_name_punctuation_count          50000 non-null  float64\n",
      " 20  item_name_number_count               50000 non-null  float64\n",
      " 21  item_name_after_word_count           50000 non-null  float64\n",
      " 22  item_name_after_char_count           50000 non-null  float64\n",
      " 23  item_name_after_avg_word_len         50000 non-null  float64\n",
      " 24  item_condition_id                    50000 non-null  int64  \n",
      " 25  category_name                        50000 non-null  object \n",
      " 26  brand_name                           50000 non-null  object \n",
      " 27  shipping                             50000 non-null  int64  \n",
      " 28  price                                50000 non-null  float64\n",
      " 29  c1                                   50000 non-null  object \n",
      " 30  c2                                   50000 non-null  object \n",
      " 31  c3                                   50000 non-null  object \n",
      " 32  price_bin                            50000 non-null  object \n",
      "dtypes: float64(23), int64(3), object(7)\n",
      "memory usage: 12.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:12.414632Z",
     "start_time": "2021-05-10T23:14:12.400672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 33), (50000, 100))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape,df_cid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:12.586368Z",
     "start_time": "2021-05-10T23:14:12.512396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 133)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat=pd.concat([df1,df_cid],axis=1)\n",
    "df_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using one-hot encoding for category and nominal features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete price bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:12.726731Z",
     "start_time": "2021-05-10T23:14:12.713701Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_catNnom = ['category_name','brand_name', 'c1', 'c2', 'c3'] # columns of category and nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:14.984983Z",
     "start_time": "2021-05-10T23:14:12.838952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3028)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from final.feature_encoding.one_hot_encoding import one_hot_encode_feature\n",
    "df_encode = df_concat\n",
    "for col in cols_catNnom:\n",
    "    df_encode, col_encode = one_hot_encode_feature(df_encode, encode_column=col,drop_first=False)\n",
    "df_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.091697Z",
     "start_time": "2021-05-10T23:14:14.986976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 3028 entries, train_id to c3_yoga & pilates\n",
      "dtypes: float64(123), int64(3), object(2), uint8(2900)\n",
      "memory usage: 187.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_encode.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.122613Z",
     "start_time": "2021-05-10T23:14:15.093690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>c3_window treatments</th>\n",
       "      <th>c3_wine, beer &amp; beverage coolers</th>\n",
       "      <th>c3_wipes &amp; holders</th>\n",
       "      <th>c3_women</th>\n",
       "      <th>c3_women's golf clubs</th>\n",
       "      <th>c3_wool</th>\n",
       "      <th>c3_work &amp; safety</th>\n",
       "      <th>c3_wrap</th>\n",
       "      <th>c3_writing</th>\n",
       "      <th>c3_yoga &amp; pilates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0    806824                              3.0                             13.0   \n",
       "1    772820                              6.0                             42.0   \n",
       "2   1423115                             11.0                             54.0   \n",
       "3    405853                             35.0                            188.0   \n",
       "4   1172086                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  \\\n",
       "0                                 0.0                            0.0   \n",
       "1                                 0.0                            0.0   \n",
       "2                                 0.0                            0.0   \n",
       "3                                 7.0                            1.0   \n",
       "4                                 3.0                            0.0   \n",
       "\n",
       "   item_description_after_word_count  ...  c3_window treatments  \\\n",
       "0                                2.0  ...                     0   \n",
       "1                                5.0  ...                     0   \n",
       "2                                6.0  ...                     0   \n",
       "3                               17.0  ...                     0   \n",
       "4                                5.0  ...                     0   \n",
       "\n",
       "   c3_wine, beer & beverage coolers c3_wipes & holders  c3_women  \\\n",
       "0                                 0                  0         0   \n",
       "1                                 0                  0         0   \n",
       "2                                 0                  0         0   \n",
       "3                                 0                  0         0   \n",
       "4                                 0                  0         0   \n",
       "\n",
       "   c3_women's golf clubs  c3_wool  c3_work & safety  c3_wrap  c3_writing  \\\n",
       "0                      0        0                 0        0           0   \n",
       "1                      0        0                 0        0           0   \n",
       "2                      0        0                 0        0           0   \n",
       "3                      0        0                 0        0           0   \n",
       "4                      0        0                 0        0           0   \n",
       "\n",
       "   c3_yoga & pilates  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 3028 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.138610Z",
     "start_time": "2021-05-10T23:14:15.125606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price\n",
       "0        15.0\n",
       "1        22.0\n",
       "2        54.0\n",
       "3        84.0\n",
       "4        56.0\n",
       "...       ...\n",
       "49995  1609.0\n",
       "49996   205.0\n",
       "49997    36.0\n",
       "49998    20.0\n",
       "49999    72.0\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encode[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.371160Z",
     "start_time": "2021-05-10T23:14:15.140567Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare input X, y\n",
    "X, y = df_encode.copy().drop([\"clean_item_name\",\"train_id\",\"price\",\"price_bin\"],axis=1), df_encode[[\"price\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.479881Z",
     "start_time": "2021-05-10T23:14:15.374142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 3024 entries, item_description_bef_word_count to c3_yoga & pilates\n",
      "dtypes: float64(122), int64(2), uint8(2900)\n",
      "memory usage: 185.6 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:15.891511Z",
     "start_time": "2021-05-10T23:14:15.483845Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct dimension reduction on the dateframe processed by one-hot encoding\n",
    "skip this step in the first place. <br>\n",
    "let us see how the regression result looks like. and then determine if the dimension reduction on whole dataset needed, or if use other techniques to avoid overfitting(e.g. adding penalty, using RobustScaler, conducting cross validation).<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 1: actually can't skip this step, the dimension is too large to run, Exception was raised: MemoryError: Unable to allocate 11.8 GiB for an array with shape (45079, 35000) and data type float64.\n",
    "Therefore, try conduct PCA again before regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 2: even can't not run PCA due to the large number of features. Try drop clean_item_name instead of encoding it, as it is has very less duplicated items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 3: Since log2 works, skip this step( e.i. 1.5) for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 4: features are too much later, have to reduce dimension at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:18.944806Z",
     "start_time": "2021-05-10T23:14:15.894439Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:22.937089Z",
     "start_time": "2021-05-10T23:14:18.946758Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00290463, 0.00227748, 0.0021392 , 0.00197141, 0.00187969,\n",
       "       0.00185723, 0.00180453, 0.00177984, 0.00174778, 0.00167633,\n",
       "       0.00161552, 0.00160401, 0.00154318, 0.00153357, 0.00145383,\n",
       "       0.00145094, 0.00143836, 0.00143613, 0.00143506, 0.00142606,\n",
       "       0.00141384, 0.00140871, 0.00140269, 0.00139759, 0.00139177,\n",
       "       0.00138739, 0.00138107, 0.00136905, 0.00136496, 0.00136107,\n",
       "       0.00135542, 0.00134973, 0.00133956, 0.00133637, 0.00132216,\n",
       "       0.00131045, 0.00130529, 0.00129102, 0.00127827, 0.00126776,\n",
       "       0.00126149, 0.00124665, 0.001242  , 0.00123949, 0.00122593,\n",
       "       0.0012158 , 0.00121305, 0.00120527, 0.00119444, 0.00117524])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50) # reduce features to 50\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:30:58.956957Z",
     "start_time": "2021-05-11T00:30:58.943615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 50), (15000, 50))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape, X_test_pca.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Selection\n",
    "Proposal:\n",
    "1. try different regression techniques, and select the best one;\n",
    "      - DT regressor\n",
    "      * Ensemble method\n",
    "      - Adding polynomial items to multiple linear regression? \n",
    "      - Tensorflow.Keras\n",
    "2. focus on the selected one and tuning modelling.(Guessing propably would use Ensemble learning or Keras in the end)<br>\n",
    "**Based on the our previous experiment so far, our results have both large bias and variance.** Probably need to use more powerful algorithm to improve the bias, and then considering solve overfitting issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:24.432427Z",
     "start_time": "2021-05-10T23:14:22.955042Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score,r2_score \n",
    "def evaluate_dt_regressor(X_train, X_test, y_train, y_test,n_iter,max_depth):\n",
    "    # the maximum depth of the tree. If None, then nodes are expanded until all leaves are pure\n",
    "    MSE_test=[]\n",
    "    EVS_test=[]\n",
    "    R2_test=[]\n",
    "    MSE_train=[]\n",
    "    EVS_train=[]\n",
    "    R2_train=[]\n",
    "    for i in range(n_iter):\n",
    "        rg = tree.DecisionTreeRegressor(max_depth=max_depth)\n",
    "        rg.fit(X_train, y_train)\n",
    "        y_train_pred = rg.predict(X_train)\n",
    "        y_pred = rg.predict(X_test)\n",
    "        MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "        EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "        R2_train.append(r2_score(y_train, y_train_pred))\n",
    "        \n",
    "        MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "        EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "        R2_test.append(r2_score(y_test, y_pred))\n",
    "    print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "    print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:27.799730Z",
     "start_time": "2021-05-10T23:14:24.434036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 1.4285714285714285e-05 EVS: 0.9999999996453222 R2: 0.9999999996453222\n",
      "Test score: MSE: 25453.1081 EVS: 0.32469162425114917 R2: 0.32468964011539003\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca, y_train, y_test,1,max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:31.063592Z",
     "start_time": "2021-05-10T23:14:30.502631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 27603.316402674467 EVS: 0.31468007373987195 R2: 0.31468007373987195\n",
      "Test score: MSE: 25451.206550664436 EVS: 0.3247873054026028 R2: 0.32474009116290425\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,y_train, y_test,1,max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:14:32.233789Z",
     "start_time": "2021-05-10T23:14:31.273341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 23710.359452021607 EVS: 0.41133226333317674 R2: 0.41133226333317674\n",
      "Test score: MSE: 22479.658016756082 EVS: 0.40358066969169526 R2: 0.4035798737923677\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,  y_train, y_test,1,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:30:58.705944Z",
     "start_time": "2021-05-11T00:30:25.047711Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 1.4285714285714289e-05 EVS: 0.9999999996453222 R2: 0.9999999996453222\n",
      "Test score: MSE: 24968.189694999997 EVS: 0.33756667512715666 R2: 0.337555276064786\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,  y_train, y_test,10,max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:51:43.841278Z",
     "start_time": "2021-05-11T00:51:36.050125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-71-6f87890d9029>:41: UserWarning: This figure was using constrained_layout==True, but that is incompatible with subplots_adjust and or tight_layout: setting constrained_layout==False. \n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores =\\\n",
    "                learning_curve(estimator=tree.DecisionTreeRegressor(max_depth=5),\n",
    "                               X=X_train_pca,\n",
    "                               y=y_train,\n",
    "                               train_sizes=np.linspace(0.1, 1.0, 4),\n",
    "                               cv=5,\n",
    "                               n_jobs=1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/06_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.321016Z",
     "start_time": "2021-05-10T23:15:05.260423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.01139248e+01,  3.33909961e+00, -1.24632424e+01,\n",
       "         2.92924271e-01, -4.78158123e+00,  1.28572231e+01,\n",
       "        -5.37623204e-01,  4.63062060e+00, -2.34387322e+01,\n",
       "        -6.38668717e+00,  1.11445240e+00, -9.80527906e+00,\n",
       "         1.93814162e+00, -5.89439692e+00,  3.45141980e+00,\n",
       "        -4.19551000e+00,  4.67771693e+00,  2.26721231e+00,\n",
       "        -2.52076644e+00,  3.12808726e-01, -3.33907395e+00,\n",
       "         3.45865149e-01, -2.20375317e-01, -1.06058981e+01,\n",
       "        -1.05208256e+01,  7.39183271e+00, -1.46368928e+00,\n",
       "        -1.93780801e+00, -2.03429896e+00,  5.88554372e+00,\n",
       "         4.62818933e+00, -6.53923613e+00, -5.64377145e+00,\n",
       "         6.17206393e+00,  8.76943599e+00,  1.76356336e+00,\n",
       "         5.56305871e+00, -1.55913194e+00,  2.25449809e+00,\n",
       "        -4.71081324e-01,  4.45548607e+00, -7.80405356e+00,\n",
       "        -6.10614015e+00, -3.82468595e+00, -8.02043049e-01,\n",
       "        -8.38901054e-01, -3.49886943e+00,  3.04608200e+00,\n",
       "         6.28226186e+00, -2.32166991e-02]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train_pca, y_train)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why linear regression is so slow. after 1 and harf hour, not completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.587377Z",
     "start_time": "2021-05-10T23:15:05.574337Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, explained_variance_score,r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.664097Z",
     "start_time": "2021-05-10T23:15:05.589298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'MSE': 28508.33052943577, 'EVS': 0.2922108817931993, 'R2': 0.2922108817931993}\n",
      "test: {'MSE': 25841.256944870216, 'EVS': 0.3144575277431273, 'R2': 0.3143914503977224}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train_pca, y_train)\n",
    "y_train_pred = reg.predict(X_train_pca)\n",
    "y_pred = reg.predict(X_test_pca)\n",
    "\n",
    "print(\"train:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_train, y_train_pred), \n",
    "    \"EVS\": explained_variance_score(y_train, y_train_pred), \n",
    "    \"R2\": r2_score(y_train, y_train_pred)\n",
    "})\n",
    "\n",
    "print(\"test:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred), \n",
    "    \"EVS\": explained_variance_score(y_test, y_pred), \n",
    "    \"R2\": r2_score(y_test, y_pred)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.725932Z",
     "start_time": "2021-05-10T23:15:05.666092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'MSE': 28508.3305295391, 'EVS': 0.2922108817906339, 'R2': 0.2922108817906338}\n",
      "test: {'MSE': 25841.25771250408, 'EVS': 0.31445750733101396, 'R2': 0.31439143003120773}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha=.5) # tuning alpha does not help\n",
    "reg.fit(X_train_pca, y_train)\n",
    "y_train_pred = reg.predict(X_train_pca)\n",
    "y_pred = reg.predict(X_test_pca)\n",
    "\n",
    "print(\"train:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_train, y_train_pred), \n",
    "    \"EVS\": explained_variance_score(y_train, y_train_pred), \n",
    "    \"R2\": r2_score(y_train, y_train_pred)\n",
    "})\n",
    "\n",
    "print(\"test:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred), \n",
    "    \"EVS\": explained_variance_score(y_test, y_pred), \n",
    "    \"R2\": r2_score(y_test, y_pred)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.804721Z",
     "start_time": "2021-05-10T23:15:05.728924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'MSE': 28516.26978674493, 'EVS': 0.2920137702883967, 'R2': 0.2920137702883967}\n",
      "test: {'MSE': 25860.14695920318, 'EVS': 0.313954114991316, 'R2': 0.31389026907529616}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso(alpha=0.8) # tuning alpha does not help\n",
    "reg.fit(X_train_pca, y_train)\n",
    "y_train_pred = reg.predict(X_train_pca)\n",
    "y_pred = reg.predict(X_test_pca)\n",
    "\n",
    "print(\"train:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_train, y_train_pred), \n",
    "    \"EVS\": explained_variance_score(y_train, y_train_pred), \n",
    "    \"R2\": r2_score(y_train, y_train_pred)\n",
    "})\n",
    "\n",
    "print(\"test:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred), \n",
    "    \"EVS\": explained_variance_score(y_test, y_pred), \n",
    "    \"R2\": r2_score(y_test, y_pred)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Bagging) for classification, also for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:15:05.865558Z",
     "start_time": "2021-05-10T23:15:05.806715Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def evaluate_rf_regressor(X_train, X_test, y_train, y_test,n_iter,max_depth,random_state):\n",
    "    MSE_test=[]\n",
    "    EVS_test=[]\n",
    "    R2_test=[]\n",
    "    MSE_train=[]\n",
    "    EVS_train=[]\n",
    "    R2_train=[]\n",
    "    for i in range(n_iter):\n",
    "        rg = RandomForestRegressor(max_depth=max_depth, random_state=random_state)\n",
    "        rg.fit(X_train, y_train)\n",
    "        y_train_pred = rg.predict(X_train)\n",
    "        y_pred = rg.predict(X_test)\n",
    "        MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "        EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "        R2_train.append(r2_score(y_train, y_train_pred))\n",
    "        \n",
    "        MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "        EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "        R2_test.append(r2_score(y_test, y_pred))\n",
    "    print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "    print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_regressor turns out very very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:18:22.715535Z",
     "start_time": "2021-05-10T23:15:05.867553Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-ffee7f25d399>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rg.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 977.6322390524449 EVS: 0.9762643748608849 R2: 0.9757278855843557\n",
      "Test score: MSE: 10828.01092624251 EVS: 0.7128459008502149 R2: 0.7127161081190192\n"
     ]
    }
   ],
   "source": [
    "evaluate_rf_regressor(X_train_pca, X_test_pca, y_train, y_test,1,max_depth=None,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:18:53.271110Z",
     "start_time": "2021-05-10T23:18:22.717528Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-558030b727bd>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rg.fit(X_train_pca, y_train)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-558030b727bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mMSE_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    387\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \"\"\"\n\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rg = RandomForestRegressor(max_depth=None, random_state=42)\n",
    "rg.fit(X_train_pca, y_train)\n",
    "y_train_pred = rg.predict(X_train_pca)\n",
    "y_pred = rg.predict(X_test_pca)\n",
    "MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "R2_train.append(r2_score(y_train, y_train_pred))\n",
    "\n",
    "MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "R2_test.append(r2_score(y_test, y_pred))\n",
    "print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:09:48.005739Z",
     "start_time": "2021-05-04T13:09:47.465304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rg.feature_importances_\n",
    "importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:09:49.846589Z",
     "start_time": "2021-05-04T13:09:49.835306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3024)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:14:07.663612Z",
     "start_time": "2021-05-04T13:14:07.573550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 7                              0.105877\n",
      " 2) 24                             0.063736\n",
      " 3) 33                             0.055135\n",
      " 4) 288                            0.033101\n",
      " 5) 1                              0.030501\n",
      " 6) 10                             0.025732\n",
      " 7) 316                            0.017765\n",
      " 8) 89                             0.014740\n",
      " 9) 48                             0.012854\n",
      "10) 469                            0.012297\n",
      "11) 11                             0.010544\n",
      "12) 262                            0.009389\n",
      "13) 2                              0.008283\n",
      "14) 0                              0.007948\n",
      "15) 14                             0.007850\n",
      "16) 491                            0.007349\n",
      "17) 57                             0.006804\n",
      "18) 6                              0.006769\n",
      "19) 34                             0.006605\n",
      "20) 46                             0.006498\n",
      "21) 261                            0.005871\n",
      "22) 476                            0.005158\n",
      "23) 483                            0.004931\n",
      "24) 192                            0.004860\n",
      "25) 252                            0.004593\n",
      "26) 8                              0.004519\n",
      "27) 285                            0.004433\n",
      "28) 273                            0.004364\n",
      "29) 216                            0.004305\n",
      "30) 467                            0.004116\n",
      "31) 116                            0.003915\n",
      "32) 27                             0.003776\n",
      "33) 323                            0.003739\n",
      "34) 175                            0.003534\n",
      "35) 242                            0.003235\n",
      "36) 299                            0.003226\n",
      "37) 399                            0.003218\n",
      "38) 32                             0.003109\n",
      "39) 470                            0.002954\n",
      "40) 25                             0.002944\n",
      "41) 70                             0.002937\n",
      "42) 167                            0.002923\n",
      "43) 455                            0.002843\n",
      "44) 5                              0.002751\n",
      "45) 235                            0.002579\n",
      "46) 477                            0.002554\n",
      "47) 3                              0.002538\n",
      "48) 20                             0.002510\n",
      "49) 39                             0.002465\n",
      "50) 208                            0.002452\n",
      "51) 493                            0.002441\n",
      "52) 269                            0.002374\n",
      "53) 80                             0.002358\n",
      "54) 170                            0.002353\n",
      "55) 321                            0.002326\n",
      "56) 120                            0.002315\n",
      "57) 174                            0.002315\n",
      "58) 484                            0.002294\n",
      "59) 318                            0.002258\n",
      "60) 472                            0.002208\n",
      "61) 26                             0.002193\n",
      "62) 125                            0.002192\n",
      "63) 495                            0.002172\n",
      "64) 274                            0.002160\n",
      "65) 103                            0.002083\n",
      "66) 38                             0.002052\n",
      "67) 222                            0.002014\n",
      "68) 437                            0.001982\n",
      "69) 129                            0.001977\n",
      "70) 15                             0.001932\n",
      "71) 489                            0.001922\n",
      "72) 180                            0.001899\n",
      "73) 390                            0.001878\n",
      "74) 259                            0.001860\n",
      "75) 209                            0.001827\n",
      "76) 91                             0.001807\n",
      "77) 99                             0.001794\n",
      "78) 84                             0.001762\n",
      "79) 479                            0.001747\n",
      "80) 492                            0.001742\n",
      "81) 376                            0.001733\n",
      "82) 12                             0.001718\n",
      "83) 402                            0.001680\n",
      "84) 189                            0.001679\n",
      "85) 355                            0.001668\n",
      "86) 218                            0.001644\n",
      "87) 104                            0.001614\n",
      "88) 71                             0.001593\n",
      "89) 113                            0.001578\n",
      "90) 450                            0.001569\n",
      "91) 409                            0.001556\n",
      "92) 223                            0.001526\n",
      "93) 72                             0.001523\n",
      "94) 298                            0.001514\n",
      "95) 217                            0.001507\n",
      "96) 327                            0.001496\n",
      "97) 154                            0.001495\n",
      "98) 244                            0.001493\n",
      "99) 40                             0.001477\n",
      "100) 162                            0.001472\n",
      "101) 443                            0.001471\n",
      "102) 254                            0.001451\n",
      "103) 258                            0.001448\n",
      "104) 58                             0.001448\n",
      "105) 419                            0.001445\n",
      "106) 311                            0.001441\n",
      "107) 90                             0.001437\n",
      "108) 148                            0.001434\n",
      "109) 291                            0.001429\n",
      "110) 434                            0.001424\n",
      "111) 105                            0.001421\n",
      "112) 28                             0.001421\n",
      "113) 9                              0.001420\n",
      "114) 485                            0.001408\n",
      "115) 52                             0.001407\n",
      "116) 315                            0.001406\n",
      "117) 94                             0.001392\n",
      "118) 13                             0.001392\n",
      "119) 23                             0.001391\n",
      "120) 176                            0.001376\n",
      "121) 418                            0.001368\n",
      "122) 386                            0.001367\n",
      "123) 303                            0.001366\n",
      "124) 268                            0.001365\n",
      "125) 30                             0.001357\n",
      "126) 119                            0.001347\n",
      "127) 356                            0.001347\n",
      "128) 87                             0.001345\n",
      "129) 49                             0.001341\n",
      "130) 73                             0.001339\n",
      "131) 276                            0.001336\n",
      "132) 481                            0.001335\n",
      "133) 42                             0.001318\n",
      "134) 461                            0.001309\n",
      "135) 230                            0.001309\n",
      "136) 100                            0.001309\n",
      "137) 111                            0.001304\n",
      "138) 494                            0.001299\n",
      "139) 382                            0.001298\n",
      "140) 295                            0.001288\n",
      "141) 92                             0.001279\n",
      "142) 83                             0.001278\n",
      "143) 385                            0.001275\n",
      "144) 248                            0.001273\n",
      "145) 465                            0.001262\n",
      "146) 499                            0.001251\n",
      "147) 131                            0.001248\n",
      "148) 183                            0.001246\n",
      "149) 279                            0.001242\n",
      "150) 50                             0.001236\n",
      "151) 246                            0.001232\n",
      "152) 79                             0.001230\n",
      "153) 220                            0.001230\n",
      "154) 411                            0.001228\n",
      "155) 159                            0.001227\n",
      "156) 96                             0.001226\n",
      "157) 497                            0.001223\n",
      "158) 294                            0.001212\n",
      "159) 236                            0.001210\n",
      "160) 102                            0.001204\n",
      "161) 460                            0.001184\n",
      "162) 77                             0.001182\n",
      "163) 18                             0.001176\n",
      "164) 41                             0.001174\n",
      "165) 47                             0.001172\n",
      "166) 452                            0.001158\n",
      "167) 212                            0.001147\n",
      "168) 283                            0.001138\n",
      "169) 496                            0.001135\n",
      "170) 108                            0.001127\n",
      "171) 107                            0.001126\n",
      "172) 146                            0.001125\n",
      "173) 381                            0.001123\n",
      "174) 449                            0.001115\n",
      "175) 413                            0.001109\n",
      "176) 51                             0.001106\n",
      "177) 158                            0.001103\n",
      "178) 98                             0.001100\n",
      "179) 426                            0.001099\n",
      "180) 31                             0.001098\n",
      "181) 63                             0.001096\n",
      "182) 150                            0.001091\n",
      "183) 439                            0.001089\n",
      "184) 21                             0.001088\n",
      "185) 344                            0.001086\n",
      "186) 482                            0.001083\n",
      "187) 458                            0.001081\n",
      "188) 78                             0.001080\n",
      "189) 332                            0.001070\n",
      "190) 16                             0.001064\n",
      "191) 238                            0.001063\n",
      "192) 416                            0.001059\n",
      "193) 322                            0.001058\n",
      "194) 290                            0.001055\n",
      "195) 320                            0.001054\n",
      "196) 287                            0.001052\n",
      "197) 374                            0.001044\n",
      "198) 166                            0.001040\n",
      "199) 474                            0.001031\n",
      "200) 66                             0.001031\n",
      "201) 369                            0.001027\n",
      "202) 312                            0.001026\n",
      "203) 463                            0.001023\n",
      "204) 251                            0.001019\n",
      "205) 114                            0.001019\n",
      "206) 112                            0.001017\n",
      "207) 4                              0.001013\n",
      "208) 420                            0.001012\n",
      "209) 35                             0.001010\n",
      "210) 117                            0.001004\n",
      "211) 227                            0.001004\n",
      "212) 115                            0.001001\n",
      "213) 490                            0.001000\n",
      "214) 86                             0.000999\n",
      "215) 234                            0.000995\n",
      "216) 328                            0.000995\n",
      "217) 68                             0.000992\n",
      "218) 186                            0.000990\n",
      "219) 53                             0.000989\n",
      "220) 142                            0.000986\n",
      "221) 178                            0.000986\n",
      "222) 448                            0.000985\n",
      "223) 237                            0.000982\n",
      "224) 301                            0.000982\n",
      "225) 256                            0.000979\n",
      "226) 267                            0.000969\n",
      "227) 309                            0.000968\n",
      "228) 128                            0.000967\n",
      "229) 67                             0.000964\n",
      "230) 134                            0.000962\n",
      "231) 480                            0.000959\n",
      "232) 181                            0.000957\n",
      "233) 36                             0.000957\n",
      "234) 135                            0.000954\n",
      "235) 253                            0.000953\n",
      "236) 410                            0.000951\n",
      "237) 471                            0.000945\n",
      "238) 106                            0.000945\n",
      "239) 165                            0.000942\n",
      "240) 200                            0.000942\n",
      "241) 468                            0.000942\n",
      "242) 171                            0.000941\n",
      "243) 398                            0.000941\n",
      "244) 286                            0.000940\n",
      "245) 475                            0.000940\n",
      "246) 144                            0.000939\n",
      "247) 199                            0.000938\n",
      "248) 407                            0.000936\n",
      "249) 93                             0.000934\n",
      "250) 394                            0.000934\n",
      "251) 447                            0.000930\n",
      "252) 488                            0.000929\n",
      "253) 423                            0.000928\n",
      "254) 61                             0.000924\n",
      "255) 330                            0.000923\n",
      "256) 215                            0.000921\n",
      "257) 155                            0.000920\n",
      "258) 55                             0.000913\n",
      "259) 457                            0.000909\n",
      "260) 352                            0.000909\n",
      "261) 179                            0.000906\n",
      "262) 388                            0.000905\n",
      "263) 335                            0.000904\n",
      "264) 319                            0.000899\n",
      "265) 195                            0.000898\n",
      "266) 459                            0.000897\n",
      "267) 76                             0.000894\n",
      "268) 44                             0.000891\n",
      "269) 375                            0.000890\n",
      "270) 438                            0.000890\n",
      "271) 453                            0.000887\n",
      "272) 313                            0.000886\n",
      "273) 22                             0.000885\n",
      "274) 271                            0.000883\n",
      "275) 266                            0.000882\n",
      "276) 451                            0.000881\n",
      "277) 60                             0.000881\n",
      "278) 349                            0.000881\n",
      "279) 264                            0.000880\n",
      "280) 121                            0.000877\n",
      "281) 370                            0.000876\n",
      "282) 153                            0.000876\n",
      "283) 314                            0.000868\n",
      "284) 280                            0.000867\n",
      "285) 401                            0.000867\n",
      "286) 29                             0.000866\n",
      "287) 184                            0.000860\n",
      "288) 387                            0.000860\n",
      "289) 126                            0.000859\n",
      "290) 19                             0.000853\n",
      "291) 211                            0.000852\n",
      "292) 110                            0.000852\n",
      "293) 431                            0.000851\n",
      "294) 182                            0.000847\n",
      "295) 289                            0.000843\n",
      "296) 446                            0.000841\n",
      "297) 62                             0.000837\n",
      "298) 337                            0.000835\n",
      "299) 462                            0.000835\n",
      "300) 417                            0.000833\n",
      "301) 231                            0.000831\n",
      "302) 270                            0.000827\n",
      "303) 168                            0.000826\n",
      "304) 338                            0.000826\n",
      "305) 172                            0.000825\n",
      "306) 308                            0.000823\n",
      "307) 132                            0.000821\n",
      "308) 265                            0.000818\n",
      "309) 421                            0.000817\n",
      "310) 45                             0.000817\n",
      "311) 487                            0.000815\n",
      "312) 198                            0.000809\n",
      "313) 436                            0.000808\n",
      "314) 228                            0.000807\n",
      "315) 341                            0.000806\n",
      "316) 161                            0.000805\n",
      "317) 428                            0.000802\n",
      "318) 293                            0.000802\n",
      "319) 151                            0.000801\n",
      "320) 361                            0.000799\n",
      "321) 359                            0.000798\n",
      "322) 464                            0.000794\n",
      "323) 353                            0.000791\n",
      "324) 367                            0.000791\n",
      "325) 284                            0.000790\n",
      "326) 122                            0.000789\n",
      "327) 37                             0.000788\n",
      "328) 194                            0.000787\n",
      "329) 240                            0.000783\n",
      "330) 354                            0.000778\n",
      "331) 221                            0.000776\n",
      "332) 430                            0.000776\n",
      "333) 101                            0.000776\n",
      "334) 203                            0.000775\n",
      "335) 404                            0.000772\n",
      "336) 249                            0.000772\n",
      "337) 81                             0.000769\n",
      "338) 56                             0.000765\n",
      "339) 396                            0.000765\n",
      "340) 444                            0.000763\n",
      "341) 331                            0.000760\n",
      "342) 445                            0.000760\n",
      "343) 325                            0.000757\n",
      "344) 306                            0.000756\n",
      "345) 435                            0.000755\n",
      "346) 362                            0.000754\n",
      "347) 219                            0.000753\n",
      "348) 351                            0.000753\n",
      "349) 124                            0.000750\n",
      "350) 422                            0.000748\n",
      "351) 17                             0.000748\n",
      "352) 147                            0.000746\n",
      "353) 282                            0.000746\n",
      "354) 160                            0.000746\n",
      "355) 202                            0.000745\n",
      "356) 272                            0.000744\n",
      "357) 406                            0.000740\n",
      "358) 43                             0.000738\n",
      "359) 281                            0.000738\n",
      "360) 123                            0.000737\n",
      "361) 345                            0.000735\n",
      "362) 185                            0.000733\n",
      "363) 74                             0.000733\n",
      "364) 133                            0.000731\n",
      "365) 145                            0.000730\n",
      "366) 383                            0.000726\n",
      "367) 339                            0.000726\n",
      "368) 310                            0.000722\n",
      "369) 486                            0.000721\n",
      "370) 164                            0.000717\n",
      "371) 454                            0.000714\n",
      "372) 173                            0.000711\n",
      "373) 75                             0.000708\n",
      "374) 317                            0.000706\n",
      "375) 141                            0.000705\n",
      "376) 427                            0.000704\n",
      "377) 363                            0.000703\n",
      "378) 278                            0.000702\n",
      "379) 69                             0.000702\n",
      "380) 263                            0.000701\n",
      "381) 229                            0.000701\n",
      "382) 54                             0.000698\n",
      "383) 210                            0.000698\n",
      "384) 441                            0.000693\n",
      "385) 241                            0.000691\n",
      "386) 243                            0.000689\n",
      "387) 478                            0.000686\n",
      "388) 473                            0.000683\n",
      "389) 204                            0.000682\n",
      "390) 371                            0.000681\n",
      "391) 187                            0.000679\n",
      "392) 257                            0.000676\n",
      "393) 225                            0.000674\n",
      "394) 296                            0.000672\n",
      "395) 350                            0.000671\n",
      "396) 156                            0.000670\n",
      "397) 95                             0.000670\n",
      "398) 177                            0.000670\n",
      "399) 82                             0.000669\n",
      "400) 336                            0.000666\n",
      "401) 429                            0.000665\n",
      "402) 307                            0.000665\n",
      "403) 346                            0.000663\n",
      "404) 233                            0.000663\n",
      "405) 140                            0.000662\n",
      "406) 403                            0.000660\n",
      "407) 456                            0.000659\n",
      "408) 188                            0.000658\n",
      "409) 127                            0.000657\n",
      "410) 405                            0.000656\n",
      "411) 152                            0.000654\n",
      "412) 466                            0.000652\n",
      "413) 138                            0.000648\n",
      "414) 373                            0.000648\n",
      "415) 224                            0.000647\n",
      "416) 408                            0.000643\n",
      "417) 232                            0.000639\n",
      "418) 137                            0.000637\n",
      "419) 326                            0.000635\n",
      "420) 143                            0.000632\n",
      "421) 292                            0.000631\n",
      "422) 277                            0.000629\n",
      "423) 136                            0.000627\n",
      "424) 85                             0.000624\n",
      "425) 88                             0.000624\n",
      "426) 414                            0.000623\n",
      "427) 364                            0.000622\n",
      "428) 365                            0.000620\n",
      "429) 226                            0.000619\n",
      "430) 360                            0.000617\n",
      "431) 300                            0.000616\n",
      "432) 118                            0.000612\n",
      "433) 206                            0.000612\n",
      "434) 302                            0.000612\n",
      "435) 368                            0.000607\n",
      "436) 432                            0.000604\n",
      "437) 149                            0.000603\n",
      "438) 329                            0.000594\n",
      "439) 297                            0.000593\n",
      "440) 348                            0.000593\n",
      "441) 392                            0.000592\n",
      "442) 377                            0.000592\n",
      "443) 415                            0.000590\n",
      "444) 139                            0.000589\n",
      "445) 190                            0.000588\n",
      "446) 201                            0.000586\n",
      "447) 498                            0.000586\n",
      "448) 191                            0.000584\n",
      "449) 340                            0.000582\n",
      "450) 197                            0.000580\n",
      "451) 247                            0.000580\n",
      "452) 333                            0.000580\n",
      "453) 347                            0.000577\n",
      "454) 260                            0.000577\n",
      "455) 59                             0.000576\n",
      "456) 130                            0.000573\n",
      "457) 196                            0.000571\n",
      "458) 357                            0.000567\n",
      "459) 245                            0.000565\n",
      "460) 433                            0.000563\n",
      "461) 275                            0.000561\n",
      "462) 412                            0.000561\n",
      "463) 255                            0.000561\n",
      "464) 97                             0.000559\n",
      "465) 442                            0.000554\n",
      "466) 372                            0.000553\n",
      "467) 378                            0.000551\n",
      "468) 250                            0.000550\n",
      "469) 64                             0.000550\n",
      "470) 109                            0.000548\n",
      "471) 393                            0.000548\n",
      "472) 213                            0.000547\n",
      "473) 440                            0.000539\n",
      "474) 343                            0.000538\n",
      "475) 395                            0.000537\n",
      "476) 305                            0.000536\n",
      "477) 342                            0.000533\n",
      "478) 324                            0.000531\n",
      "479) 397                            0.000526\n",
      "480) 214                            0.000522\n",
      "481) 205                            0.000521\n",
      "482) 379                            0.000520\n",
      "483) 391                            0.000517\n",
      "484) 65                             0.000515\n",
      "485) 389                            0.000515\n",
      "486) 384                            0.000515\n",
      "487) 163                            0.000507\n",
      "488) 304                            0.000497\n",
      "489) 366                            0.000495\n",
      "490) 424                            0.000494\n",
      "491) 193                            0.000486\n",
      "492) 207                            0.000483\n",
      "493) 358                            0.000476\n",
      "494) 169                            0.000476\n",
      "495) 425                            0.000473\n",
      "496) 239                            0.000469\n",
      "497) 334                            0.000453\n",
      "498) 157                            0.000446\n",
      "499) 380                            0.000433\n",
      "500) 400                            0.000413\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 500 is out of bounds for axis 0 with size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-665614754bd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     print(\"%2d) %-*s %f\" % (f + 1, 30, \n\u001b[1;32m----> 6\u001b[1;33m                             \u001b[0mfeat_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                             importances[indices[f]]))\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 500 is out of bounds for axis 0 with size 500"
     ]
    }
   ],
   "source": [
    "feat_labels = range(X_train_pca.shape[1])\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train_pca.shape[1]), \n",
    "        importances[indices],\n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train_pca.shape[1]), \n",
    "           feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train_pca.shape[1]])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/04_09.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning multiple linear regression with polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:19:06.120875Z",
     "start_time": "2021-05-10T23:19:06.114838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:19:08.498431Z",
     "start_time": "2021-05-10T23:19:08.492444Z"
    }
   },
   "outputs": [],
   "source": [
    "def r_2_score(y_true, y_pred):\n",
    "    from tensorflow.keras import backend as K\n",
    "    RSS =  K.sum(K.square( y_true- y_pred ))\n",
    "    TSS = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1. - RSS/(TSS) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:19:09.124905Z",
     "start_time": "2021-05-10T23:19:09.109659Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:30:31.851509Z",
     "start_time": "2021-05-10T23:30:31.805786Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X_train_pca.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model_train = Model(inputs=input_layer, outputs=output)\n",
    "model_train.compile(loss=\"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\",\"mean_squared_logarithmic_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:52:03.939230Z",
     "start_time": "2021-05-10T23:30:32.071055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 27596.1348 - mean_squared_error: 27596.1348 - mean_squared_logarithmic_error: 1.2500 - val_loss: 25329.7012 - val_mean_squared_error: 25329.7012 - val_mean_squared_logarithmic_error: 1.1910\n",
      "Epoch 2/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 23104.7715 - mean_squared_error: 23104.7715 - mean_squared_logarithmic_error: 1.0373 - val_loss: 21706.9902 - val_mean_squared_error: 21706.9902 - val_mean_squared_logarithmic_error: 0.9479\n",
      "Epoch 3/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 21469.6289 - mean_squared_error: 21469.6289 - mean_squared_logarithmic_error: 0.9764 - val_loss: 21258.8203 - val_mean_squared_error: 21258.8203 - val_mean_squared_logarithmic_error: 1.0591\n",
      "Epoch 4/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 20243.5508 - mean_squared_error: 20243.5508 - mean_squared_logarithmic_error: 0.9568 - val_loss: 20111.1914 - val_mean_squared_error: 20111.1914 - val_mean_squared_logarithmic_error: 0.9289\n",
      "Epoch 5/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 19365.1680 - mean_squared_error: 19365.1680 - mean_squared_logarithmic_error: 0.9186 - val_loss: 19669.8867 - val_mean_squared_error: 19669.8867 - val_mean_squared_logarithmic_error: 0.8521\n",
      "Epoch 6/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 18971.2871 - mean_squared_error: 18971.2871 - mean_squared_logarithmic_error: 0.9002 - val_loss: 18946.7148 - val_mean_squared_error: 18946.7148 - val_mean_squared_logarithmic_error: 0.9812\n",
      "Epoch 7/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 18460.4648 - mean_squared_error: 18460.4648 - mean_squared_logarithmic_error: 0.8920 - val_loss: 17878.2910 - val_mean_squared_error: 17878.2910 - val_mean_squared_logarithmic_error: 0.8742\n",
      "Epoch 8/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 17803.7305 - mean_squared_error: 17803.7305 - mean_squared_logarithmic_error: 0.8705 - val_loss: 18299.5547 - val_mean_squared_error: 18299.5547 - val_mean_squared_logarithmic_error: 0.8113\n",
      "Epoch 9/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 17606.3730 - mean_squared_error: 17606.3730 - mean_squared_logarithmic_error: 0.8514 - val_loss: 18484.0098 - val_mean_squared_error: 18484.0098 - val_mean_squared_logarithmic_error: 1.0244\n",
      "Epoch 10/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 17104.4355 - mean_squared_error: 17104.4355 - mean_squared_logarithmic_error: 0.8451 - val_loss: 17703.4688 - val_mean_squared_error: 17703.4688 - val_mean_squared_logarithmic_error: 0.8590\n",
      "Epoch 11/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16580.9199 - mean_squared_error: 16580.9199 - mean_squared_logarithmic_error: 0.8340 - val_loss: 19738.0547 - val_mean_squared_error: 19738.0547 - val_mean_squared_logarithmic_error: 1.0174\n",
      "Epoch 12/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16568.9668 - mean_squared_error: 16568.9668 - mean_squared_logarithmic_error: 0.8325 - val_loss: 18725.0977 - val_mean_squared_error: 18725.0977 - val_mean_squared_logarithmic_error: 0.8806\n",
      "Epoch 13/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16169.7793 - mean_squared_error: 16169.7793 - mean_squared_logarithmic_error: 0.8221 - val_loss: 21519.7422 - val_mean_squared_error: 21519.7422 - val_mean_squared_logarithmic_error: 0.8062\n",
      "Epoch 14/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16125.0830 - mean_squared_error: 16125.0830 - mean_squared_logarithmic_error: 0.8179 - val_loss: 18975.1289 - val_mean_squared_error: 18975.1289 - val_mean_squared_logarithmic_error: 0.7842\n",
      "Epoch 15/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15619.8008 - mean_squared_error: 15619.8008 - mean_squared_logarithmic_error: 0.8087 - val_loss: 19481.1230 - val_mean_squared_error: 19481.1230 - val_mean_squared_logarithmic_error: 0.7829\n",
      "Epoch 16/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15560.1562 - mean_squared_error: 15560.1562 - mean_squared_logarithmic_error: 0.7977 - val_loss: 16526.0820 - val_mean_squared_error: 16526.0820 - val_mean_squared_logarithmic_error: 0.7614\n",
      "Epoch 17/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15207.5615 - mean_squared_error: 15207.5615 - mean_squared_logarithmic_error: 0.7936 - val_loss: 21504.8242 - val_mean_squared_error: 21504.8242 - val_mean_squared_logarithmic_error: 0.9012\n",
      "Epoch 18/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 14875.1943 - mean_squared_error: 14875.1943 - mean_squared_logarithmic_error: 0.7862 - val_loss: 17747.4414 - val_mean_squared_error: 17747.4414 - val_mean_squared_logarithmic_error: 0.8990\n",
      "Epoch 19/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 14555.4326 - mean_squared_error: 14555.4326 - mean_squared_logarithmic_error: 0.7724 - val_loss: 18384.6758 - val_mean_squared_error: 18384.6758 - val_mean_squared_logarithmic_error: 0.8570\n",
      "Epoch 20/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 14297.9316 - mean_squared_error: 14297.9316 - mean_squared_logarithmic_error: 0.7720 - val_loss: 15992.8867 - val_mean_squared_error: 15992.8867 - val_mean_squared_logarithmic_error: 0.8286\n",
      "Epoch 21/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 14412.5430 - mean_squared_error: 14412.5430 - mean_squared_logarithmic_error: 0.7668 - val_loss: 16223.9395 - val_mean_squared_error: 16223.9395 - val_mean_squared_logarithmic_error: 0.8415\n",
      "Epoch 22/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 14043.5225 - mean_squared_error: 14043.5225 - mean_squared_logarithmic_error: 0.7701 - val_loss: 15205.5332 - val_mean_squared_error: 15205.5332 - val_mean_squared_logarithmic_error: 0.7794\n",
      "Epoch 23/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13779.6689 - mean_squared_error: 13779.6689 - mean_squared_logarithmic_error: 0.7623 - val_loss: 15780.1279 - val_mean_squared_error: 15780.1279 - val_mean_squared_logarithmic_error: 0.8481\n",
      "Epoch 24/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13409.3018 - mean_squared_error: 13409.3018 - mean_squared_logarithmic_error: 0.7591 - val_loss: 16333.2803 - val_mean_squared_error: 16333.2803 - val_mean_squared_logarithmic_error: 0.7623\n",
      "Epoch 25/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13373.6455 - mean_squared_error: 13373.6455 - mean_squared_logarithmic_error: 0.7508 - val_loss: 15916.0781 - val_mean_squared_error: 15916.0781 - val_mean_squared_logarithmic_error: 0.78193481.1250 - mean_squared_error: 13481.1250 - mean_squar\n",
      "Epoch 26/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13259.7812 - mean_squared_error: 13259.7812 - mean_squared_logarithmic_error: 0.7563 - val_loss: 15405.0938 - val_mean_squared_error: 15405.0938 - val_mean_squared_logarithmic_error: 0.8160\n",
      "Epoch 27/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13071.1123 - mean_squared_error: 13071.1123 - mean_squared_logarithmic_error: 0.7452 - val_loss: 15399.2910 - val_mean_squared_error: 15399.2910 - val_mean_squared_logarithmic_error: 0.7934\n",
      "Epoch 28/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12861.7197 - mean_squared_error: 12861.7197 - mean_squared_logarithmic_error: 0.7553 - val_loss: 15017.0869 - val_mean_squared_error: 15017.0869 - val_mean_squared_logarithmic_error: 0.8216mean_squared_logarithmic_error: 0.\n",
      "Epoch 29/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12592.0078 - mean_squared_error: 12592.0078 - mean_squared_logarithmic_error: 0.7410 - val_loss: 14799.2080 - val_mean_squared_error: 14799.2080 - val_mean_squared_logarithmic_error: 0.8112\n",
      "Epoch 30/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12524.7578 - mean_squared_error: 12524.7578 - mean_squared_logarithmic_error: 0.7465 - val_loss: 14890.4209 - val_mean_squared_error: 14890.4209 - val_mean_squared_logarithmic_error: 0.7682\n",
      "Epoch 31/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12249.0459 - mean_squared_error: 12249.0459 - mean_squared_logarithmic_error: 0.7454 - val_loss: 14734.7197 - val_mean_squared_error: 14734.7197 - val_mean_squared_logarithmic_error: 0.8082mean_squared_loga - ETA: 4s - los\n",
      "Epoch 32/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12019.6064 - mean_squared_error: 12019.6064 - mean_squared_logarithmic_error: 0.7368 - val_loss: 14800.7773 - val_mean_squared_error: 14800.7773 - val_mean_squared_logarithmic_error: 0.8493n_squared_error: 12407.1260 - mean_squared_lo - ETA: 7s - loss: 12022.3018 - mean_squared_error: 12022.3 - ETA: 5s - loss: 11868.1201 - mean_squared - ETA: 2s - loss: 12070.4814 - mean_squared_error: 1207\n",
      "Epoch 33/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12028.8877 - mean_squared_error: 12028.8877 - mean_squared_logarithmic_error: 0.7428 - val_loss: 14709.1445 - val_mean_squared_error: 14709.1445 - val_mean_squared_logarithmic_error: 0.7715ean_squared_error: 11920.0645 - mean_squared_logarithmic_err - ETA: 0s - loss: 11858.3506 - mean_squared_error: 11858.3506 - mean_squared_logarithmic_error: 0.\n",
      "Epoch 34/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11800.7207 - mean_squared_error: 11800.7207 - mean_squared_logarithmic_error: 0.7296 - val_loss: 15472.4521 - val_mean_squared_error: 15472.4521 - val_mean_squared_logarithmic_error: 0.7325\n",
      "Epoch 35/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11504.6768 - mean_squared_error: 11504.6768 - mean_squared_logarithmic_error: 0.7228 - val_loss: 15593.3838 - val_mean_squared_error: 15593.3838 - val_mean_squared_logarithmic_error: 0.7914\n",
      "Epoch 36/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11396.9580 - mean_squared_error: 11396.9580 - mean_squared_logarithmic_error: 0.7287 - val_loss: 14085.4033 - val_mean_squared_error: 14085.4033 - val_mean_squared_logarithmic_error: 0.7921\n",
      "Epoch 37/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11274.3545 - mean_squared_error: 11274.3545 - mean_squared_logarithmic_error: 0.7337 - val_loss: 14850.3955 - val_mean_squared_error: 14850.3955 - val_mean_squared_logarithmic_error: 0.8541\n",
      "Epoch 38/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11195.4072 - mean_squared_error: 11195.4072 - mean_squared_logarithmic_error: 0.7165 - val_loss: 14895.3711 - val_mean_squared_error: 14895.3711 - val_mean_squared_logarithmic_error: 0.7959\n",
      "Epoch 39/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11201.5801 - mean_squared_error: 11201.5801 - mean_squared_logarithmic_error: 0.7266 - val_loss: 17181.8203 - val_mean_squared_error: 17181.8203 - val_mean_squared_logarithmic_error: 0.8362s: 11164.9219 - mean_squared_error: 11164.9\n",
      "Epoch 40/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10883.8438 - mean_squared_error: 10883.8438 - mean_squared_logarithmic_error: 0.7129 - val_loss: 15149.7627 - val_mean_squared_error: 15149.7627 - val_mean_squared_logarithmic_error: 0.8628\n",
      "Epoch 41/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10811.8115 - mean_squared_error: 10811.8115 - mean_squared_logarithmic_error: 0.7147 - val_loss: 14204.2607 - val_mean_squared_error: 14204.2607 - val_mean_squared_logarithmic_error: 0.7217\n",
      "Epoch 42/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10788.4688 - mean_squared_error: 10788.4688 - mean_squared_logarithmic_error: 0.7091 - val_loss: 14300.0400 - val_mean_squared_error: 14300.0400 - val_mean_squared_logarithmic_error: 0.7483\n",
      "Epoch 43/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10537.6943 - mean_squared_error: 10537.6943 - mean_squared_logarithmic_error: 0.7130 - val_loss: 14966.4961 - val_mean_squared_error: 14966.4961 - val_mean_squared_logarithmic_error: 0.8032\n",
      "Epoch 44/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10536.5254 - mean_squared_error: 10536.5254 - mean_squared_logarithmic_error: 0.7138 - val_loss: 16755.7461 - val_mean_squared_error: 16755.7461 - val_mean_squared_logarithmic_error: 0.7717\n",
      "Epoch 45/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10363.9502 - mean_squared_error: 10363.9502 - mean_squared_logarithmic_error: 0.7093 - val_loss: 17431.0391 - val_mean_squared_error: 17431.0391 - val_mean_squared_logarithmic_error: 0.7685\n",
      "Epoch 46/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10369.8379 - mean_squared_error: 10369.8379 - mean_squared_logarithmic_error: 0.7086 - val_loss: 16843.0352 - val_mean_squared_error: 16843.0352 - val_mean_squared_logarithmic_error: 0.7323\n",
      "Epoch 47/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9995.5713 - mean_squared_error: 9995.5713 - mean_squared_logarithmic_error: 0.7041 - val_loss: 17644.1406 - val_mean_squared_error: 17644.1406 - val_mean_squared_logarithmic_error: 0.7696\n",
      "Epoch 48/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9957.7559 - mean_squared_error: 9957.7559 - mean_squared_logarithmic_error: 0.7139 - val_loss: 14084.0566 - val_mean_squared_error: 14084.0566 - val_mean_squared_logarithmic_error: 0.73270s - loss: 10020.4180 - mean_squared_error: 10020.4180 - mean_squared_logarithmic_error: 0.\n",
      "Epoch 49/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10072.8037 - mean_squared_error: 10072.8037 - mean_squared_logarithmic_error: 0.7005 - val_loss: 13771.9570 - val_mean_squared_error: 13771.9570 - val_mean_squared_logarithmic_error: 0.7783\n",
      "Epoch 50/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9941.2744 - mean_squared_error: 9941.2744 - mean_squared_logarithmic_error: 0.7045 - val_loss: 14095.3330 - val_mean_squared_error: 14095.3330 - val_mean_squared_logarithmic_error: 0.7434\n",
      "Epoch 51/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9814.1680 - mean_squared_error: 9814.1680 - mean_squared_logarithmic_error: 0.6984 - val_loss: 15608.6475 - val_mean_squared_error: 15608.6475 - val_mean_squared_logarithmic_error: 0.7935\n",
      "Epoch 52/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9466.9287 - mean_squared_error: 9466.9287 - mean_squared_logarithmic_error: 0.7025 - val_loss: 19966.0703 - val_mean_squared_error: 19966.0703 - val_mean_squared_logarithmic_error: 0.8076\n",
      "Epoch 53/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9613.4746 - mean_squared_error: 9613.4746 - mean_squared_logarithmic_error: 0.6923 - val_loss: 14269.5996 - val_mean_squared_error: 14269.5996 - val_mean_squared_logarithmic_error: 0.7558\n",
      "Epoch 54/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9475.2832 - mean_squared_error: 9475.2832 - mean_squared_logarithmic_error: 0.6971 - val_loss: 18975.4492 - val_mean_squared_error: 18975.4492 - val_mean_squared_logarithmic_error: 0.7288- loss: 9240.2422 - mean_squared_error: 9240.2422 - mean_squared_logarithm - ETA: 4s - loss:\n",
      "Epoch 55/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9457.5303 - mean_squared_error: 9457.5303 - mean_squared_logarithmic_error: 0.6990 - val_loss: 16547.6914 - val_mean_squared_error: 16547.6914 - val_mean_squared_logarithmic_error: 0.7526\n",
      "Epoch 56/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9185.6846 - mean_squared_error: 9185.6846 - mean_squared_logarithmic_error: 0.6905 - val_loss: 13972.4268 - val_mean_squared_error: 13972.4268 - val_mean_squared_logarithmic_error: 0.8074 loss: 8885.3232 - mean_squared_error: 8885.3232 - mean_squared_log - ETA: 3s - loss: 8769.5264 - mea\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9141.3906 - mean_squared_error: 9141.3906 - mean_squared_logarithmic_error: 0.6912 - val_loss: 16197.0029 - val_mean_squared_error: 16197.0029 - val_mean_squared_logarithmic_error: 0.8020ss: 8946.9746 - mean_squared_error: 8946.9746 - mea\n",
      "Epoch 58/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9199.8750 - mean_squared_error: 9199.8750 - mean_squared_logarithmic_error: 0.6931 - val_loss: 14452.7432 - val_mean_squared_error: 14452.7432 - val_mean_squared_logarithmic_error: 0.7674\n",
      "Epoch 59/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9000.7275 - mean_squared_error: 9000.7275 - mean_squared_logarithmic_error: 0.6916 - val_loss: 17332.6895 - val_mean_squared_error: 17332.6895 - val_mean_squared_logarithmic_error: 0.6990\n",
      "Epoch 60/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8939.5078 - mean_squared_error: 8939.5078 - mean_squared_logarithmic_error: 0.6827 - val_loss: 15161.3652 - val_mean_squared_error: 15161.3652 - val_mean_squared_logarithmic_error: 0.8230\n",
      "Epoch 61/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8815.1279 - mean_squared_error: 8815.1279 - mean_squared_logarithmic_error: 0.6764 - val_loss: 20771.9473 - val_mean_squared_error: 20771.9473 - val_mean_squared_logarithmic_error: 0.8395\n",
      "Epoch 62/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8774.3770 - mean_squared_error: 8774.3770 - mean_squared_logarithmic_error: 0.6819 - val_loss: 14438.2432 - val_mean_squared_error: 14438.2432 - val_mean_squared_logarithmic_error: 0.7290\n",
      "Epoch 63/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8712.7129 - mean_squared_error: 8712.7129 - mean_squared_logarithmic_error: 0.6708 - val_loss: 16383.2764 - val_mean_squared_error: 16383.2764 - val_mean_squared_logarithmic_error: 0.8602\n",
      "Epoch 64/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8760.0771 - mean_squared_error: 8760.0771 - mean_squared_logarithmic_error: 0.6769 - val_loss: 15417.8281 - val_mean_squared_error: 15417.8281 - val_mean_squared_logarithmic_error: 0.7433\n",
      "Epoch 65/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8696.6416 - mean_squared_error: 8696.6416 - mean_squared_logarithmic_error: 0.6784 - val_loss: 18625.0078 - val_mean_squared_error: 18625.0078 - val_mean_squared_logarithmic_error: 0.7220\n",
      "Epoch 66/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8473.6846 - mean_squared_error: 8473.6846 - mean_squared_logarithmic_error: 0.6675 - val_loss: 14820.0469 - val_mean_squared_error: 14820.0469 - val_mean_squared_logarithmic_error: 0.7420\n",
      "Epoch 67/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8523.8018 - mean_squared_error: 8523.8018 - mean_squared_logarithmic_error: 0.6695 - val_loss: 13956.1035 - val_mean_squared_error: 13956.1035 - val_mean_squared_logarithmic_error: 0.7242\n",
      "Epoch 68/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8353.9863 - mean_squared_error: 8353.9863 - mean_squared_logarithmic_error: 0.6727 - val_loss: 21217.2676 - val_mean_squared_error: 21217.2676 - val_mean_squared_logarithmic_error: 0.7579ed_error: 8046.803\n",
      "Epoch 69/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8367.4668 - mean_squared_error: 8367.4668 - mean_squared_logarithmic_error: 0.6680 - val_loss: 15353.4492 - val_mean_squared_error: 15353.4492 - val_mean_squared_logarithmic_error: 0.7326\n",
      "Epoch 70/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8328.3525 - mean_squared_error: 8328.3525 - mean_squared_logarithmic_error: 0.6685 - val_loss: 16065.5479 - val_mean_squared_error: 16065.5479 - val_mean_squared_logarithmic_error: 0.7895quared_error: 8380.1602 - mean_squared_logarithmic_error:\n",
      "Epoch 71/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8196.4219 - mean_squared_error: 8196.4219 - mean_squared_logarithmic_error: 0.6756 - val_loss: 22266.0547 - val_mean_squared_error: 22266.0547 - val_mean_squared_logarithmic_error: 0.7613\n",
      "Epoch 72/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8158.6084 - mean_squared_error: 8158.6084 - mean_squared_logarithmic_error: 0.6671 - val_loss: 22728.7129 - val_mean_squared_error: 22728.7129 - val_mean_squared_logarithmic_error: 0.7655\n",
      "Epoch 73/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8114.3721 - mean_squared_error: 8114.3721 - mean_squared_logarithmic_error: 0.6635 - val_loss: 15013.0771 - val_mean_squared_error: 15013.0771 - val_mean_squared_logarithmic_error: 0.7372\n",
      "Epoch 74/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7827.3667 - mean_squared_error: 7827.3667 - mean_squared_logarithmic_error: 0.6632 - val_loss: 20471.3027 - val_mean_squared_error: 20471.3027 - val_mean_squared_logarithmic_error: 0.7172\n",
      "Epoch 75/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7969.6582 - mean_squared_error: 7969.6582 - mean_squared_logarithmic_error: 0.6643 - val_loss: 22084.1016 - val_mean_squared_error: 22084.1016 - val_mean_squared_logarithmic_error: 0.7233\n",
      "Epoch 76/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7927.0596 - mean_squared_error: 7927.0596 - mean_squared_logarithmic_error: 0.6633 - val_loss: 15439.7930 - val_mean_squared_error: 15439.7930 - val_mean_squared_logarithmic_error: 0.7553_logarithmic_error: 0\n",
      "Epoch 77/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7848.9155 - mean_squared_error: 7848.9155 - mean_squared_logarithmic_error: 0.6598 - val_loss: 16229.5029 - val_mean_squared_error: 16229.5029 - val_mean_squared_logarithmic_error: 0.7356\n",
      "Epoch 78/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7735.1763 - mean_squared_error: 7735.1763 - mean_squared_logarithmic_error: 0.6548 - val_loss: 17204.9805 - val_mean_squared_error: 17204.9805 - val_mean_squared_logarithmic_error: 0.7651\n",
      "Epoch 79/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7769.0117 - mean_squared_error: 7769.0117 - mean_squared_logarithmic_error: 0.6623 - val_loss: 18266.2773 - val_mean_squared_error: 18266.2773 - val_mean_squared_logarithmic_error: 0.7354\n",
      "Epoch 80/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7627.1084 - mean_squared_error: 7627.1084 - mean_squared_logarithmic_error: 0.6585 - val_loss: 15842.2383 - val_mean_squared_error: 15842.2383 - val_mean_squared_logarithmic_error: 0.7405\n",
      "Epoch 81/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7659.7729 - mean_squared_error: 7659.7729 - mean_squared_logarithmic_error: 0.6600 - val_loss: 15666.5635 - val_mean_squared_error: 15666.5635 - val_mean_squared_logarithmic_error: 0.7738\n",
      "Epoch 82/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7458.6436 - mean_squared_error: 7458.6436 - mean_squared_logarithmic_error: 0.6541 - val_loss: 19868.0254 - val_mean_squared_error: 19868.0254 - val_mean_squared_logarithmic_error: 0.7530\n",
      "Epoch 83/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7561.7520 - mean_squared_error: 7561.7520 - mean_squared_logarithmic_error: 0.6604 - val_loss: 18625.3867 - val_mean_squared_error: 18625.3867 - val_mean_squared_logarithmic_error: 0.6983\n",
      "Epoch 84/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7479.8320 - mean_squared_error: 7479.8320 - mean_squared_logarithmic_error: 0.6414 - val_loss: 21466.2852 - val_mean_squared_error: 21466.2852 - val_mean_squared_logarithmic_error: 0.7708\n",
      "Epoch 85/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7314.7021 - mean_squared_error: 7314.7021 - mean_squared_logarithmic_error: 0.6550 - val_loss: 18486.5293 - val_mean_squared_error: 18486.5293 - val_mean_squared_logarithmic_error: 0.7436\n",
      "Epoch 86/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7320.6836 - mean_squared_error: 7320.6836 - mean_squared_logarithmic_error: 0.6477 - val_loss: 20451.2754 - val_mean_squared_error: 20451.2754 - val_mean_squared_logarithmic_error: 0.7316\n",
      "Epoch 87/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7430.7344 - mean_squared_error: 7430.7344 - mean_squared_logarithmic_error: 0.6489 - val_loss: 18921.1152 - val_mean_squared_error: 18921.1152 - val_mean_squared_logarithmic_error: 0.7839\n",
      "Epoch 88/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7280.3369 - mean_squared_error: 7280.3369 - mean_squared_logarithmic_error: 0.6554 - val_loss: 26853.6191 - val_mean_squared_error: 26853.6191 - val_mean_squared_logarithmic_error: 0.73827269.4302 - mean_squared_error: 7269.4302 - mean_s\n",
      "Epoch 89/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7099.2261 - mean_squared_error: 7099.2261 - mean_squared_logarithmic_error: 0.6572 - val_loss: 19209.5156 - val_mean_squared_error: 19209.5156 - val_mean_squared_logarithmic_error: 0.7960\n",
      "Epoch 90/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7354.7368 - mean_squared_error: 7354.7368 - mean_squared_logarithmic_error: 0.6496 - val_loss: 20587.9629 - val_mean_squared_error: 20587.9629 - val_mean_squared_logarithmic_error: 0.7319\n",
      "Epoch 91/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7126.9272 - mean_squared_error: 7126.9272 - mean_squared_logarithmic_error: 0.6473 - val_loss: 15695.2607 - val_mean_squared_error: 15695.2607 - val_mean_squared_logarithmic_error: 0.7312\n",
      "Epoch 92/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6973.1650 - mean_squared_error: 6973.1650 - mean_squared_logarithmic_error: 0.6450 - val_loss: 16567.1582 - val_mean_squared_error: 16567.1582 - val_mean_squared_logarithmic_error: 0.7694- mean_squared_logarithmic_error: 0.64\n",
      "Epoch 93/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7097.9570 - mean_squared_error: 7097.9570 - mean_squared_logarithmic_error: 0.6477 - val_loss: 17956.6855 - val_mean_squared_error: 17956.6855 - val_mean_squared_logarithmic_error: 0.7583\n",
      "Epoch 94/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6970.4307 - mean_squared_error: 6970.4307 - mean_squared_logarithmic_error: 0.6472 - val_loss: 17313.5879 - val_mean_squared_error: 17313.5879 - val_mean_squared_logarithmic_error: 0.7506\n",
      "Epoch 95/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6931.2949 - mean_squared_error: 6931.2949 - mean_squared_logarithmic_error: 0.6465 - val_loss: 31790.9922 - val_mean_squared_error: 31790.9922 - val_mean_squared_logarithmic_error: 0.7652\n",
      "Epoch 96/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6889.8140 - mean_squared_error: 6889.8140 - mean_squared_logarithmic_error: 0.6408 - val_loss: 21159.1992 - val_mean_squared_error: 21159.1992 - val_mean_squared_logarithmic_error: 0.7343\n",
      "Epoch 97/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6888.9927 - mean_squared_error: 6888.9927 - mean_squared_logarithmic_error: 0.6428 - val_loss: 24708.8574 - val_mean_squared_error: 24708.8574 - val_mean_squared_logarithmic_error: 0.760917 - me\n",
      "Epoch 98/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6849.8477 - mean_squared_error: 6849.8477 - mean_squared_logarithmic_error: 0.6369 - val_loss: 26324.6270 - val_mean_squared_error: 26324.6270 - val_mean_squared_logarithmic_error: 0.7397- loss: 7031.1797 - mean_squared_error: 7031.1797 - mean_squared_logarithmic_error: 0.63 - ETA: 3s - loss: 7092.4883 - mean_squared_error: 7092.4883 - mean_squared_logarithmic_error:  - ETA: 3s - loss: 6991.3789 - mean_squared_error - ETA: 0s - loss: 6983.0332 - mean_squared_error: 6983.0332 - mean_squared_logarithmi\n",
      "Epoch 99/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6776.5005 - mean_squared_error: 6776.5005 - mean_squared_logarithmic_error: 0.6320 - val_loss: 24374.9941 - val_mean_squared_error: 24374.9941 - val_mean_squared_logarithmic_error: 0.8170\n",
      "Epoch 100/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6778.5527 - mean_squared_error: 6778.5527 - mean_squared_logarithmic_error: 0.6402 - val_loss: 19052.1660 - val_mean_squared_error: 19052.1660 - val_mean_squared_logarithmic_error: 0.7462s: 6781.2627 - mean_squared_error: 6781.2627 - m - ETA: 4s - loss: 6832.3750 - mean_squared_e - ETA: 1s - loss: 6841.4580 - mean_squared_error: 6841.4580 - mean_squared_logarithmic_erro - ETA: 0s - loss: 6833.1660 - mean_squared_error: 6833.1660 - mean_squared_logar\n"
     ]
    }
   ],
   "source": [
    "history_train = model_train.fit(X_train_pca, y_train, batch_size=2, epochs=100, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T19:20:04.457314Z",
     "start_time": "2021-05-10T19:20:04.397782Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X_train_pca.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(loss=\"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\",\"mean_squared_logarithmic_error\",det_coeff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T19:42:48.266939Z",
     "start_time": "2021-05-10T19:20:09.669230Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 27502.4492 - mean_squared_error: 27502.4492 - mean_squared_logarithmic_error: 1.2241 - det_coeff: -inf - val_loss: 25228.3965 - val_mean_squared_error: 25228.3965 - val_mean_squared_logarithmic_error: 0.9755 - val_det_coeff: -inf\n",
      "Epoch 2/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 23168.6055 - mean_squared_error: 23168.6055 - mean_squared_logarithmic_error: 1.0271 - det_coeff: -inf - val_loss: 24931.4199 - val_mean_squared_error: 24931.4199 - val_mean_squared_logarithmic_error: 1.1732 - val_det_coeff: -infn_squared_error: 22650.7832 - mean_squared_logarithmic_error: 1.0234 - det_c - ETA: 3s - loss: 22628.4902 - mean_squared_error: 2\n",
      "Epoch 3/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 21653.6055 - mean_squared_error: 21653.6055 - mean_squared_logarithmic_error: 0.9881 - det_coeff: -inf - val_loss: 22447.9824 - val_mean_squared_error: 22447.9824 - val_mean_squared_logarithmic_error: 1.1357 - val_det_coeff: -inf\n",
      "Epoch 4/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 20732.7422 - mean_squared_error: 20732.7422 - mean_squared_logarithmic_error: 0.9645 - det_coeff: -inf - val_loss: 22273.5488 - val_mean_squared_error: 22273.5488 - val_mean_squared_logarithmic_error: 1.1145 - val_det_coeff: -inf\n",
      "Epoch 5/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 20257.8281 - mean_squared_error: 20257.8281 - mean_squared_logarithmic_error: 0.9410 - det_coeff: -inf - val_loss: 22732.7266 - val_mean_squared_error: 22732.7266 - val_mean_squared_logarithmic_error: 0.8842 - val_det_coeff: -inf\n",
      "Epoch 6/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 19489.2051 - mean_squared_error: 19489.2051 - mean_squared_logarithmic_error: 0.9200 - det_coeff: -inf - val_loss: 20481.5527 - val_mean_squared_error: 20481.5527 - val_mean_squared_logarithmic_error: 1.0290 - val_det_coeff: -infloss: 19313.5215 - mean_squared_error: 19313.5215 - mean_squared_logarithmic_error: 0.8959 - det_coe - ETA: 6s - loss: 19245.2598 - mean_squared_error: 19245.2598 - mean_squared_logarithmic_e - ETA: 4s - loss: 18830.4395 - mean_squared_error: 18830.4395 - mean_squared_logarithmic - ETA: 3s - loss: 19152.1680 - mean_squared_error: 19152.1680 - mean_squared_loga - ETA: 1s - loss: 19111.3945 - mean_squared_error: 19111.3945 - mean_squared_logarithmic_error: 0. - ETA: 0s - loss: 19481.2285 - mean_squared_error: 19481.2285 - mean_squared_logarithmic_error: 0.9197 - det_coeff: -in\n",
      "Epoch 7/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 18924.6309 - mean_squared_error: 18924.6309 - mean_squared_logarithmic_error: 0.9216 - det_coeff: -inf - val_loss: 20580.3125 - val_mean_squared_error: 20580.3125 - val_mean_squared_logarithmic_error: 0.9293 - val_det_coeff: -infss: 19170.1387 - mean_squared_error: 19170.1387 - mean_squared_logarithmic_error: 0.9276 - det_coef - ETA: 1s - loss: 18959.9609 - mean_squared_error: 18959.9609 - mean_squared_logarithmic_error: 0.9264 - de - ETA: 0s - loss: 19001.2734 - mean_squared_error: 19001.2734 - mean_squared_logarithmic_error: 0.9256 - det_coeff:  - ETA: 0s - loss: 18886.9980 - mean_squared_error: 18886.9980 - mean_squared_logarithmic_error: 0.9250 - det_coeff: - - ETA: 0s - loss: 18792.2559 - mean_squared_error: 18792.2559 - mean_squared_logarithmic_error: 0.9222 - det_coeff - ETA: 0s - loss: 18855.8965 - mean_squared_error: 18855.8965 - mean_squared_logarithmic_error: 0.9201 - det_coeff:\n",
      "Epoch 8/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 18490.8379 - mean_squared_error: 18490.8379 - mean_squared_logarithmic_error: 0.8992 - det_coeff: -inf - val_loss: 21092.4824 - val_mean_squared_error: 21092.4824 - val_mean_squared_logarithmic_error: 1.0076 - val_det_coeff: -inf023 - mean_sq - ETA: 1s - loss: 18509.7207 - mean_squared_error: 18509.7207 - mean_squared_logar\n",
      "Epoch 9/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 18131.6758 - mean_squared_error: 18131.6758 - mean_squared_logarithmic_error: 0.8918 - det_coeff: -inf - val_loss: 18996.1172 - val_mean_squared_error: 18996.1172 - val_mean_squared_logarithmic_error: 0.9336 - val_det_coeff: -inf\n",
      "Epoch 10/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 17704.5137 - mean_squared_error: 17704.5137 - mean_squared_logarithmic_error: 0.8714 - det_coeff: -inf - val_loss: 20731.7969 - val_mean_squared_error: 20731.7969 - val_mean_squared_logarithmic_error: 1.1087 - val_det_coeff: -infsquared_error: 17962.3477 - mean_squared_logarithmic_error: 0.8668 - det_coeff: -i - ETA: 2s - loss: 18056.7285 - mean_squared_error: 18056.7285 - mean_squared_logarithmic_error: 0. - ETA: 0s - loss: 17948.0156 - mean_squared_error: 17948.0156 - mean_squared_logarithmic_error: 0.8699 - det_coeff: - ETA: 0s - loss: 17829.6719 - mean_squared_error: 17829.6719 - mean_squared_logarithmic_error: 0.8691 - de\n",
      "Epoch 11/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 17624.5039 - mean_squared_error: 17624.5039 - mean_squared_logarithmic_error: 0.8629 - det_coeff: -inf - val_loss: 18923.8086 - val_mean_squared_error: 18923.8086 - val_mean_squared_logarithmic_error: 0.8354 - val_det_coeff: -infsquared_error: 17560.2539 - mean_squared_logarithmic_error: 0.8576 - det_coeff: - - ETA: 1s - loss: 17745.0371 - mean_squared_error: 17745.0371 - mean_squared_logarithmic_error: 0.8607 - det_coeff: - ETA: 0s - loss: 17973.9141 - mean_squared_error: 17973.9141 - mean_squared_logarithmic_error: 0.863\n",
      "Epoch 12/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 17042.7656 - mean_squared_error: 17042.7656 - mean_squared_logarithmic_error: 0.8509 - det_coeff: -inf - val_loss: 18518.2773 - val_mean_squared_error: 18518.2773 - val_mean_squared_logarithmic_error: 0.8770 - val_det_coeff: -infquared_error: 17504.5195 - mean_squared_logarithmic_error: 0.8513 - ETA: 5s - loss: 17349.1484 - mean_squared_error: 17349.1484 - mean_squared_l - ETA: 3s - loss: 16788.6719 - mean_squared_error: 16788.6719 - mean_squared_logarithmic_error: 0.8498 - d - ETA: 2s - loss: 16917.2520 - mean_squared_error: 16917.2520 - mean_squa\n",
      "Epoch 13/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 16884.4707 - mean_squared_error: 16884.4707 - mean_squared_logarithmic_error: 0.8426 - det_coeff: -inf - val_loss: 19154.5000 - val_mean_squared_error: 19154.5000 - val_mean_squared_logarithmic_error: 0.8066 - val_det_coeff: -infETA: 1s - loss: 16707.8008 - mean_squared_error: 16707.8008 - mean_squared_logarithmic_error: - ETA: 0s - loss: 16901.0098 - mean_squared_error: 16901.0098 - mean_squared_logarithmic_error: 0.8415 - det_coeff: -i\n",
      "Epoch 14/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16679.7344 - mean_squared_error: 16679.7344 - mean_squared_logarithmic_error: 0.8315 - det_coeff: -inf - val_loss: 17984.8359 - val_mean_squared_error: 17984.8359 - val_mean_squared_logarithmic_error: 0.7637 - val_det_coeff: -infred_error: 16758.8008 -  - ETA: 0s - loss: 16770.7500 - mean_squared_error: 16770.7500 - mean_squared_logarithmic_error: 0.8323 - det_\n",
      "Epoch 15/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 16462.9766 - mean_squared_error: 16462.9766 - mean_squared_logarithmic_error: 0.8283 - det_coeff: -inf - val_loss: 17721.0469 - val_mean_squared_error: 17721.0469 - val_mean_squared_logarithmic_error: 1.0161 - val_det_coeff: -inf\n",
      "Epoch 16/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 16329.8203 - mean_squared_error: 16329.8203 - mean_squared_logarithmic_error: 0.8316 - det_coeff: -inf - val_loss: 17391.5215 - val_mean_squared_error: 17391.5215 - val_mean_squared_logarithmic_error: 0.8624 - val_det_coeff: -inf mean_squared_error: 16798.3809 - mean_squared_logarithmic_error: 0.8540 - det_co - ETA: 8s - loss: 15947.4736 - mean_squared_error: 15947.4736  - ETA: 5s - loss: 16672.9746 - mean_squared_error: 16672.9746 - mean_squared_logarithmic_error: 0.8261 - det_coef - ETA: 4s - loss: 16593.8066 - mean_squared_error: 16593.8066 - mean_squared_logarithmic - ETA: 2s - loss: 16442.7324 - mean_squared_error: 16442.7324 - m\n",
      "Epoch 17/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15682.1094 - mean_squared_error: 15682.1094 - mean_squared_logarithmic_error: 0.8192 - det_coeff: -inf - val_loss: 16820.3477 - val_mean_squared_error: 16820.3477 - val_mean_squared_logarithmic_error: 0.8263 - val_det_coeff: -inf.2607 - mean_squ - ETA: 2s - loss: 16075.3301 - mean_squared_error: 16075.3301\n",
      "Epoch 18/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15948.5361 - mean_squared_error: 15948.5361 - mean_squared_logarithmic_error: 0.8214 - det_coeff: -inf - val_loss: 17265.6953 - val_mean_squared_error: 17265.6953 - val_mean_squared_logarithmic_error: 0.8601 - val_det_coeff: -infoss: 16248.5527 - mean_squared_error: 16248.5527 - mean_squared_logarithmic_ - ETA: 5s - loss: 15932.3936 - mean_squared_error: 15932.3936 - mean_squared_logarithmic_error: 0.8291 - det_co - ETA: 5s - loss: 16023.9424 - mean_squared_error: 16023.9424 - mean_squared_logarithmic_error: 0.8274 - det_coeff: -i - ETA: 5s - \n",
      "Epoch 19/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15544.9395 - mean_squared_error: 15544.9395 - mean_squared_logarithmic_error: 0.8061 - det_coeff: -inf - val_loss: 17520.9531 - val_mean_squared_error: 17520.9531 - val_mean_squared_logarithmic_error: 0.9184 - val_det_coeff: -inf5104.7354 - mean_squared - ETA: 1s - loss: 15752.5400 - mean_squared_error: 15752.5400 - mean_squared_logarithmic_error: \n",
      "Epoch 20/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 15304.5850 - mean_squared_error: 15304.5850 - mean_squared_logarithmic_error: 0.8106 - det_coeff: -inf - val_loss: 17545.3711 - val_mean_squared_error: 17545.3711 - val_mean_squared_logarithmic_error: 1.0540 - val_det_coeff: -inf_squared_logarithmic_error: 0.7951 - det_coeff: - ETA: 3s - loss: 14896.5850 - mean_squared_error: 14896.5850 - ETA: 0s - loss: 14909.0537 - mean_squared_error: 14909.0537 - mean_squared_logarithmic_error: 0.804\n",
      "Epoch 21/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15118.3291 - mean_squared_error: 15118.3291 - mean_squared_logarithmic_error: 0.8075 - det_coeff: -inf - val_loss: 16808.9043 - val_mean_squared_error: 16808.9043 - val_mean_squared_logarithmic_error: 0.9864 - val_det_coeff: -inf\n",
      "Epoch 22/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 15010.0215 - mean_squared_error: 15010.0215 - mean_squared_logarithmic_error: 0.8006 - det_coeff: -inf - val_loss: 16347.0127 - val_mean_squared_error: 16347.0127 - val_mean_squared_logarithmic_error: 0.8461 - val_det_coeff: -inf656.2891 - mean_squared_logarithmic - ETA: 5s - loss: 1\n",
      "Epoch 23/100\n",
      "12250/12250 [==============================] - 12s 1ms/step - loss: 14688.3477 - mean_squared_error: 14688.3477 - mean_squared_logarithmic_error: 0.7938 - det_coeff: -inf - val_loss: 17766.3574 - val_mean_squared_error: 17766.3574 - val_mean_squared_logarithmic_error: 0.8179 - val_det_coeff: -infrror: 14479.2051 - mean_squared_logarithmic_error: 0.7938 - \n",
      "Epoch 24/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 14472.7656 - mean_squared_error: 14472.7656 - mean_squared_logarithmic_error: 0.7825 - det_coeff: -inf - val_loss: 16781.3184 - val_mean_squared_error: 16781.3184 - val_mean_squared_logarithmic_error: 0.8077 - val_det_coeff: -inf80.1924\n",
      "Epoch 25/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 14477.1162 - mean_squared_error: 14477.1162 - mean_squared_logarithmic_error: 0.7828 - det_coeff: -inf - val_loss: 16238.1533 - val_mean_squared_error: 16238.1533 - val_mean_squared_logarithmic_error: 0.8128 - val_det_coeff: -inf\n",
      "Epoch 26/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 14252.3027 - mean_squared_error: 14252.3027 - mean_squared_logarithmic_error: 0.7905 - det_coeff: -inf - val_loss: 16083.0869 - val_mean_squared_error: 16083.0869 - val_mean_squared_logarithmic_error: 0.8429 - val_det_coeff: -infn_squared_error: 1470\n",
      "Epoch 27/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 13803.9590 - mean_squared_error: 13803.9590 - mean_squared_logarithmic_error: 0.7733 - det_coeff: -inf - val_loss: 18212.3320 - val_mean_squared_error: 18212.3320 - val_mean_squared_logarithmic_error: 1.0120 - val_det_coeff: -inf_squared_error: 13352.1221 - mean_squared_logarithmic_error: 0.7719 - det_coeff: - ETA: 3s - loss: 13420.5752 - mean_squared_error\n",
      "Epoch 28/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13745.7607 - mean_squared_error: 13745.7607 - mean_squared_logarithmic_error: 0.7856 - det_coeff: -inf - val_loss: 16963.2598 - val_mean_squared_error: 16963.2598 - val_mean_squared_logarithmic_error: 0.9141 - val_det_coeff: -inf: 13893.4189 - mean_squared_error: 13893.4189 - mean_squared_logarithmic_error: 0.7\n",
      "Epoch 29/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 13469.5801 - mean_squared_error: 13469.5801 - mean_squared_logarithmic_error: 0.7718 - det_coeff: -inf - val_loss: 16738.9980 - val_mean_squared_error: 16738.9980 - val_mean_squared_logarithmic_error: 0.8905 - val_det_coeff: -inf6 - mean_squared_logarithmic_error: 0.7716 - det_coeff - ETA: 6s - loss: 12617.4023 - mean_squ - ETA: 2s - loss: 13630.0322 - mean_squared_error: 13630.0322 - mean_squared_logarithmic_error: 0.7738 - det_coeff:  - ETA: 2s - loss: 13602.2061 - mean_squared_error: 13602.2061 - mean_squared_logarithmic_error: 0.7725 - det_co - ETA: 1s - loss: 13368.8672 - mean_squared_error: 13368.8672 - mean_squared_logarit\n",
      "Epoch 30/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 13484.0449 - mean_squared_error: 13484.0449 - mean_squared_logarithmic_error: 0.7792 - det_coeff: -inf - val_loss: 15721.9248 - val_mean_squared_error: 15721.9248 - val_mean_squared_logarithmic_error: 0.8149 - val_det_coeff: -inf_squared_error: 13423.6045 - mean_squared_l - ETA: 5s - loss: 13121.8105 - mean_squared_error: 13121.8105 - mean_squared_logarithmic_er - ETA: 3s - loss: 13270.7939 - mean_squared_error: 13270.7939 - mean_squared_logarithmic_e - ETA: 2s - loss: 13418.4004 - mean_squared_error: 13418.4004 - mean_squared_logarithmic_erro - ETA: 1s - loss: 13591.0771 - mean_squared_error: 13591.0771 - mean_squared_logarithmic_error: 0.7\n",
      "Epoch 31/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 13312.4189 - mean_squared_error: 13312.4189 - mean_squared_logarithmic_error: 0.7686 - det_coeff: -inf - val_loss: 15679.4678 - val_mean_squared_error: 15679.4678 - val_mean_squared_logarithmic_error: 0.7931 - val_det_coeff: -inf\n",
      "Epoch 32/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 13118.9668 - mean_squared_error: 13118.9668 - mean_squared_logarithmic_error: 0.7731 - det_coeff: -inf - val_loss: 17877.8496 - val_mean_squared_error: 17877.8496 - val_mean_squared_logarithmic_error: 0.9701 - val_det_coeff: -infquared_error: 13322.0537 - mean_squared_logarithmic_error: 0.7650 - det_c - ETA: 3s - loss: 13343.4570 - mean_squared_error: 13343.4570 - mean_squared_logarithmic_error: 0.7715 - det_coeff: - ETA: 3s - loss: 13196.0889 - mean_squared_error: 13196.\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12250/12250 [==============================] - 14s 1ms/step - loss: 12940.5039 - mean_squared_error: 12940.5039 - mean_squared_logarithmic_error: 0.7619 - det_coeff: -inf - val_loss: 16808.1348 - val_mean_squared_error: 16808.1348 - val_mean_squared_logarithmic_error: 0.8210 - val_det_coeff: -inf\n",
      "Epoch 34/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 12568.7129 - mean_squared_error: 12568.7129 - mean_squared_logarithmic_error: 0.7597 - det_coeff: -inf - val_loss: 15230.9590 - val_mean_squared_error: 15230.9590 - val_mean_squared_logarithmic_error: 0.8207 - val_det_coeff: -infr: 12721.4277 - mean_squared_logarithmic_error: 0.7 - ETA: 2s - loss: 12274.6953 - mean_squared_error: 12274.6953 - mean_squared_logarithmic_error: 0.7621 - det_coe - ETA: 2s - loss: 12402.8125 - mean_squared_error: 12402.8125 - mean_squared_\n",
      "Epoch 35/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 12562.4775 - mean_squared_error: 12562.4775 - mean_squared_logarithmic_error: 0.7620 - det_coeff: -inf - val_loss: 14392.3203 - val_mean_squared_error: 14392.3203 - val_mean_squared_logarithmic_error: 0.8078 - val_det_coeff: -inf\n",
      "Epoch 36/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 12418.1484 - mean_squared_error: 12418.1484 - mean_squared_logarithmic_error: 0.7510 - det_coeff: -inf - val_loss: 14120.7207 - val_mean_squared_error: 14120.7207 - val_mean_squared_logarithmic_error: 0.8669 - val_det_coeff: -inf\n",
      "Epoch 37/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 12177.0869 - mean_squared_error: 12177.0869 - mean_squared_logarithmic_error: 0.7671 - det_coeff: -inf - val_loss: 15172.0703 - val_mean_squared_error: 15172.0703 - val_mean_squared_logarithmic_error: 0.7707 - val_det_coeff: -infared_logarithmic_error: 0.7693 - det_co - ETA: 7s - loss: 11646.5820 - ETA: 2s - loss: 12408.3779 - mean_squared_error: 12408.3779 - mean_squa - ETA: 0s - loss: 12200.0420 - mean_squared_error: 12200.0420 - mean_squared_logarithmic_error: 0.7677 - det_coeff: -\n",
      "Epoch 38/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 11941.8164 - mean_squared_error: 11941.8164 - mean_squared_logarithmic_error: 0.7485 - det_coeff: -inf - val_loss: 14693.2969 - val_mean_squared_error: 14693.2969 - val_mean_squared_logarithmic_error: 0.7858 - val_det_coeff: -infA: 4s - loss: 11912.7832 - mean_squa\n",
      "Epoch 39/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 11925.2031 - mean_squared_error: 11925.2031 - mean_squared_logarithmic_error: 0.7522 - det_coeff: -inf - val_loss: 14899.6084 - val_mean_squared_error: 14899.6084 - val_mean_squared_logarithmic_error: 0.7709 - val_det_coeff: -inf01.4434 - mean_squ\n",
      "Epoch 40/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11677.3965 - mean_squared_error: 11677.3965 - mean_squared_logarithmic_error: 0.7396 - det_coeff: -inf - val_loss: 15724.3506 - val_mean_squared_error: 15724.3506 - val_mean_squared_logarithmic_error: 0.9254 - val_det_coeff: -inf\n",
      "Epoch 41/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 11645.2373 - mean_squared_error: 11645.2373 - mean_squared_logarithmic_error: 0.7398 - det_coeff: -inf - val_loss: 14544.7715 - val_mean_squared_error: 14544.7715 - val_mean_squared_logarithmic_error: 0.8295 - val_det_coeff: -inf\n",
      "Epoch 42/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11322.1748 - mean_squared_error: 11322.1748 - mean_squared_logarithmic_error: 0.7473 - det_coeff: -inf - val_loss: 15496.0107 - val_mean_squared_error: 15496.0107 - val_mean_squared_logarithmic_error: 0.8097 - val_det_coeff: -inf\n",
      "Epoch 43/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11289.7373 - mean_squared_error: 11289.7373 - mean_squared_logarithmic_error: 0.7423 - det_coeff: -inf - val_loss: 14979.8018 - val_mean_squared_error: 14979.8018 - val_mean_squared_logarithmic_error: 0.8392 - val_det_coeff: -inf\n",
      "Epoch 44/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 11165.1504 - mean_squared_error: 11165.1504 - mean_squared_logarithmic_error: 0.7369 - det_coeff: -inf - val_loss: 14669.8008 - val_mean_squared_error: 14669.8008 - val_mean_squared_logarithmic_error: 0.7724 - val_det_coeff: -inf\n",
      "Epoch 45/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 11148.7910 - mean_squared_error: 11148.7910 - mean_squared_logarithmic_error: 0.7380 - det_coeff: -inf - val_loss: 14110.4346 - val_mean_squared_error: 14110.4346 - val_mean_squared_logarithmic_error: 0.8306 - val_det_coeff: -inf\n",
      "Epoch 46/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10938.3828 - mean_squared_error: 10938.3828 - mean_squared_logarithmic_error: 0.7316 - det_coeff: -inf - val_loss: 13844.6768 - val_mean_squared_error: 13844.6768 - val_mean_squared_logarithmic_error: 0.7954 - val_det_coeff: -inf\n",
      "Epoch 47/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10606.5137 - mean_squared_error: 10606.5137 - mean_squared_logarithmic_error: 0.7221 - det_coeff: -inf - val_loss: 16168.8779 - val_mean_squared_error: 16168.8779 - val_mean_squared_logarithmic_error: 0.8213 - val_det_coeff: -inf\n",
      "Epoch 48/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10555.4189 - mean_squared_error: 10555.4189 - mean_squared_logarithmic_error: 0.7226 - det_coeff: -inf - val_loss: 14004.8945 - val_mean_squared_error: 14004.8945 - val_mean_squared_logarithmic_error: 0.7421 - val_det_coeff: -inf\n",
      "Epoch 49/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10457.1240 - mean_squared_error: 10457.1240 - mean_squared_logarithmic_error: 0.7284 - det_coeff: -inf - val_loss: 15569.9141 - val_mean_squared_error: 15569.9141 - val_mean_squared_logarithmic_error: 0.8653 - val_det_coeff: -infror: 10132.1465 - mean_squared_logarithmic_error: 0.704 - ETA:\n",
      "Epoch 50/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 10244.0752 - mean_squared_error: 10244.0752 - mean_squared_logarithmic_error: 0.7163 - det_coeff: -inf - val_loss: 14942.9961 - val_mean_squared_error: 14942.9961 - val_mean_squared_logarithmic_error: 0.7928 - val_det_coeff: -inf mean_squared_logarithmic_error: 0.7015 - det_coeff: - ETA: 3s - loss: 9876.6846 - mean_squared_error: 9876.6846 - mean_squared_logarithmic_error: 0.7021 - det_coeff:  - ETA: 2s - loss: 9935.3701 - mean_squared_error: 9935.3701 -\n",
      "Epoch 51/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 10388.6631 - mean_squared_error: 10388.6631 - mean_squared_logarithmic_error: 0.7275 - det_coeff: -inf - val_loss: 14086.8711 - val_mean_squared_error: 14086.8711 - val_mean_squared_logarithmic_error: 0.8597 - val_det_coeff: -inf\n",
      "Epoch 52/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10262.5635 - mean_squared_error: 10262.5635 - mean_squared_logarithmic_error: 0.7208 - det_coeff: -inf - val_loss: 14675.6191 - val_mean_squared_error: 14675.6191 - val_mean_squared_logarithmic_error: 0.7461 - val_det_coeff: -inf\n",
      "Epoch 53/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10264.8809 - mean_squared_error: 10264.8809 - mean_squared_logarithmic_error: 0.7086 - det_coeff: -inf - val_loss: 14411.1631 - val_mean_squared_error: 14411.1631 - val_mean_squared_logarithmic_error: 0.7821 - val_det_coeff: -inf\n",
      "Epoch 54/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 10041.9941 - mean_squared_error: 10041.9941 - mean_squared_logarithmic_error: 0.6973 - det_coeff: -inf - val_loss: 15113.4658 - val_mean_squared_error: 15113.4658 - val_mean_squared_logarithmic_error: 0.7725 - val_det_coeff: -inf\n",
      "Epoch 55/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 9815.1094 - mean_squared_error: 9815.1094 - mean_squared_logarithmic_error: 0.7084 - det_coeff: -inf - val_loss: 13883.5518 - val_mean_squared_error: 13883.5518 - val_mean_squared_logarithmic_error: 0.7527 - val_det_coeff: -inf\n",
      "Epoch 56/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 9792.1670 - mean_squared_error: 9792.1670 - mean_squared_logarithmic_error: 0.6971 - det_coeff: -inf - val_loss: 15096.0840 - val_mean_squared_error: 15096.0840 - val_mean_squared_logarithmic_error: 0.8600 - val_det_coeff: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 9886.0420 - mean_squared_error: 9886.0420 - mean_squared_logarithmic_error: 0.6970 - det_coeff: -inf - val_loss: 14483.3555 - val_mean_squared_error: 14483.3555 - val_mean_squared_logarithmic_error: 0.8303 - val_det_coeff: -inf\n",
      "Epoch 58/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 9623.2539 - mean_squared_error: 9623.2539 - mean_squared_logarithmic_error: 0.7022 - det_coeff: -inf - val_loss: 13866.3516 - val_mean_squared_error: 13866.3516 - val_mean_squared_logarithmic_error: 0.7694 - val_det_coeff: -inf\n",
      "Epoch 59/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9467.2676 - mean_squared_error: 9467.2676 - mean_squared_logarithmic_error: 0.6957 - det_coeff: -inf - val_loss: 14260.2363 - val_mean_squared_error: 14260.2363 - val_mean_squared_logarithmic_error: 0.7792 - val_det_coeff: -inf\n",
      "Epoch 60/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9474.6543 - mean_squared_error: 9474.6543 - mean_squared_logarithmic_error: 0.6905 - det_coeff: -inf - val_loss: 13717.5469 - val_mean_squared_error: 13717.5469 - val_mean_squared_logarithmic_error: 0.7281 - val_det_coeff: -inf\n",
      "Epoch 61/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9254.5186 - mean_squared_error: 9254.5186 - mean_squared_logarithmic_error: 0.7023 - det_coeff: -inf - val_loss: 13927.9883 - val_mean_squared_error: 13927.9883 - val_mean_squared_logarithmic_error: 0.7768 - val_det_coeff: -inf\n",
      "Epoch 62/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 9296.4473 - mean_squared_error: 9296.4473 - mean_squared_logarithmic_error: 0.6936 - det_coeff: -inf - val_loss: 13680.6982 - val_mean_squared_error: 13680.6982 - val_mean_squared_logarithmic_error: 0.7408 - val_det_coeff: -infTA: 4s - loss: 8830.\n",
      "Epoch 63/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9311.2480 - mean_squared_error: 9311.2480 - mean_squared_logarithmic_error: 0.7013 - det_coeff: -inf - val_loss: 13563.3447 - val_mean_squared_error: 13563.3447 - val_mean_squared_logarithmic_error: 0.7477 - val_det_coeff: -infss: 8956.4189 - mean_squared_error: 8956.4189 - mean_squared_logarithmic_error:  - ETA: 3s - loss: 9059.2197 - mean_squared_error: 9059.2197 - mean_squared_logarithmic_error: 0.7037 - det_coeff: -in - ETA: 3s - loss: 9037.9727 - mean_squared_error: 903\n",
      "Epoch 64/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9210.5342 - mean_squared_error: 9210.5342 - mean_squared_logarithmic_error: 0.6878 - det_coeff: -inf - val_loss: 14102.5781 - val_mean_squared_error: 14102.5781 - val_mean_squared_logarithmic_error: 0.7265 - val_det_coeff: -inf\n",
      "Epoch 65/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 9184.7695 - mean_squared_error: 9184.7695 - mean_squared_logarithmic_error: 0.6942 - det_coeff: -inf - val_loss: 13829.2021 - val_mean_squared_error: 13829.2021 - val_mean_squared_logarithmic_error: 0.7872 - val_det_coeff: -inf\n",
      "Epoch 66/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8938.2188 - mean_squared_error: 8938.2188 - mean_squared_logarithmic_error: 0.6877 - det_coeff: -inf - val_loss: 13522.3730 - val_mean_squared_error: 13522.3730 - val_mean_squared_logarithmic_error: 0.8291 - val_det_coeff: -inf\n",
      "Epoch 67/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8985.7051 - mean_squared_error: 8985.7051 - mean_squared_logarithmic_error: 0.6951 - det_coeff: -inf - val_loss: 14347.9570 - val_mean_squared_error: 14347.9570 - val_mean_squared_logarithmic_error: 0.7824 - val_det_coeff: -inf\n",
      "Epoch 68/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8815.6709 - mean_squared_error: 8815.6709 - mean_squared_logarithmic_error: 0.6819 - det_coeff: -inf - val_loss: 14006.9990 - val_mean_squared_error: 14006.9990 - val_mean_squared_logarithmic_error: 0.8299 - val_det_coeff: -infn_squared_logarithmic_erro\n",
      "Epoch 69/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8687.8945 - mean_squared_error: 8687.8945 - mean_squared_logarithmic_error: 0.6788 - det_coeff: -inf - val_loss: 14023.5371 - val_mean_squared_error: 14023.5371 - val_mean_squared_logarithmic_error: 0.7706 - val_det_coeff: -inf37.1270 - mean_squared_error: 8937.1270 - mean_squared - ETA: 5s - loss: 8794.7324 - mean_squared_error: 8794.7324 - mean_squared_logarithmic_erro - ETA: 3s - loss: 9086.8906 - mean_squared_error\n",
      "Epoch 70/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8733.2393 - mean_squared_error: 8733.2393 - mean_squared_logarithmic_error: 0.6829 - det_coeff: -inf - val_loss: 13349.2783 - val_mean_squared_error: 13349.2783 - val_mean_squared_logarithmic_error: 0.7846 - val_det_coeff: -infrror: 8717.3418 - mean_squared_logarithmic_error: 0.6831 - det_co\n",
      "Epoch 71/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8495.4082 - mean_squared_error: 8495.4082 - mean_squared_logarithmic_error: 0.6876 - det_coeff: -inf - val_loss: 13489.6230 - val_mean_squared_error: 13489.6230 - val_mean_squared_logarithmic_error: 0.7829 - val_det_coeff: -inf\n",
      "Epoch 72/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8525.2988 - mean_squared_error: 8525.2988 - mean_squared_logarithmic_error: 0.6815 - det_coeff: -inf - val_loss: 15325.9463 - val_mean_squared_error: 15325.9463 - val_mean_squared_logarithmic_error: 0.8171 - val_det_coeff: -infsquared_error: 8248.9238 - mean_squared_logar - ETA: 7s - loss: - ETA: 1s - loss: 8448.3750 - mean_squared_error: 8448.3750 - mean_squared_logarithmic_e\n",
      "Epoch 73/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8523.9971 - mean_squared_error: 8523.9971 - mean_squared_logarithmic_error: 0.6766 - det_coeff: -inf - val_loss: 14025.4502 - val_mean_squared_error: 14025.4502 - val_mean_squared_logarithmic_error: 0.7976 - val_det_coeff: -inf\n",
      "Epoch 74/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8309.5537 - mean_squared_error: 8309.5537 - mean_squared_logarithmic_error: 0.6790 - det_coeff: -inf - val_loss: 13704.9463 - val_mean_squared_error: 13704.9463 - val_mean_squared_logarithmic_error: 0.7035 - val_det_coeff: -inf\n",
      "Epoch 75/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8456.2471 - mean_squared_error: 8456.2471 - mean_squared_logarithmic_error: 0.6821 - det_coeff: -inf - val_loss: 13622.1475 - val_mean_squared_error: 13622.1475 - val_mean_squared_logarithmic_error: 0.7869 - val_det_coeff: -infrror: 8414.9893 - mean_squared_logarithmic_error: 0.6817 - det_coeff: -i\n",
      "Epoch 76/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8193.5303 - mean_squared_error: 8193.5303 - mean_squared_logarithmic_error: 0.6744 - det_coeff: -inf - val_loss: 13367.5811 - val_mean_squared_error: 13367.5811 - val_mean_squared_logarithmic_error: 0.8139 - val_det_coeff: -infarithmic_error: 0.6437 - det_c - ETA: 5s - loss: 7870.8389 - mean_squared_error: 7870.8389 - mean_squared_logarithmic_error: 0.6537 - det_ - ETA: 5s - loss: 7828.2744 - mean_squared_error: 7828.2744 - mean_squared_logarithmic_error - ETA: 3s - loss: 7944.2295 - mean_squared_error: 7944.2295 - mean_squared_logarithmic_error: 0.6593 - det_coeff:  - ETA: 3s - loss: 7911.8423 - mean_squared_error: 7911.8423 - mean_squared_logarithmic_error: 0.6 - ETA: 2s - loss: 8308.9590 - mean_squared_error: 8308.9590 - me\n",
      "Epoch 77/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8302.3965 - mean_squared_error: 8302.3965 - mean_squared_logarithmic_error: 0.6770 - det_coeff: -inf - val_loss: 13480.1816 - val_mean_squared_error: 13480.1816 - val_mean_squared_logarithmic_error: 0.7555 - val_det_coeff: -inf\n",
      "Epoch 78/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 8112.9614 - mean_squared_error: 8112.9614 - mean_squared_logarithmic_error: 0.6742 - det_coeff: -inf - val_loss: 12715.9072 - val_mean_squared_error: 12715.9072 - val_mean_squared_logarithmic_error: 0.7344 - val_det_coeff: -inf 7667.3501 - mean_squared_logarithmic_e\n",
      "Epoch 79/100\n",
      "12250/12250 [==============================] - 15s 1ms/step - loss: 8111.2646 - mean_squared_error: 8111.2646 - mean_squared_logarithmic_error: 0.6693 - det_coeff: -inf - val_loss: 12848.8428 - val_mean_squared_error: 12848.8428 - val_mean_squared_logarithmic_error: 0.7628 - val_det_coeff: -infn_squared_error: 8095.2520 - mean_squared_logarithmic_error: 0.6694 - de\n",
      "Epoch 80/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 8025.8755 - mean_squared_error: 8025.8755 - mean_squared_logarithmic_error: 0.6692 - det_coeff: -inf - val_loss: 13120.1143 - val_mean_squared_error: 13120.1143 - val_mean_squared_logarithmic_error: 0.7389 - val_det_coeff: -inf\n",
      "Epoch 81/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7819.9106 - mean_squared_error: 7819.9106 - mean_squared_logarithmic_error: 0.6669 - det_coeff: -inf - val_loss: 13228.3535 - val_mean_squared_error: 13228.3535 - val_mean_squared_logarithmic_error: 0.7515 - val_det_coeff: -infror: 7966.0132 - mean_squared_logarithm\n",
      "Epoch 82/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7832.1284 - mean_squared_error: 7832.1284 - mean_squared_logarithmic_error: 0.6744 - det_coeff: -inf - val_loss: 13936.9873 - val_mean_squared_error: 13936.9873 - val_mean_squared_logarithmic_error: 0.7504 - val_det_coeff: -inf3 - det - ETA: 5s - \n",
      "Epoch 83/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7914.9004 - mean_squared_error: 7914.9004 - mean_squared_logarithmic_error: 0.6705 - det_coeff: -inf - val_loss: 13037.3223 - val_mean_squared_error: 13037.3223 - val_mean_squared_logarithmic_error: 0.7300 - val_det_coeff: -inf\n",
      "Epoch 84/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7729.0259 - mean_squared_error: 7729.0259 - mean_squared_logarithmic_error: 0.6614 - det_coeff: -inf - val_loss: 13286.1396 - val_mean_squared_error: 13286.1396 - val_mean_squared_logarithmic_error: 0.8279 - val_det_coeff: -inf637.6401 - mean_squared_logarithmic_error: 0. - ETA: 3s - loss: 7571.4121 - mean_squared_error: 7571.4121 - mean_squa - ETA: 1s - loss: 7484.7256 - mean_squared_error: 7484.7256 - mean_squared_logarithmic_error: 0.6556 - de - ETA: 0s - loss: 7550.0679 - mean_squared_error: 7550.0679 - mean_squared_logarithmic_error: 0.658\n",
      "Epoch 85/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7657.8999 - mean_squared_error: 7657.8999 - mean_squared_logarithmic_error: 0.6689 - det_coeff: -inf - val_loss: 13601.1836 - val_mean_squared_error: 13601.1836 - val_mean_squared_logarithmic_error: 0.7858 - val_det_coeff: -inf - mean_squared_e - ETA: 5s - loss: 6667.7212 - mean_squared_error: 6667.7212 - mean_squared_logarithmi - ETA: 4s - loss: 7223.3452 - mean_s\n",
      "Epoch 86/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7599.2510 - mean_squared_error: 7599.2510 - mean_squared_logarithmic_error: 0.6687 - det_coeff: -inf - val_loss: 12738.5186 - val_mean_squared_error: 12738.5186 - val_mean_squared_logarithmic_error: 0.7536 - val_det_coeff: -inf\n",
      "Epoch 87/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7532.3691 - mean_squared_error: 7532.3691 - mean_squared_logarithmic_error: 0.6602 - det_coeff: -inf - val_loss: 12927.9102 - val_mean_squared_error: 12927.9102 - val_mean_squared_logarithmic_error: 0.7926 - val_det_coeff: -inf628.2637 - mean_squared_error: 7628.2637 - mean_squared_logarithmic_error: 0.6664 - de - ETA: 1s - loss: 7562.6836 - mean_squared_error: 7562.6836 - mean_squared_logarithmic_error: 0.6651 - det_coe - ETA: 1s - loss: 7484.1509 - mean_squared_error: 7484.1509 - mean_squared_logarit\n",
      "Epoch 88/100\n",
      "12250/12250 [==============================] - 15s 1ms/step - loss: 7538.5098 - mean_squared_error: 7538.5098 - mean_squared_logarithmic_error: 0.6635 - det_coeff: -inf - val_loss: 13291.0869 - val_mean_squared_error: 13291.0869 - val_mean_squared_logarithmic_error: 0.7841 - val_det_coeff: -inf 675 - ETA: 8s - loss: 7449.9375 - mean_squared_error: 7449.9375 - mean_squared_logarithmic_error: 0 - ETA: 7s - loss: 7428.9570 - mean_squared_error: 7428.9570 - mean_squar - ETA: 5s - loss: 7299.0928 - mean_squared_error: 7299.0928 - mean_squared_logarithmic_ - ETA: 3s - loss: 7372.6904 - mean_squared_error: 7372.6904 - mean_squared_logarithmic_error: 0.6568 - det_coeff: - - ETA: 3s - loss: 7395.6411 - mean_squared_error: 7395.6411 - mean_squared_logarithmic_error: 0. - ETA: 2s - loss: 7410.6504 - mean_squared_error: 7410.6504 - mean_squared_logarithmic_error: 0.658 - ETA: 1s - loss: 7514.8384 - mean_squared_error: 7514.8384 - mean_squared_logarithmic_error: 0.6600 - det_coeff: - - ETA: 1s - loss: 7487.4189 - mean_squared_error: 7487.4189 - mean_squared_logarithmic_error: 0.6609 - det_coeff: - - ETA: 1s - loss: 7466.7432 - mean_squared_error: 7466.7432 - mean_squared_logarithmic_error: 0.6\n",
      "Epoch 89/100\n",
      "12250/12250 [==============================] - 15s 1ms/step - loss: 7386.6099 - mean_squared_error: 7386.6099 - mean_squared_logarithmic_error: 0.6528 - det_coeff: -inf - val_loss: 14099.1768 - val_mean_squared_error: 14099.1768 - val_mean_squared_logarithmic_error: 0.7543 - val_det_coeff: -inf mean_squared_error: 9865.3418 - mean_squared_log - ETA: 10s - loss: 7636.5869 - mean_squared_error: 7636.5869 - mean_squared_logarithmic_error: 0. - ETA: 9s - loss: 7109.0703 - mean_squared_error: 7109.0703 - mean_squared_logarithmic_error: 0.6471 - d - ETA: 2s - loss: 7603.0396 - mean_squared_error: 7603.0396 - mean_sq\n",
      "Epoch 90/100\n",
      "12250/12250 [==============================] - 15s 1ms/step - loss: 7451.1885 - mean_squared_error: 7451.1885 - mean_squared_logarithmic_error: 0.6527 - det_coeff: -inf - val_loss: 12891.2324 - val_mean_squared_error: 12891.2324 - val_mean_squared_logarithmic_error: 0.7640 - val_det_coeff: -infor: 7163.9131 - mean_square - ETA: 7s - loss: 6968.5068 - mean_squared_error: 6968.5068 - mean_squared_logarithmic_error: 0.6519 - det_ - ETA: 7s - loss: 6913.5088 - mean_squared_error: 6913.5088 - mean_squared_logarithmic_error: 0.6568 - det_coef - ETA: 6s - loss: 6800.4395 - mean_squared_error: 6800.4395 - mean_squared_logarithmic_error: 0 - ETA: 5s - los\n",
      "Epoch 91/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7276.0156 - mean_squared_error: 7276.0156 - mean_squared_logarithmic_error: 0.6582 - det_coeff: -inf - val_loss: 12479.0820 - val_mean_squared_error: 12479.0820 - val_mean_squared_logarithmic_error: 0.7460 - val_det_coeff: -infuared_error: 8217.4287 - - ETA: 0s - loss: 7344.6636 - mean_squared_error: 7344.6636 - mean_squared_logarithmic_error: 0.6595 - det_coeff\n",
      "Epoch 92/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7212.7954 - mean_squared_error: 7212.7954 - mean_squared_logarithmic_error: 0.6632 - det_coeff: -inf - val_loss: 13088.0049 - val_mean_squared_error: 13088.0049 - val_mean_squared_logarithmic_error: 0.7378 - val_det_coeff: -inf\n",
      "Epoch 93/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7141.4033 - mean_squared_error: 7141.4033 - mean_squared_logarithmic_error: 0.6600 - det_coeff: -inf - val_loss: 12724.9932 - val_mean_squared_error: 12724.9932 - val_mean_squared_logarithmic_error: 0.7149 - val_det_coeff: -inf\n",
      "Epoch 94/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7165.9570 - mean_squared_error: 7165.9570 - mean_squared_logarithmic_error: 0.6476 - det_coeff: -inf - val_loss: 12204.2793 - val_mean_squared_error: 12204.2793 - val_mean_squared_logarithmic_error: 0.7261 - val_det_coeff: -inf mean_squared_error:  - ETA: 3s - loss: 7055.5220 - mean_squared_error: 7055.5220 - mean_squared_logarithmic_error: 0.6437 - det_co - ETA: 3s - loss: 7015.5620 - mean_squared_error: 7015.5620 - mean_squared_logarithmic_error: 0.6467 - det_coeff: - ETA: 2s - loss: 7055.4517 - mean_squared_error: 7055.4517 -\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7205.7935 - mean_squared_error: 7205.7935 - mean_squared_logarithmic_error: 0.6558 - det_coeff: -inf - val_loss: 12468.0908 - val_mean_squared_error: 12468.0908 - val_mean_squared_logarithmic_error: 0.7117 - val_det_coeff: -inf\n",
      "Epoch 96/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 7001.9385 - mean_squared_error: 7001.9385 - mean_squared_logarithmic_error: 0.6503 - det_coeff: -inf - val_loss: 12655.1416 - val_mean_squared_error: 12655.1416 - val_mean_squared_logarithmic_error: 0.7551 - val_det_coeff: -inf\n",
      "Epoch 97/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 6961.7334 - mean_squared_error: 6961.7334 - mean_squared_logarithmic_error: 0.6587 - det_coeff: -inf - val_loss: 12182.4082 - val_mean_squared_error: 12182.4082 - val_mean_squared_logarithmic_error: 0.6969 - val_det_coeff: -infan_squared_error: 6920.9702 - mean_squared_logarithmic_e\n",
      "Epoch 98/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 7066.4727 - mean_squared_error: 7066.4727 - mean_squared_logarithmic_error: 0.6558 - det_coeff: -inf - val_loss: 15869.4629 - val_mean_squared_error: 15869.4629 - val_mean_squared_logarithmic_error: 0.8256 - val_det_coeff: -inf - mean_squared_logarithmic_error:  - ETA: 6s - loss: 6673.8818 - mean_squared_error: 6673.8818 - mean_squared_logarithmic_err - ETA: 5s - loss: 6420.6 - ETA: 0s - loss: 7058.9131 - mean_squared_error: 7058.9131 - mean_squared_logarithmic_error: 0.6549 - d\n",
      "Epoch 99/100\n",
      "12250/12250 [==============================] - 13s 1ms/step - loss: 6982.5908 - mean_squared_error: 6982.5908 - mean_squared_logarithmic_error: 0.6585 - det_coeff: -inf - val_loss: 13207.7197 - val_mean_squared_error: 13207.7197 - val_mean_squared_logarithmic_error: 0.7557 - val_det_coeff: -inf627.9360 - mean_squared_error: 662 - ETA: 3s - loss: 6984.8628 - mean_squared_er\n",
      "Epoch 100/100\n",
      "12250/12250 [==============================] - 14s 1ms/step - loss: 6878.7114 - mean_squared_error: 6878.7114 - mean_squared_logarithmic_error: 0.6522 - det_coeff: -inf - val_loss: 13384.4180 - val_mean_squared_error: 13384.4180 - val_mean_squared_logarithmic_error: 0.7951 - val_det_coeff: -inf\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pca, y_train, batch_size=2, epochs=100, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:45:14.642906Z",
     "start_time": "2021-05-10T21:45:14.621925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_squared_error', 'mean_squared_logarithmic_error', 'det_coeff', 'val_loss', 'val_mean_squared_error', 'val_mean_squared_logarithmic_error', 'val_det_coeff'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:46:02.672717Z",
     "start_time": "2021-05-10T21:46:02.247916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d09332d640>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:01:26.198794Z",
     "start_time": "2021-05-10T20:01:25.495334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 8415.242815932415 EVS: 0.791611134779733 R2: 0.7910709893715125\n",
      "Test Score: MSE: 13037.545496267461 EVS: 0.6541490753629551 R2: 0.6540937355663705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, explained_variance_score,r2_score, mean_squared_log_error\n",
    "\n",
    "pred_train = model.predict(X_train_pca)\n",
    "print(\"Train score:\", \"MSE:\",mean_squared_error(y_train,pred_train),\"EVS:\",explained_variance_score(y_train,pred_train),\"R2:\",r2_score(y_train,pred_train))\n",
    "\n",
    "pred = model.predict(X_test_pca)\n",
    "print(\"Test Score:\", \"MSE:\", mean_squared_error(y_test,pred),\"EVS:\",explained_variance_score(y_test,pred),\"R2:\",r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:21:17.817638Z",
     "start_time": "2021-05-10T23:21:17.762183Z"
    }
   },
   "outputs": [],
   "source": [
    "# validation curve\n",
    "input_layer = Input(shape=(X_test_pca.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model_val = Model(inputs=input_layer, outputs=output)\n",
    "model_val.compile(loss=\"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\",\"mean_squared_logarithmic_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:30:31.568962Z",
     "start_time": "2021-05-10T23:21:18.937208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 43976.4219 - mean_squared_error: 43976.4219 - mean_squared_logarithmic_error: 2.1982 - val_loss: 41613.6094 - val_mean_squared_error: 41613.6094 - val_mean_squared_logarithmic_error: 2.3911\n",
      "Epoch 2/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42895.8672 - mean_squared_error: 42895.8672 - mean_squared_logarithmic_error: 2.1235 - val_loss: 40832.8398 - val_mean_squared_error: 40832.8398 - val_mean_squared_logarithmic_error: 2.1783\n",
      "Epoch 3/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42793.2578 - mean_squared_error: 42793.2578 - mean_squared_logarithmic_error: 2.1334 - val_loss: 40763.9922 - val_mean_squared_error: 40763.9922 - val_mean_squared_logarithmic_error: 2.1721 43307.4805 - mean_squared_error: 43307.4805 - mean_squared_logari - ETA: 2s - loss: 44543.2461 - mean_squared_error: 44543.2461 - mean_squared_logarithmic_er - ETA: 1s - loss: 44864.9883 - mean_squared_error: 44864.9883 - \n",
      "Epoch 4/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42726.9766 - mean_squared_error: 42726.9766 - mean_squared_logarithmic_error: 2.1418 - val_loss: 40992.4570 - val_mean_squared_error: 40992.4570 - val_mean_squared_logarithmic_error: 2.0086\n",
      "Epoch 5/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42606.9688 - mean_squared_error: 42606.9688 - mean_squared_logarithmic_error: 2.1377 - val_loss: 40857.7891 - val_mean_squared_error: 40857.7891 - val_mean_squared_logarithmic_error: 2.0899\n",
      "Epoch 6/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42561.0664 - mean_squared_error: 42561.0664 - mean_squared_logarithmic_error: 2.1361 - val_loss: 40934.6719 - val_mean_squared_error: 40934.6719 - val_mean_squared_logarithmic_error: 2.2548\n",
      "Epoch 7/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42460.4375 - mean_squared_error: 42460.4375 - mean_squared_logarithmic_error: 2.1341 - val_loss: 40726.9102 - val_mean_squared_error: 40726.9102 - val_mean_squared_logarithmic_error: 2.0443\n",
      "Epoch 8/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42473.3477 - mean_squared_error: 42473.3477 - mean_squared_logarithmic_error: 2.1438 - val_loss: 40892.3906 - val_mean_squared_error: 40892.3906 - val_mean_squared_logarithmic_error: 2.1176 - loss: 43079.0039 - mean_squared_error: 43079.0039 - mean_squared_logarithmic - ETA: 0s - loss: 42906.5508 - mean_squared_error: 42906.5508 - mean_squared_logarithmic\n",
      "Epoch 9/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42426.2656 - mean_squared_error: 42426.2656 - mean_squared_logarithmic_error: 2.1411 - val_loss: 40858.2578 - val_mean_squared_error: 40858.2578 - val_mean_squared_logarithmic_error: 2.2687\n",
      "Epoch 10/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42383.8008 - mean_squared_error: 42383.8008 - mean_squared_logarithmic_error: 2.1412 - val_loss: 40951.0625 - val_mean_squared_error: 40951.0625 - val_mean_squared_logarithmic_error: 2.3029\n",
      "Epoch 11/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42344.3906 - mean_squared_error: 42344.3906 - mean_squared_logarithmic_error: 2.1393 - val_loss: 40839.6055 - val_mean_squared_error: 40839.6055 - val_mean_squared_logarithmic_error: 2.1575 - loss: 52664.8398 - mean_squared_error: 52664.8398 - mean_squared_logarithmic_error: 2.19 - ETA: 3s - loss: 51908.7344 - mean_squared_error: 51908.7344 - mean_squared_logarithmic_error - ETA: 3s - loss: 47831.2148 - mean_squared_error: 47831.2148 - mean_squared_logarithmic_erro - ETA: 2s - loss: 42410.6602 - mean_squared_error: 42410.6602 - mean_squared_logari - ETA: 2s - loss: 41799.5547 - mean_squared_error: 41799.5547 \n",
      "Epoch 12/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42328.1875 - mean_squared_error: 42328.1875 - mean_squared_logarithmic_error: 2.1505 - val_loss: 40752.2148 - val_mean_squared_error: 40752.2148 - val_mean_squared_logarithmic_error: 2.0543quared_error: 44191.2031 - mean_squared_logar - ETA: 0s - loss: 42830.2969 - mean_squared_error: 42830.2969 - mean_squared_logarithmic_err\n",
      "Epoch 13/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42316.8594 - mean_squared_error: 42316.8594 - mean_squared_logarithmic_error: 2.1386 - val_loss: 40753.8047 - val_mean_squared_error: 40753.8047 - val_mean_squared_logarithmic_error: 2.084036.6758 - mean_squared_error: 41236.6758 - mean_squar - ETA: 0s - loss: 41536.3711 - mean_squared_error: 41536.3711 - mean_squared_logarith\n",
      "Epoch 14/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42237.5547 - mean_squared_error: 42237.5547 - mean_squared_logarithmic_error: 2.1344 - val_loss: 41288.5391 - val_mean_squared_error: 41288.5391 - val_mean_squared_logarithmic_error: 2.4149\n",
      "Epoch 15/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42243.2031 - mean_squared_error: 42243.2031 - mean_squared_logarithmic_error: 2.1565 - val_loss: 40892.1953 - val_mean_squared_error: 40892.1953 - val_mean_squared_logarithmic_error: 1.9487ss: 42489.0898 - mean_squared_error: 42489.0898 - mean_squared_lo\n",
      "Epoch 16/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42187.0742 - mean_squared_error: 42187.0742 - mean_squared_logarithmic_error: 2.1440 - val_loss: 40848.9023 - val_mean_squared_error: 40848.9023 - val_mean_squared_logarithmic_error: 2.1269\n",
      "Epoch 17/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42182.9844 - mean_squared_error: 42182.9844 - mean_squared_logarithmic_error: 2.1445 - val_loss: 40946.3945 - val_mean_squared_error: 40946.3945 - val_mean_squared_logarithmic_error: 2.1263\n",
      "Epoch 18/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 42131.3125 - mean_squared_error: 42131.3125 - mean_squared_logarithmic_error: 2.1373 - val_loss: 41285.5977 - val_mean_squared_error: 41285.5977 - val_mean_squared_logarithmic_error: 2.3377.5898 - mean_squared_error: 417\n",
      "Epoch 19/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42081.6875 - mean_squared_error: 42081.6875 - mean_squared_logarithmic_error: 2.1424 - val_loss: 40911.2656 - val_mean_squared_error: 40911.2656 - val_mean_squared_logarithmic_error: 2.12229.0469 - mean_squared_error: 43789.0469 -  - ETA: 0s - loss: 43487.6992 - mean_squared_error: 43487.6992 - mean_squared_logarithmic_error: 2.14 - ETA: 0s - loss: 43468.4414 - mean_squared_error: 43468.4414 - mean_squared_logarith\n",
      "Epoch 20/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42017.4961 - mean_squared_error: 42017.4961 - mean_squared_logarithmic_error: 2.1317 - val_loss: 41238.9961 - val_mean_squared_error: 41238.9961 - val_mean_squared_logarithmic_error: 2.3591738.6055 - mean_squared_erro\n",
      "Epoch 21/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42011.0039 - mean_squared_error: 42011.0039 - mean_squared_logarithmic_error: 2.1438 - val_loss: 41050.7773 - val_mean_squared_error: 41050.7773 - val_mean_squared_logarithmic_error: 2.1614\n",
      "Epoch 22/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41989.6758 - mean_squared_error: 41989.6758 - mean_squared_logarithmic_error: 2.1325 - val_loss: 41495.4648 - val_mean_squared_error: 41495.4648 - val_mean_squared_logarithmic_error: 2.4264\n",
      "Epoch 23/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 42029.8867 - mean_squared_error: 42029.8867 - mean_squared_logarithmic_error: 2.1459 - val_loss: 40930.3125 - val_mean_squared_error: 40930.3125 - val_mean_squared_logarithmic_error: 2.11703s - loss: 42948.7070 - mean_squared_error: 42948.7070 - mean_squared_logarithmic_erro - ETA: 3s - loss: 45324.9375 - mean_squa\n",
      "Epoch 24/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41900.4258 - mean_squared_error: 41900.4258 - mean_squared_logarithmic_error: 2.1324 - val_loss: 41119.2227 - val_mean_squared_error: 41119.2227 - val_mean_squared_logarithmic_error: 2.2191 39632.7930 - mean_squared_ - ETA: 0s - loss: 41879.2227 - mean_squared_error: 41879.2227 - mean_squared_logarithmic_error: 2.13\n",
      "Epoch 25/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 41823.1562 - mean_squared_error: 41823.1562 - mean_squared_logarithmic_error: 2.1331 - val_loss: 41562.9180 - val_mean_squared_error: 41562.9180 - val_mean_squared_logarithmic_error: 2.3307\n",
      "Epoch 26/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 41801.4609 - mean_squared_error: 41801.4609 - mean_squared_logarithmic_error: 2.1322 - val_loss: 41083.3828 - val_mean_squared_error: 41083.3828 - val_mean_squared_logarithmic_error: 2.1390ean_squared_error: 42066.5781 - mean_squared_logarithmic_error: \n",
      "Epoch 27/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41841.4727 - mean_squared_error: 41841.4727 - mean_squared_logarithmic_error: 2.1346 - val_loss: 41297.2734 - val_mean_squared_error: 41297.2734 - val_mean_squared_logarithmic_error: 2.1575\n",
      "Epoch 28/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41661.0547 - mean_squared_error: 41661.0547 - mean_squared_logarithmic_error: 2.1270 - val_loss: 41172.5781 - val_mean_squared_error: 41172.5781 - val_mean_squared_logarithmic_error: 2.1151 - mean_squared_error: 42386.6445 - mean_squared_logarithmic_error: 2.122 - ETA: 1s - loss: 42494.1719 - mean_squared_error: 42494.1719 - mean\n",
      "Epoch 29/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41499.7930 - mean_squared_error: 41499.7930 - mean_squared_logarithmic_error: 2.1118 - val_loss: 42223.9922 - val_mean_squared_error: 42223.9922 - val_mean_squared_logarithmic_error: 2.4722\n",
      "Epoch 30/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41524.8828 - mean_squared_error: 41524.8828 - mean_squared_logarithmic_error: 2.1326 - val_loss: 41204.6523 - val_mean_squared_error: 41204.6523 - val_mean_squared_logarithmic_error: 2.0363\n",
      "Epoch 31/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 41370.9258 - mean_squared_error: 41370.9258 - mean_squared_logarithmic_error: 2.1196 - val_loss: 41350.9961 - val_mean_squared_error: 41350.9961 - val_mean_squared_logarithmic_error: 1.9545\n",
      "Epoch 32/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41354.4766 - mean_squared_error: 41354.4766 - mean_squared_logarithmic_error: 2.1070 - val_loss: 41445.8711 - val_mean_squared_error: 41445.8711 - val_mean_squared_logarithmic_error: 2.2591\n",
      "Epoch 33/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 41240.5000 - mean_squared_error: 41240.5000 - mean_squared_logarithmic_error: 2.1141 - val_loss: 41677.2266 - val_mean_squared_error: 41677.2266 - val_mean_squared_logarithmic_error: 2.2804\n",
      "Epoch 34/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 41120.4570 - mean_squared_error: 41120.4570 - mean_squared_logarithmic_error: 2.1120 - val_loss: 41728.8281 - val_mean_squared_error: 41728.8281 - val_mean_squared_logarithmic_error: 2.1289: 39886.6016 - mean_squared_error: 39886.6016 - mean_squared - ETA: 0s - loss: 41532.9062 - mean_squared_error: 41532.9062 - mean_squared_logarithmic_error: 2\n",
      "Epoch 35/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 41015.5508 - mean_squared_error: 41015.5508 - mean_squared_logarithmic_error: 2.1081 - val_loss: 41750.4805 - val_mean_squared_error: 41750.4805 - val_mean_squared_logarithmic_error: 2.1303\n",
      "Epoch 36/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 40747.5977 - mean_squared_error: 40747.5977 - mean_squared_logarithmic_error: 2.0940 - val_loss: 42034.9375 - val_mean_squared_error: 42034.9375 - val_mean_squared_logarithmic_error: 2.3222\n",
      "Epoch 37/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 40741.1836 - mean_squared_error: 40741.1836 - mean_squared_logarithmic_error: 2.1004 - val_loss: 42056.1484 - val_mean_squared_error: 42056.1484 - val_mean_squared_logarithmic_error: 2.2535 - mean_squared_error: 41328.5781 - mean\n",
      "Epoch 38/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 40472.9609 - mean_squared_error: 40472.9609 - mean_squared_logarithmic_error: 2.0959 - val_loss: 42314.0039 - val_mean_squared_error: 42314.0039 - val_mean_squared_logarithmic_error: 2.3115\n",
      "Epoch 39/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 40345.8203 - mean_squared_error: 40345.8203 - mean_squared_logarithmic_error: 2.1006 - val_loss: 41938.7969 - val_mean_squared_error: 41938.7969 - val_mean_squared_logarithmic_error: 2.2115\n",
      "Epoch 40/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 40252.5977 - mean_squared_error: 40252.5977 - mean_squared_logarithmic_error: 2.0972 - val_loss: 41986.3828 - val_mean_squared_error: 41986.3828 - val_mean_squared_logarithmic_error: 2.0486\n",
      "Epoch 41/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 40035.8633 - mean_squared_error: 40035.8633 - mean_squared_logarithmic_error: 2.0724 - val_loss: 42527.4023 - val_mean_squared_error: 42527.4023 - val_mean_squared_logarithmic_error: 2.2082 - mean_squared_logarithmic_error: 2.07\n",
      "Epoch 42/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 39716.0273 - mean_squared_error: 39716.0273 - mean_squared_logarithmic_error: 2.0764 - val_loss: 42265.3750 - val_mean_squared_error: 42265.3750 - val_mean_squared_logarithmic_error: 2.1944ss: 36303.0430 - mean_sq\n",
      "Epoch 43/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 39652.9922 - mean_squared_error: 39652.9922 - mean_squared_logarithmic_error: 2.0759 - val_loss: 42939.9414 - val_mean_squared_error: 42939.9414 - val_mean_squared_logarithmic_error: 2.1620 loss: 40020.6602 - mean_squared_error: 40020.6602 - mean_squared_logarithmic_err - ETA: 2s - loss: 40239.5117 - mean_squared_error: 402 - ETA: 0s - loss: 40488.9688 - mean_squared_error: 40488.9688 - mean_squared_logarithmic_e\n",
      "Epoch 44/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 39183.7891 - mean_squared_error: 39183.7891 - mean_squared_logarithmic_error: 2.0538 - val_loss: 42443.6719 - val_mean_squared_error: 42443.6719 - val_mean_squared_logarithmic_error: 2.2418\n",
      "Epoch 45/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 39241.5469 - mean_squared_error: 39241.5469 - mean_squared_logarithmic_error: 2.0758 - val_loss: 42311.2031 - val_mean_squared_error: 42311.2031 - val_mean_squared_logarithmic_error: 2.0350\n",
      "Epoch 46/100\n",
      "5250/5250 [==============================] - 5s 977us/step - loss: 39025.8164 - mean_squared_error: 39025.8164 - mean_squared_logarithmic_error: 2.0488 - val_loss: 43429.6992 - val_mean_squared_error: 43429.6992 - val_mean_squared_logarithmic_error: 2.4232ean_squared_error: 36537.2344 - mean_squared_logari - ETA: 0s - loss: 38239.8203 - mean_squared_error: 38239.8203 - mean_squared_logarithmic_error: 2.\n",
      "Epoch 47/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 38430.0781 - mean_squared_error: 38430.0781 - mean_squared_logarithmic_error: 2.0533 - val_loss: 44149.3086 - val_mean_squared_error: 44149.3086 - val_mean_squared_logarithmic_error: 2.3161\n",
      "Epoch 48/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 38271.8984 - mean_squared_error: 38271.8984 - mean_squared_logarithmic_error: 2.0394 - val_loss: 42898.8984 - val_mean_squared_error: 42898.8984 - val_mean_squared_logarithmic_error: 2.0408\n",
      "Epoch 49/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 38153.6172 - mean_squared_error: 38153.6172 - mean_squared_logarithmic_error: 2.0439 - val_loss: 43639.9492 - val_mean_squared_error: 43639.9492 - val_mean_squared_logarithmic_error: 2.2259\n",
      "Epoch 50/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 37846.6484 - mean_squared_error: 37846.6484 - mean_squared_logarithmic_error: 2.0315 - val_loss: 45351.2266 - val_mean_squared_error: 45351.2266 - val_mean_squared_logarithmic_error: 2.2809\n",
      "Epoch 51/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 37593.9062 - mean_squared_error: 37593.9062 - mean_squared_logarithmic_error: 2.0198 - val_loss: 43914.3203 - val_mean_squared_error: 43914.3203 - val_mean_squared_logarithmic_error: 2.2992\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5250/5250 [==============================] - 6s 1ms/step - loss: 37631.0938 - mean_squared_error: 37631.0938 - mean_squared_logarithmic_error: 2.0238 - val_loss: 45659.2383 - val_mean_squared_error: 45659.2383 - val_mean_squared_logarithmic_error: 2.24237082.4141 - me\n",
      "Epoch 53/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 37439.3672 - mean_squared_error: 37439.3672 - mean_squared_logarithmic_error: 2.0173 - val_loss: 46933.0117 - val_mean_squared_error: 46933.0117 - val_mean_squared_logarithmic_error: 2.32369531 - mean_squared_error: 38075.95\n",
      "Epoch 54/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 37240.0859 - mean_squared_error: 37240.0859 - mean_squared_logarithmic_error: 2.0220 - val_loss: 47590.1797 - val_mean_squared_error: 47590.1797 - val_mean_squared_logarithmic_error: 2.2908.4102 - mean_squared_error: 33926.4102\n",
      "Epoch 55/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 36817.5898 - mean_squared_error: 36817.5898 - mean_squared_logarithmic_error: 2.0115 - val_loss: 46349.2656 - val_mean_squared_error: 46349.2656 - val_mean_squared_logarithmic_error: 2.2306oss: 39801.8984 - mean_squared_error: 39801.8984 - mean_squared_logarithmic_error: 2.1 - ETA: 3s - loss: 38613.0781 - mean_squared_error: 38613.0781 - mean_squared_logarithmic_error: 2.079 - ETA: 3s - loss: 38609.1406 - mean_squared_erro - ETA: 0s - loss: 36648.8477 - mean_squared_error: 36648.8477 - mean_squared_logarithmic_error\n",
      "Epoch 56/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 37125.0547 - mean_squared_error: 37125.0547 - mean_squared_logarithmic_error: 2.0009 - val_loss: 43517.5078 - val_mean_squared_error: 43517.5078 - val_mean_squared_logarithmic_error: 2.2608\n",
      "Epoch 57/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 36765.9961 - mean_squared_error: 36765.9961 - mean_squared_logarithmic_error: 2.0042 - val_loss: 45138.0781 - val_mean_squared_error: 45138.0781 - val_mean_squared_logarithmic_error: 2.2455\n",
      "Epoch 58/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 36419.9727 - mean_squared_error: 36419.9727 - mean_squared_logarithmic_error: 1.9976 - val_loss: 46828.2188 - val_mean_squared_error: 46828.2188 - val_mean_squared_logarithmic_error: 2.3001\n",
      "Epoch 59/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 36317.5469 - mean_squared_error: 36317.5469 - mean_squared_logarithmic_error: 1.9987 - val_loss: 45835.2930 - val_mean_squared_error: 45835.2930 - val_mean_squared_logarithmic_error: 2.0177\n",
      "Epoch 60/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 36473.2891 - mean_squared_error: 36473.2891 - mean_squared_logarithmic_error: 1.9930 - val_loss: 44375.7812 - val_mean_squared_error: 44375.7812 - val_mean_squared_logarithmic_error: 2.2146- loss: 35274.4062 - mean_squared_error: 35274.4062 - mean_squared_logarithmic_error: 1. - ETA: 1s - loss: 35422.8398 - mean_squared_error: 35422.8398 - mean_squared_logar\n",
      "Epoch 61/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 36174.6602 - mean_squared_error: 36174.6602 - mean_squared_logarithmic_error: 1.9897 - val_loss: 45199.8711 - val_mean_squared_error: 45199.8711 - val_mean_squared_logarithmic_error: 2.3914\n",
      "Epoch 62/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 35881.7969 - mean_squared_error: 35881.7969 - mean_squared_logarithmic_error: 1.9834 - val_loss: 44152.1211 - val_mean_squared_error: 44152.1211 - val_mean_squared_logarithmic_error: 2.2749.7539 - mean_squared_error: 38497.7539 - mean_square - ETA: 1s - loss: 36541.1797 - mean_squared_error: 36541.1797 - mean\n",
      "Epoch 63/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 35940.9375 - mean_squared_error: 35940.9375 - mean_squared_logarithmic_error: 1.9928 - val_loss: 46473.1016 - val_mean_squared_error: 46473.1016 - val_mean_squared_logarithmic_error: 2.2342\n",
      "Epoch 64/100\n",
      "5250/5250 [==============================] - 5s 988us/step - loss: 35732.3242 - mean_squared_error: 35732.3242 - mean_squared_logarithmic_error: 1.9765 - val_loss: 50286.1875 - val_mean_squared_error: 50286.1875 - val_mean_squared_logarithmic_error: 2.2024\n",
      "Epoch 65/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 35430.0547 - mean_squared_error: 35430.0547 - mean_squared_logarithmic_error: 1.9827 - val_loss: 46009.5859 - val_mean_squared_error: 46009.5859 - val_mean_squared_logarithmic_error: 2.3123\n",
      "Epoch 66/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 35418.1914 - mean_squared_error: 35418.1914 - mean_squared_logarithmic_error: 1.9740 - val_loss: 44857.5117 - val_mean_squared_error: 44857.5117 - val_mean_squared_logarithmic_error: 2.0955750.7070 - mean_squared_loga\n",
      "Epoch 67/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 35285.4102 - mean_squared_error: 35285.4102 - mean_squared_logarithmic_error: 1.9621 - val_loss: 44788.4766 - val_mean_squared_error: 44788.4766 - val_mean_squared_logarithmic_error: 2.1328 loss: 36650.0898 - mean_squared_error: 36650.0898 - mean_squared_logarithmic_er - ETA: 3s - loss: 35856.3320 - mean_squared_error: 35856.3320 - mean_ - ETA: 1s - loss: 37328.6484 - mean_squared_error: 37328.6484 - mean_\n",
      "Epoch 68/100\n",
      "5250/5250 [==============================] - 5s 979us/step - loss: 35034.9805 - mean_squared_error: 35034.9805 - mean_squared_logarithmic_error: 1.9502 - val_loss: 48718.8555 - val_mean_squared_error: 48718.8555 - val_mean_squared_logarithmic_error: 2.3447\n",
      "Epoch 69/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 35349.1797 - mean_squared_error: 35349.1797 - mean_squared_logarithmic_error: 1.9600 - val_loss: 48005.7930 - val_mean_squared_error: 48005.7930 - val_mean_squared_logarithmic_error: 2.3451\n",
      "Epoch 70/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 35190.2734 - mean_squared_error: 35190.2734 - mean_squared_logarithmic_error: 1.9512 - val_loss: 45839.1602 - val_mean_squared_error: 45839.1602 - val_mean_squared_logarithmic_error: 2.2770\n",
      "Epoch 71/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 34801.7852 - mean_squared_error: 34801.7852 - mean_squared_logarithmic_error: 1.9490 - val_loss: 45778.2930 - val_mean_squared_error: 45778.2930 - val_mean_squared_logarithmic_error: 2.2767\n",
      "Epoch 72/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 34711.1055 - mean_squared_error: 34711.1055 - mean_squared_logarithmic_error: 1.9515 - val_loss: 45185.7812 - val_mean_squared_error: 45185.7812 - val_mean_squared_logarithmic_error: 2.1897\n",
      "Epoch 73/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 35111.6602 - mean_squared_error: 35111.6602 - mean_squared_logarithmic_error: 1.9572 - val_loss: 48783.3516 - val_mean_squared_error: 48783.3516 - val_mean_squared_logarithmic_error: 2.2841\n",
      "Epoch 74/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 33961.5430 - mean_squared_error: 33961.5430 - mean_squared_logarithmic_error: 1.9312 - val_loss: 45856.3359 - val_mean_squared_error: 45856.3359 - val_mean_squared_logarithmic_error: 2.220532216.3965 - mean_squared_error: 32216.3965 - mean_squared_logarithmic_error: 1.90 - ETA: 1s - loss: 32401.7441 - mean_squared_error: 32401.7441 - mean_squared_logarithmic_err - ETA: 1s - loss: 33057.2422 - mean_squared_error: 33057.2422 - mean_squared_lo\n",
      "Epoch 75/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 34560.3828 - mean_squared_error: 34560.3828 - mean_squared_logarithmic_error: 1.9364 - val_loss: 45251.7109 - val_mean_squared_error: 45251.7109 - val_mean_squared_logarithmic_error: 2.2142quared_logarithmic_error: 1.936\n",
      "Epoch 76/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 34299.6172 - mean_squared_error: 34299.6172 - mean_squared_logarithmic_error: 1.9339 - val_loss: 45470.0703 - val_mean_squared_error: 45470.0703 - val_mean_squared_logarithmic_error: 2.4235\n",
      "Epoch 77/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 34172.4570 - mean_squared_error: 34172.4570 - mean_squared_logarithmic_error: 1.9471 - val_loss: 48215.6016 - val_mean_squared_error: 48215.6016 - val_mean_squared_logarithmic_error: 2.26621.1211 - mean_squared_logari\n",
      "Epoch 78/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33626.3594 - mean_squared_error: 33626.3594 - mean_squared_logarithmic_error: 1.9182 - val_loss: 47201.6758 - val_mean_squared_error: 47201.6758 - val_mean_squared_logarithmic_error: 2.351529236.0156 - mean_squared_error: 29236.015 - ETA: 1s - loss: 33583.3008 - mean_squared_error: 33583.3008 - mean_squared\n",
      "Epoch 79/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33988.2930 - mean_squared_error: 33988.2930 - mean_squared_logarithmic_error: 1.9291 - val_loss: 47567.8477 - val_mean_squared_error: 47567.8477 - val_mean_squared_logarithmic_error: 2.3982\n",
      "Epoch 80/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 34025.4570 - mean_squared_error: 34025.4570 - mean_squared_logarithmic_error: 1.9244 - val_loss: 46663.8555 - val_mean_squared_error: 46663.8555 - val_mean_squared_logarithmic_error: 2.2673\n",
      "Epoch 81/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33909.4805 - mean_squared_error: 33909.4805 - mean_squared_logarithmic_error: 1.9277 - val_loss: 45730.0430 - val_mean_squared_error: 45730.0430 - val_mean_squared_logarithmic_error: 2.2129\n",
      "Epoch 82/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 33493.5938 - mean_squared_error: 33493.5938 - mean_squared_logarithmic_error: 1.9200 - val_loss: 48380.0117 - val_mean_squared_error: 48380.0117 - val_mean_squared_logarithmic_error: 2.3653\n",
      "Epoch 83/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33450.9414 - mean_squared_error: 33450.9414 - mean_squared_logarithmic_error: 1.9129 - val_loss: 46487.3086 - val_mean_squared_error: 46487.3086 - val_mean_squared_logarithmic_error: 2.23335000 - mean_squared_error: 33392.5000 - mean_squared_logarithmic_er\n",
      "Epoch 84/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33757.9688 - mean_squared_error: 33757.9688 - mean_squared_logarithmic_error: 1.9218 - val_loss: 47105.9336 - val_mean_squared_error: 47105.9336 - val_mean_squared_logarithmic_error: 2.170234076.5586 - mean_squared_error: 34076.5586 - mean_squared_logarithmic_error:\n",
      "Epoch 85/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33093.0703 - mean_squared_error: 33093.0703 - mean_squared_logarithmic_error: 1.9038 - val_loss: 44567.9414 - val_mean_squared_error: 44567.9414 - val_mean_squared_logarithmic_error: 2.1468\n",
      "Epoch 86/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 33169.4961 - mean_squared_error: 33169.4961 - mean_squared_logarithmic_error: 1.9165 - val_loss: 47282.2695 - val_mean_squared_error: 47282.2695 - val_mean_squared_logarithmic_error: 2.2949mean_squared_error: \n",
      "Epoch 87/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32949.6562 - mean_squared_error: 32949.6562 - mean_squared_logarithmic_error: 1.9099 - val_loss: 47032.5156 - val_mean_squared_error: 47032.5156 - val_mean_squared_logarithmic_error: 2.21592734 - mean_squared_error: 32744.2734 - mean_squared_logarithmic_error - ETA: 1s - loss: 32747.4004 - mean_squared_error: 32747.4004 - mean_sq\n",
      "Epoch 88/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33133.7148 - mean_squared_error: 33133.7148 - mean_squared_logarithmic_error: 1.9164 - val_loss: 47563.5039 - val_mean_squared_error: 47563.5039 - val_mean_squared_logarithmic_error: 2.1906\n",
      "Epoch 89/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 33067.9023 - mean_squared_error: 33067.9023 - mean_squared_logarithmic_error: 1.8958 - val_loss: 46237.4883 - val_mean_squared_error: 46237.4883 - val_mean_squared_logarithmic_error: 2.2726red_error: 34\n",
      "Epoch 90/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 33149.7539 - mean_squared_error: 33149.7539 - mean_squared_logarithmic_error: 1.9019 - val_loss: 48887.2969 - val_mean_squared_error: 48887.2969 - val_mean_squared_logarithmic_error: 2.2261ss: 33132.3242 - mean_squared_error: 33132.3242 - mean_squared_logarithm\n",
      "Epoch 91/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32405.5527 - mean_squared_error: 32405.5527 - mean_squared_logarithmic_error: 1.8971 - val_loss: 45932.3945 - val_mean_squared_error: 45932.3945 - val_mean_squared_logarithmic_error: 2.1947ean_squared_error: 34549.7383 - mean_squared_logarithmic_error: 1. - ETA: 2s - loss: 34726.7188 - mean_squared_error: 34726.71\n",
      "Epoch 92/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32758.3750 - mean_squared_error: 32758.3750 - mean_squared_logarithmic_error: 1.8958 - val_loss: 47571.6914 - val_mean_squared_error: 47571.6914 - val_mean_squared_logarithmic_error: 2.1767\n",
      "Epoch 93/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 32743.4219 - mean_squared_error: 32743.4219 - mean_squared_logarithmic_error: 1.8833 - val_loss: 47514.9414 - val_mean_squared_error: 47514.9414 - val_mean_squared_logarithmic_error: 2.146634793.4570 - mean_squared_error: 34793.4570 \n",
      "Epoch 94/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32085.9648 - mean_squared_error: 32085.9648 - mean_squared_logarithmic_error: 1.8942 - val_loss: 46645.2734 - val_mean_squared_error: 46645.2734 - val_mean_squared_logarithmic_error: 2.1727\n",
      "Epoch 95/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32482.2637 - mean_squared_error: 32482.2637 - mean_squared_logarithmic_error: 1.8889 - val_loss: 48604.4297 - val_mean_squared_error: 48604.4297 - val_mean_squared_logarithmic_error: 2.2597\n",
      "Epoch 96/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 32066.3340 - mean_squared_error: 32066.3340 - mean_squared_logarithmic_error: 1.8790 - val_loss: 47642.4180 - val_mean_squared_error: 47642.4180 - val_mean_squared_logarithmic_error: 2.1822\n",
      "Epoch 97/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32179.9902 - mean_squared_error: 32179.9902 - mean_squared_logarithmic_error: 1.8666 - val_loss: 49024.4883 - val_mean_squared_error: 49024.4883 - val_mean_squared_logarithmic_error: 2.2759\n",
      "Epoch 98/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 31578.2832 - mean_squared_error: 31578.2832 - mean_squared_logarithmic_error: 1.8719 - val_loss: 48708.2500 - val_mean_squared_error: 48708.2500 - val_mean_squared_logarithmic_error: 2.2419\n",
      "Epoch 99/100\n",
      "5250/5250 [==============================] - 5s 1ms/step - loss: 32097.5215 - mean_squared_error: 32097.5215 - mean_squared_logarithmic_error: 1.8716 - val_loss: 47578.4766 - val_mean_squared_error: 47578.4766 - val_mean_squared_logarithmic_error: 2.1388\n",
      "Epoch 100/100\n",
      "5250/5250 [==============================] - 6s 1ms/step - loss: 32097.2441 - mean_squared_error: 32097.2441 - mean_squared_logarithmic_error: 1.8797 - val_loss: 48931.0664 - val_mean_squared_error: 48931.0664 - val_mean_squared_logarithmic_error: 2.2400\n"
     ]
    }
   ],
   "source": [
    "history_val = model_val.fit(X_test_pca, y_train, batch_size=2, epochs=100, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:55:29.141393Z",
     "start_time": "2021-05-10T23:55:29.134414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_squared_error', 'mean_squared_logarithmic_error', 'val_loss', 'val_mean_squared_error', 'val_mean_squared_logarithmic_error'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_val.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T23:57:04.810207Z",
     "start_time": "2021-05-10T23:57:04.599753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b352945280>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEAAAARACAYAAADu/yZPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xV9f3H8fe5N3uTCWSSAAkzAcKSrVZx74GrdaHWOtqqdbTV/mpbq7buarVWrSI4cYETEdkYRggrJEA22XvfcX5/hFJRRgJJbri8no9HHjfc8z3f7+cEeDySd77DME1TAAAAAAAA7szi6gIAAAAAAAB6GgEIAAAAAABwewQgAAAAAADA7RGAAAAAAAAAt0cAAgAAAAAA3B4BCAAAAAAAcHserho4PDzcTEhIcNXwAAAAAADAzaxfv77SNM2Ig11zWQCSkJCgjIwMVw0PAAAAAADcjGEY+Ye6xhIYAAAAAADg9ghAAAAAAACA2yMAAQAAAAAAbo8ABAAAAAAAuD0CEAAAAAAA4PYIQAAAAAAAgNsjAAEAAAAAAG6PAAQAAAAAALg9AhAAAAAAAOD2CEAAAAAAAIDbIwABAAAAAABujwAEAAAAAAC4PQIQAAAAAADg9ghAAAAAAACA2yMAAQAAAAAAbo8ABAAAAAAAuD0CEAAAAAAA4PYIQAAAAAAAgNsjAAEAAAAAAG6PAAQAAAAAALg9AhAAAAAAAOD2CEAAAAAAAIDbIwABAAAAAABujwAEAAAAAAC4PQIQAAAAAADg9ghAAAAAAACA2yMAAQAAAAAAbo8ABAAAAAAAuD0CEAAAAAAA4PYIQAAAAAAAgNsjAAEAAAAAAG6PAAQAAAAAALg9AhAAAAAAAOD2CEAAAAAAAIDbIwABAAAAAABujwAEAAAAAAC4PQIQAAAAAADg9ghAAAAAAACA2yMAAQAAAAAAbo8ABAAAAAAAuD0CEAAAAAAA4PaOGIAYhhFrGMZSwzC2G4ax1TCMOw7S5krDMDbv+1hlGEZqz5QLAAAAAADQdR6daGOX9GvTNDcYhhEoab1hGF+aprnte232SJphmmaNYRhnSHpR0sQeqBcAAAAAAKDLjhiAmKa5V9LefZ83GIaxXVK0pG3fa7Pqe7eskRTTzXUCAAAAAAActS7tAWIYRoKkMZLWHqbZ9ZI+PfqSjg9Op+nqEgAAAAAAQCd1ZgmMJMkwjABJ70m60zTN+kO0maWOAGTqIa7PlTRXkuLi4rpcbF9x7SvrFODjqWfmjHF1KQAAAAAAoBM6NQPEMAxPdYQf80zTfP8QbUZL+pek80zTrDpYG9M0XzRNM900zfSIiIijrdnl/L09tCG/xtVlAAAAAACATurMKTCGpJclbTdN8++HaBMn6X1JV5umubN7S+x70mJDVFzbooqGNleXAgAAAAAAOqEzS2CmSLpaUpZhGJv2vXe/pDhJMk3zBUm/lxQm6R8deYnspmmmd3+5fUNqbIgkaXNRrU4ZFuXiagAAAAAAwJF05hSYFZKMI7S5QdIN3VVUXzdiYJCsFkOZhQQgAAAAAAAcD7p0Cgw6+Hl5aGhUoDYV1bm6FAAAAAAA0AkEIEcpLTZYmYW1Mk2OwwUAAAAAoK8jADlKqTEhqmuxKb+q2dWlAAAAAACAIyAAOUr/3Qg1s6jWxZUAAAAAAIAjIQA5SkMiA+TraVVmIfuAAAAAAADQ1xGAHCUPq0Ujo4OYAQIAAAAAwHGAAOQYpMaEaEtxnWwOp6tLAQAAAAAAh0EAcgxSY0PUZncqu7TB1aUAAAAAAIDDIAA5BmlshAoAAAAAwHGBAOQYxPTzVai/lzILCUAAAAAAAOjLCECOgWEYSo0J5iQYAAAAAAD6OAKQY5QaG6Kd5Q1qbLO7uhQAAAAAAHAIBCDHKDU2RKYpbSlmFggAAAAAAH0VAcgxSo3ZtxEq+4AAAAAAANBnEYAco1B/L8WF+nESDAAAAAAAfRgBSDdIjQ1hI1QAAAAAAPowApBukBoTrOLaFpU3tLq6FAAAAAAAcBAEIN0gLbZjH5DNzAIBAAAAAKBPIgDpBiMGBstqMdgHBAAAAACAPooApBv4elmVHBWoTZwEAwAAAABAn0QA0k06NkKtlWmari4FLlRS26JtJfWuLgMAAAAA8AMEIN0kNSZY9a125VU1u7oUuEhDq02XvbhaZz+zXC99u5swDAAAAAD6EAKQbpK6byPUTJbBnLAe/GirimtaNDkpTH9avF13LNiklnaHq8sCAAAAAIgApNsMiQyQr6eVfUBOUB9lluj9DcW67eQheuP6ibr79GR9vLlEFz6/SoXVzAoCAAAAAFcjAOkmHlaLRkUHcxJMH2Gapj7cVKxnv85Ru93Zo2MV17bogYVZGhMXottOHizDMHTrrMH698/Gq7imWec8u0Ircip7tAYAAAAAwOERgHSj1NhgbS2p7/EfuHF4dS023TZ/o+5YsEmPf7FTl/5ztYpqemYWhsNp6pdvbZLTaeqpy8bIw/q//1KzkiP10S+mKjLQW9f8ey37ggAAAACACxGAdKPU2BC1253aWdbg6lJOWGt3V+nMp5br0y2luuu0oXpmzhjlljfqrKdXaMn2sm4f74Vlu7RuT7X+77yRigvz+9H1hHB/vf/zKTp9RH/2BQEAAAAAFyIA6UapMR0bobIPSO+zOZx67PMduvylNfKwGnrvlpP0i5OH6JzUgfrktqmKDvHV9a9l6C+fbpfN0T0zdDYV1uqJL3fq7NEDdOHY6EO2C/D20D+uHMu+IIfw+pp8zXlxjfZUNrm6FAAAAABuzHDVlPz09HQzIyPDJWP3FNM0lf7wVzo5JVKPXZLq6nJ6RWldq97OKFREoLeGRgUquX+gArw9erWGPZVNunPBRmUW1enS9Bg9eM4I+f+ghlabQ3/4eJvmryvQ+IR+embOWPUP9jnqMZva7Drr6eVqtzv16R3TFezn2an7lmaX6475G2WxGJqQEKpWu1NtNsf/Xm0OtdqcarV3fO5pteiScbG6bmqCYvr9eIaJq3y1rWM2zanDo466D4fT1MOLtumVlXmyWgwF+njopWvSNT4htLvKBAAAAHCCMQxjvWma6Qe9RgDSva579TsV1TTri1/O6NZ+t5bUqc3u1Ojo4AP2mXAVu8OpV1fl6Ykvd6rpB0s6Yvr5KnlfGPLfj8TwAHl5dG/dpmnqnYwiPfTxVnlaLfrLhaN05qgBh73ng43Fun9hlnw8rXrysjRNHxpxVGP/5t3Nent9oRbcOEkTE8O6dG9eZZPuX5ilqsZ2+Xha5O1plY+nVT4elo5Xz/++WrW3rlWfZu2VKens0QM0d3qiRgwM7tJ4ze12Lcuu0OrdVTp1WNRRP7MktdkdeviT7Xp9Tb4k6ZJxMXro3B8HTkfS1GbXHQs26qvt5bp+6iBdOTFON7yWoaKaFj12yWidl3boGTUAAAAAcCgEIL3oqa9y9OSSncp66PRumQmRU9agRz/P1pf7fuMe6O2hSUlhmpIUpqlDwpUUESDDMI55nK7YUFCjBxZu0fa99ZqZHKGHzhkhq8XQjtIGZZfWK7usUdml9dpd0SS7s+Pfl4fFUFRQx4wLh9OU0zTlNDtCDKdpyuE0ZZqS0zQV4uel6H6+iunnq5gQX0X381V0iJ+i+/lqYIiPvD2sqm1u1/0Ls7Q4q1STE8P098tSNSDYt1P155Y36ufz1iunvFG3zRqsO04dKqul81/DT7P26pZ5G3TrrCTdfXpK17+AXVRc26J/r9ijBesK1NTu0LQh4Zo7PVFTB4cf8u++rsWmr3eU6bMtpVq2s0KtNqesFkMOp6k5E+L0wFnDuvzvs6imWbfO26DMojrNnZ4obw+Lnluaq/gwfz11eZpG71sCdiRl9a267tXvtH1vvf5w7ghdPTlBklTT1K6bXl+vdXnVuuu0obp11uBe/7cNAAAA4PhGANKLvsku189e+U7zb5ykyUldmxnwfSW1LXryq516d32R/Lw8dPOMRA0KD9DKXZVamVup/KqOPSSigrw1ZXC4pg4O15TB4ftDhp5Q29yuv36WrQXfFSgq0EcPnjNcs0f2P+QPqe12p3ZXNiq7tEHZpQ0qrW+VxTBkMSSrxZCx7/OO9zo+JKmmuV3FNS0qqmlWaX2rnD/4JxoZ6C2bw6mGVrvuOj1ZN05L7FKAIXXMivjdB1v13oYiTU4M02/PHqZh/YNkOUI/e+taNPvJ5YoP89N7t5wkz16cjVPXbNO8dfl6ZWWeKhraNHxAkG6akagzRw2Qp9WiioY2fbmtTJ9tLdWq3ErZnaaigrw1e0R/nT6yv1JjQvT0khy9uHy3okN89fglqZrUydkrS7PL9cu3NsnhMPXYJamaPbK/pI5NZ+98a5MqGtp01+nJmjst8bBfw20l9br+te9U32LTs1eO1azkyAOut9kd+s27m/XBphJdPC5Gf75gVLfPHAIAAADgvghAelFNU7vG/PFL3XtGim6ekdTl+2ub2/X8N7v06qo8maZ09eR43TprsEL9vQ5oV1jdrBW5lVqRW6lVuZWqabZJkpIi/JUQ5q/IIG9FBPooMtC74yOo4/OIQO8u/9Bumqbe21CsvyzertoWm649KUF3/mRor+z1YXM4VVrXquLaFhXVtKi4pkXFtc1qbLPrlhmDNSqma8tBfujtjEL97oMtarM7FebvpclJYfvDpNjQA/fccDpNXfXyWm0sqNXiO6ZpULj/MY19tNrsDn2wsVj//Ha3dlc0KTrEV9Ehvvouv1qmKcWF+umMkR2hR1pMyI8CiYy8at31Tqbyqpp17ZQE3XN6iny9rAcdy+E09dRXO/XM0lyl9A/S81eOVcIPnruu2ab7Fm7W4qxSTRkcpr9fmnbQIG7pjnL94s0NCvL11Ms/Ha/hA4MOOqZpmnryqxw9tSRHkxPD9MJV4zq9xwoAAACAExsBSC+b8dhSDR8QpOevGtfpe1ptDr2yMk/Pf5Orhja7LhgTrV/9ZGinNr50Ok1t21uvlbmVWrenWiV1rapoaFVVU7t++NdrGFKon5eignw6lpj089v3uu/zUF8F+fzvh82csgY98MEWrdtTrbFxIXr4/FGH/MH1eFVe36pvczpm1qzMrVR5Q5ukjiBhyuAwTRkcrsmJYXpvQ5H+vHiH/nrRKF02Ps7FVXf8vS/ZUa5/Ld+t+la7Thsepdkj+yulf+ARl440t9v110936LXV+UoM99fjl6ZqbFy/A9pUNbbpjgWbtCK3UpeMi9Efzx8pH8+DByWmaertjEI99NE2+Xha9OjFqfrJ9zZI/c/qPD300VYNHxikl386vlMzld5bX6R739+suFA/vXrthB8FUgAAAADwQwQgvez2+RuVkVetVfedcsS2dodT720o0hNf5qi0vlUnp0TqntnJSul/7CGDzeFUVWO7yhtaVV7fprJ9r+UNbSqta1FxbYsKq1vUYjtwE9NgX0/F9PNVRKC3VuRUKsDHQ/fOTtGl6bFHXCJyvDNNU7nljVqZW6kVuVVau7tKDW12SZLFkE4b3l/PXzXWbfamWJVbqbvf3ay9dS26aUaS7jx1iLw9rFqfX61b521UTXO7/njeSF06PrZT/e2qaNTt8zdqa0m9rp4Ur3vPSNHjX2TrlZV5OnVYlJ6ekyY/r87PHFq9q0o3vZ4hT6tFL/00/UchTXcxTVPVTe3aVdGk3RWN2l35v9fBEQH6+azBSovt3B4nAAAAAFyHAKSXvbxij/74yTatu/8URR7mN91ZRXW6b+FmbSmu15i4EN07O6XLJ4ocK9M0VdNsU1FNs4r27bvR8dqx3GRMXIjuPj1ZYQHevVpXX2F3OLW5uE6rciu1p7JZvz1rmPr9YDnS8a6h1aaHP9mutzIKlRwVqNNHROkf3+xSdD9f/ePKsV0+dabN7tDfvtipF7/drQBvDzW22XX91EG6/8xhXd6rRerYtPa6V79TWX2rLhwbrTa7U81tDjW129XS7lBTu0PN7XY1tXW8ttgc8vW0KsjHU4E+Hgry3ff6gz+bZscRyrsqGrW7okl1Lbb9Y3p5WDQozF9xYX5at6dadS02TRsSrttPGdKjx/Sapql/Ld+juDA/nT6if4+NAwAAALgrApBetj6/Whc9v1ovXZN+wDKA/2pss+tvX2TrtVV5Cg/w1u/PGa6zRg1wm1kFOD4t3VGu37y3WeUNbTpteJQeuyRVwb5Hv/fG8pwK/XnxDl0xIXb/SS9Hq6qxTXe+tUlbS+rl62mVv7dVfl4e/3v1ssrP20N++44PbrE51NBqU32LXQ1t+15bbapvtau+xbb/dKLIQG8lRvgrKSJAiREBHZ+HByi6n+/+sKaxza431uTrX8t3q7KxXRMHheq2k4doyuCwbv8/O39dge57P0uS9ItZg/Wrnwx1+1lXAAAAQHciAOllLe0OjXzoc90yI0l3nZ58wLUvt5Xp9x9uUWl9q66cGKd7ZqccsOcG4Eq1ze3aVFirGUMj3DaQM01TrTannKYp/y5s5NvS7tD8dQX657e7VFbfpjFxIbrt5MGalRzZLV+rrSV1uuAfqzRxUKiiQ3y14LtCnTY8Sk9cltalOgEAAIATGQGIC5z51HKFBXjp9esnSpJK61r10Edb9dnWUiVHBerPF47SuPie2c8AQM9pszv07voiPf/NLhXVtGjEwCD9Ytbgwx4JfST1rTad88wKtdmcWnT7VIX6e+nVVXn64yfbNDQqUC9dk84msAAAAEAnHC4A6dp5qOi01NgQZRbWyu5w6rVVeTr178u0NLtc98xO1ie3TyX8AI5T3h5WXTkxXkvvmqnHLh6t5naHbpm3Qb/9YIuczq4HyqZp6jfvblZRTYueuWKMwgK8ZRiGrp0ySK9dN0EltS0677mVWru7qgeeBgAAADhxEID0kLTYYNW32nXm08v14EdbNSYuRF/8crp+PnOwPK182YHjnafVokvSY/XVr2bophmJmre2QHe/u1mOLoYgr67K06dbSnXP6ck/2mB12pAIfXDrFIX4euqql9dqwbqC7nwEAAAA4ITCwvIe8t/jOqsa2/XU5Wk6N3Wg2+6pAJzIrBZD985Okb+Xh/7+5U612R164rK0TgWdGwtq9OfF23XqsEjNnZ540DaJEQFaeOsU3TZ/o+59P0s7Shv027OGyYMgFQAAAOgSApAeMiQqUG/eOFHDBwQpxM+9jk0FcCDDMHT7KUPk42nRnxfvUJvdqWevGCNvD+sh76lpatcv3tyoqCAf/e2StMMGpMG+nvr3T9P1l0936OUVe7SrolHPzhmrYD82UAYAAAA6i18h9qCTksIJP4ATyNzpSfq/80boy21luvE/69XS7jhoO6fT1K/e3qSKhjY9d0XnggwPq0W/O3u4Hr1otNbsrtL5/1ipnLKG7n4EAAAAwG0RgABAN7pmcoIevWi0ludU6NpX16mxzf6jNi98u0tLsyv027OHKTU2pEv9Xzo+VvNvnKSGVpvOf26lPttS2l2lAwAAAG6NAAQAutml42P15GVp+i6vRte8vFZ1Lbb919bsrtLjn2frrNEDdPWk+KPqPz0hVB/fNlWDowJ18xvr9fjn2V3efBUAAAA40RCAAEAPOC8tWs9dMVZZxXW68l9rVNPUroqGNt0+f6Piw/z1yIWjjmlj5AHBvnpr7iRdmh6jZ5fm6vrXvlNds+3IN/6AaZpat6daq3IrVVTTTJACAAAAt2WYpmu+2U1PTzczMjJcMjYA9Jal2eW6+fX1SgjzV4ifpzYV1uqDW6do2ICgbunfNE3NW1ugP3y8VQNDfPXi1elK7h94xPva7A59uKlELy/fo+zv7SXiaTUU089PcaF+ig/reO343F9xoX7y9Tr0xq4AAACAqxmGsd40zfSDXiMAAYCetSq3Ujf8J0PN7Q49etFoXTo+ttvHWJ9frZvf2KCmNrseuzhVZ40ecNB2NU3tmrc2X6+tzldFQ5tS+gfqhmmJGhjso/zqZuVXNaugukkF+z5vaP3fHiYWQxoxMFiTEkM1cVCYxg8KVbAvJ9EAAACg7yAAAQAXyyqq07a9dbo0PfaYlr4cTll9q255Y702FNTq5hlJuvv0ZFktHWPlVTbp5RV79M76QrXanJoxNEI3TkvUlMFhh6zHNE3VNtuUX92sgupm5ZY1aO2eam0srFW73SnDkIYPCNKkxDBNHBSqCYNCOfkKAAAALkUAAgAniDa7Q3/4eJveXFugaUPCdcO0RM1bk68vt5fJ02LReWkDdcO0xE4tkzmUVptDmwprtWZ3ldburtaGghq17QtEUvoH6dzUgbppeqIslp4JegAAAIBDIQABgBPMgnUF+v2HW9XucCrEz1NXTYzXNSfFKzLQp9vHarM7lFlYpzW7q7Qip1Lr8qp1XtpAPXZxqrw82GsbAAAAvYcABABOQFlFddq+t15npw6Qn5dHr4xpmqaeX7ZLj36WrSmDw/TCVeMU6MM+IQAAAOgdhwtA+NUcALipUTHBunR8bK+FH5JkGIZ+PnOw/nZJqtburtal/1yjsvrWXhsfAAAAOBQCEABAt7toXIxe/tl45Vc16cJ/rFJueaOrS5KrZjwCAACgb2AJDACgx2QV1enaV9fJ7jT18k/TNS4+9Ij3mKapTYW1mre2QGv3VCkttp9mDo3Q9KERigj07tL4xbUt+npHuZbuKNeqXZUK8/dWWmyIUmODlRoTopHRwfL37r0ZMgAAAOhZ7AECAHCZgqpm/fSVdSqpbdEzc8botBH9D9qusc2uDzYWa97aAm3fWy8/L6smJYZpc1GtKhvbJUmjooM1MzlCM4ZGKC02RB7WAycyOpymNhbUaMm+0GNHaYMkKS7UT9OHhqu22abMoloVVrdIkiyGNDQqUKkxIUrdF4wMjQqUp5UJkgAAAMcjAhAAgEtVNbbputcylFVUqz+eP1JXTozff21LcZ3mrS3Qh5uK1dzu0LABQbpyYpzOSxuoQB9POZ2mtpbUa9nOcn2TXaENBTVymlKwr6emDgnXzKER8vKw6Osd5Vq2s0K1zTZ5WAylJ/TTKSlRmpUSqaQIfxmGcUA9m4vqtKmwVplFtcosrFVNs02SFB7grYU/P0mxoX69/nUCAADAsSEAAQC4XHO7Xbe9uVFLdpTr1llJigv105trC5RZVCcfT4vOGT1QV0yMU1psyAFhxQ/VNdu0IrdS32R3BB7lDW2SpDB/L81IjtApKVGaNjRcQV04fcY0TRVWt2hDQY0eWJil9IRQvXrt+MPWAQAAgL6HAAQA0CfYHU799oMtWvBdoSRpaFSArpgQpwvGxijYt+vH5Zqmqe17G9TucGpUdLCslmMPLF5duUcPfbxNT12epvPSoo+5PwAAAPQeAhAAQJ9hmqY+yizRwBBfpcf363OzLBxOUxc+v0pF1c1a8usZCvHzcnVJAAAA6KTDBSDs8gYA6FWGYei8tGiNTwjtc+GHJFkthh65cJTqWmz606Ltri4HAAAA3YQABACAHxg2IEg3Tk/UO+uLtCq30tXlAAAAoBsQgAAAcBB3nDJE8WF+un9hllptDleXAwAAgGNEAAIAwEH4eFr15wtGKa+qWc9+nevqcgAAAHCMCEAAADiEKYPDddHYGL2wbJeySxtcXQ4AAACOAQEIAACH8cBZwxTk66l7398sp9M1J6cBAADg2BGAAABwGKH+Xvrd2cO0saBW89bmu7ocAAAAHCUCEAAAjuD8tGhNGxKuv36WrdK6VleXAwAAgKNAAAIAwBEYhqE/nT9KdqdTD360pVP3OJ2mcssbtaO0XnmVTSqta1VNU7ta2h0spQEAAHABD1cXAADA8SAuzE93njpUj3y6Q59tKdXskf0PuG6apnLKG7V6V5VW76rS2j1Vqmm2HbI/L6tF3p4W+XhaNSjMXy9cPU6h/l7HVGNlY5se/HCrbpmZpJHRwcfUFwAAgLshAAEAoJOunzpIH24q0YMfbdFJg8NU0dDWEXjsrtLa3VWqbGyXJEWH+OqUYVGaMChUAd4earU51Gpzqs1+4GvH+w69t6FI972/WS9cNU6GYRxVbaZp6jfvbtaSHeXKr27Sh7dOldVydH0BAAC4IwIQAAA6ydNq0SMXjtIF/1ipSX9eouZ2hySpf5CPpg2J0OTEME1OClNsqF+X+k2KCNCfFm/Xgu8KNWdC3FHV9vqafC3ZUa5ZyRFaml2hdzIKdflR9gUAAOCOCEAAAOiC1NgQPXDWcGUW1mrSvsAjIczvqGduSB0zS77ZWa7/+3ibJgwKVVJEQJfu31nWoD8t2q6ZyRF6+afjddmLq/Xo59k6Y9QABft6HnVdAAAA7oRNUAEA6KLrpw7S03PG6IqJcRoU7n9M4YckWSyG/nZJmrw9LbpzwSa1252dvrfV5tDt8zcq0MdDj12cKovF0IPnjFBNc7ue+irnmOoCAABwJwQgAAD0Af2DffTIhaOVVVynJ77a2en7Hvl0h3aUNuixi1MVEegtSRoZHaw5E+L02uo85ZQ19FDFAAAAxxcCEAAA+ojZI/trzoRYvbBsl1bvqjpi+6XZ5Xp1VZ5+dlKCZqVEHnDtrtOS5e9l1R8+3ibT5NhdAAAAAhAAAPqQ3509XIPC/PWrtzep7jDH6FY0tOnudzKVHBWoe89I+dH1UH8v/eonQ7Uit1JfbCvryZIBAACOCwQgAAD0IX5eHnry8jRVNLTp/oVZB529YZqm7nk3U/Wtdj09Z4x8PK0H7euqSfEaGhWghxdtU6vN0dOlAwAA9GkEIAAA9DGjY0L0q9OGalHWXr27vuhH119blael2RV64MxhSu4feMh+PKwWPXjOCBVWt+hfy3f3ZMkAAAB9HgEIAAB90E3TkzRxUKge+mir8iqb9r+/o7Ref/50h05OidQ1k+OP2M+UweGaPaK/nlu6S3vrWnqyZAAAgD6NAAQAgD7IajH0xGVpsloM3fnWJtkczv1H3gb5eOrRi0d3+vjdB84aJqdp6i+Ld/Rw1QAAAH0XAQgAAH3UwBBf/eXC0dpUWKtnluToL4u3a2dZox6/ZLTCA7w73U9sqJ9ump6ojzJLtG5PdQ9WDAAA0HcRgAAA0IedNXqALh4Xo2eW5uq11fm6bsogzUyOPPKNP3DLzMEaGOyjBz/aKv2QLREAACAASURBVIezc8ficnwuAABwJwQgAAD0cQ+dO0IJYf4aMTBI98xOPqo+fL2suu/MYdq+t14Lvis4ZLuy+la9/V2hbnljvVL/8IWufnntYY/jBQAAOF4YrvrtTnp6upmRkeGSsQEAON60tDtksUjeHgc/8rYzTNPUZS+uUU5Zg765a5aC/Txldzi1oaBW32SXa2l2hbbvrZck9Q/y0YRBofpsS6niwvz02nUTFB3i212PAwAA0CMMw1hvmmb6Qa8RgAAAcOLYVlKvs59ZrlnJkfLxtOrbnAo1tNpltRhKj++nmcmRmpUSoeSoQBmGodW7qjT39Qz5elr16rUTNHxgkKsfAQAA4JAIQAAAwH6/+2CLXl+Tr6ggb80cGqmZyRGaMiRcQT6eB22fXdqgn72yTg2tdr1w1ThNHRLeyxUDAAB0DgEIAADYz+ZwqrC6WYPC/Tt9lO7euhZd+8p3yi1v1KMXj9aFY2N6uEoAAICuO1wAwiaoAACcYDytFiVGBHQ6/JCkAcG+evvmyRqfEKpfvZ2p55bmdumUmKrGNpXUthxNuQAAAN3Cw9UFAACA40OQj6devW687n5nsx77PFt761r0h3NHymr5cZDicJraVFirZdnlWrazQpuL62QxDN13RoqunzqoS+ELAABAdyAAAQAAnebtYdWTl6VpQIiP/rlst0rr2vTMnDHy9bKqoqFN3+6s0Dc7K7Q8p0K1zTZZDGlMXD/98tSh2lpSp4cXbVdmUZ3+etEo+XnxbQgAAOg9fOcBAAC6xGIxdN8ZwzQw2FcPfbxVF/xjpTyshrYUdxyhGx7grVNSojQzOULThoQrxM9LUscxvM8v26XHP8/WztIG/fPqcUoI93flowAAgBMIm6ACAICj9tmWUj340RbFhfppZnKkZgyN0PABQbIcZFnMf327s0K3L9goh9PUU5en6eSUqF6sGAAAuDNOgQEAAH1KYXWzbn5jvbbtrdedpwzVbScPPmxoAgAA0BmcAgMAAPqU2FA/vXfLSbogLVpPfLVTN/4nQ3UtNleXBQAA3BgBCAAAcAkfT6v+dmmq/u+8EVq2s0LnP7dS2aUNri4LAAC4KQIQAADgMoZh6JrJCVowd5Ia2+w6/7mV+nBTsavLAgAAbogABAAAuFx6QqgW3TZVIwYG6Y4Fm3Tve5vV0u5wdVkAAMCNEIAAAIA+ITLIR/PnTtLPZybprYxCnffcCu0sY0kMAADoHgQgAACgz/C0WnTP7BS9du0EVTe169xnV2jBugK56tQ6AADgPghAAABAnzN9aIQW3zFN4+L76d73s3T7gk1qaOWUGAAAcPQ8XF0AAADAwUQG+ug/103U89/k6u9f7tTmolo9O2esRsUEH/Ke5na71ufXaPWuKq3ZXaVWm1MXjYvRxWNjFOzn2YvVAwCAvsZw1ZTS9PR0MyMjwyVjAwCA48t3edW6ff5GVTa26b4zhunaKQkyDEMt7Q6tz6/Rmt1VWr27SpmFtbI7TVkthkbHBMs0pU2FtfLxtOic0QN11aR4pcaGdHrcdrtT6/ZUa8mOMmWXNuiGaYN0ckpUDz4pAAA4FoZhrDdNM/2g1whAAADA8aCmqV13v5upr7aXa3JimOxOpzYV1srm6Ag8RkUHa1JimCYnhSk9vp/8vTsmum4tqdMbawr04aZiNbc7NCo6WFdNitO5qdHy9bL+aJyKhjYtzS7X19vLtTynQk3tDnl7WBTm76WSulZdPC5Gvzt7uIJ9mVECAEBfQwACAADcgmma+vfKPD29JEcJYX6alBSmSYlhGp8QqgDvw6/srW+16YONxXpjTb52ljUq0MdDF42N0VWT4tRqc+rrHeVasqNcmYW1kqT+QT46eVikTkmJ1ElJ4bJYpGeW5Or5ZbsUEeCtRy4apZnJkb3x2AAAoJMIQAAAAPYxTVPr9lTrjbUF+mzLXtkcHd8LGYaUGhOiU1IidfKwSA0fECTDMH50f2Zhre56J1M55Y26LD1WD5w9TEE+zAYBAKAvIAABAAA4iIqGNn2cWaIAHw/NSo5URKB3p+5rtTn01JIc/XPZLkUF+eivF43W9KERPVwtAAA4EgIQAACAHrCxoEZ3vZOpXRVNmjMhVvefOUyBzAYBAMBlDheAWHq7GAAAAHcxJq6fFt0+TTdNT9Rb3xVq9pPLtSKn0tVlAQCAgyAAAQAAOAY+nlbdd+YwvXPzSfL2sOiql9fqgYVZamyzu7o0AADwPQQgAAAA3WBcfD8tvmOabpw2SG+uK9DsJ7/Vql3MBgEAoK8gAAEAAOgmPp5WPXDWcL1z02R5WAxd8dJa/f7DLWpiNggAAC5HAAIAANDN0hNC9ekd03XdlEF6fU2+Zj/1rdbsrnJ1WQAAnNCOeAqMYRixkv4jqb8kp6QXTdN86gdtDElPSTpTUrOkn5mmueFw/XIKDAAAOBGs21Otu9/NVH5Vs352UoLumZ0sPy+Pg7ataGjT5qJaZRbVaXNRrfbWtur0kf11xYQ49Q/26eXKAQA4/hzTMbiGYQyQNMA0zQ2GYQRKWi/pfNM0t32vzZmSblNHADJR0lOmaU48XL8EIAAA4ETR3G7Xo59l69VVeYoP89NjF6cqZUCgsorqlFlUq82FHYFHSV2rJMliSEMiAxXi56l1edWyGIZOGx6lqyfHa3JimDp+9wQAAH7omAKQg3T2oaRnTdP88nvv/VPSN6Zpzt/352xJM03T3HuofghAAADAiWb1rird816mCqtbDng/PsxPo2NClBoTrNExIRoxMEj+3h2zRPKrmvTm2gK9lVGo2mabkiL8dfWkeF04LkZBPp6ueAwAAPqsbgtADMNIkPStpJGmadZ/7/1PJD1imuaKfX9eIuk3pmlm/OD+uZLmSlJcXNy4/Pz8rj0JAADAca6pza5/r9gjw5BGx4RodEywQvy8jnhfq82hTzbv1etr8pVZWCs/L6vOHxOtqyfFa9iAIJmmqeZ2h+pabKpttqm2pV11zTbV7vtzQ6tNo2NCNCslQt4e1l54UgAAel+3BCCGYQRIWibpT6Zpvv+Da4sk/eUHAcg9pmmuP1R/zAABAAA4OpuLavX66nx9lFmiNrtTof5eami1yeY49Pd1hiGZphTs66mzRw/QhWOjNTauH8tpAABu5XAByMF34PpxB56S3pM074fhxz5FkmK/9+cYSSVdLRQAAABHNjomRI9dEqIHzhqmd9cXaVdFk0L8PBXs66kQX899n3spxM9z//teVotW5FZq4cZivbehSPPWFig+zE/np0XrgjHRSgj3d/VjAQDQozqzCaoh6TVJ1aZp3nmINmdJ+oX+twnq06ZpTjhcv8wAAQAAcI3GNrs+21KqhRuLtGpXlUxTGhsXogvGxujsUQPUz//IS3IAAOiLjvUUmKmSlkvKUscxuJJ0v6Q4STJN84V9Icmzkmar4xjca3+4/8cPEYAAAAC43t66Fn2wsUQLNxZpZ1nj/hNoUmODlRobotSYECX3D5Sn1dLtYze22fXMkhytyK3U03PGKCkioNvHAACcWLr1FJjuQgACAADQd5imqa0l9fpyW5kyi2qVWVirmmabJMnbw6IRA4OUGhuitNgQjY4JUUKY31HvH2Kapj7ZvFd/WrRdpfWt8veyKtDHU+/cPFmxoX7d+VgAgBMMAQgAAAC6xDRNFVa3aFNRrTYX1iqzqFZZxXVqtXVMCI4O8dXl42N12fhYRQb5dLrf3PIG/f7DrVq1q0ojBgbpj+ePlK+nVXNeWqMAbw+9fdNkDQzx7anHAgC4OQIQAAAAHDO7w6mdZY3aVFirRVklWplbJQ+LoVOHRenKSXGakhQui+Xgs0Ka2ux6+uscvbx8j/y8rLp7doqumBAn6772m4tqdeVLaxUe6K23bpqkyMDOhyoAAPwXAQgAAAC63Z7KJs1fV6B3MgpV02xTXKif5kyI0yXpMQoP8JbUMZNkUdZePfxJx3KXS9Nj9JvZKQrbd/371udX6+qX1ymmn68WzJ2sUDZjBQB0EQEIAAAAekyb3aHPtpRq3toCrdtTLU+rodNG9NdZowZo3tp8rcztWO7yf+eN1Lj4fofta9WuSl37yndKigjQ/BsnKdjPs5eeAgDgDghAAAAA0Ctyyxv05tpCvbu+UPWtdgX5eOju05N1xcT4/ctdjuSb7HLN/c96DR8YpDdumKgAb48j3tNmd+iLrWX6anuZZgyN0Plp0YdcjgMAcF8EIAAAAOhVrTaH1uyu0sjo4P3LYbrii62lumXeBo2L66fXrpsgXy/rQdvtrmjUgu8K9e76IlU3tcvPy6rmdodGDAzS/WcO05TB4cf6KACA4wgBCAAAAI47H2eW6I4FG3VSUrj+9dN0+Xh2hCCtNoc+31qq+esKtGZ3tawWQz8ZFqU5E+M0JSlMi7L26tHPslVc26JZyRG678xhGhoV6OKnAQD0BgIQAAAAHJfeXV+ku97J1MkpkbpndrLezSjSexuKVNNsU2yory4fH6dLxsX86CjeVptDr63K07NLc9XUZtdl42P1y1OHdunIXgDA8YcABAAAAMetN9bk67cfbJEkeVgMnTYiSnMmHP7Y3f+qaWrX01/n6PXV+fLysGju9ETNnZ4oP68j7ysCADj+EIAAAADguLZwY5HK69t04dgYRQR2fU+RvMomPfr5Di3OKlVEoLfuPi1Zl6THyDDYKBUA3AkBCAAAACBpfX61/rRouzYU1OqMkf3114tHK8iHo3YBwF0cLgCx9HYxAAAAgKuMiw/Ve7ecpPvPTNEX28p0zjMrtKW4ztVlAQB6AQEIAAAATiiGYWju9CS9NXeS2mxOXfj8Kr25tkCumhkNAOgdBCAAAAA4IaUnhGrR7VM1cVCo7l+YpV++tUlNbXZXlwUA6CEEIAAAADhhhQV467VrJ+jXPxmqjzJLdO6zK7SzrMHVZQEAegABCAAAAE5oFouh204Zojeun6i6FrvOe3al3ltf5OqyAADdjAAEAAAAkHTS4HAtvn2qRscE69fvZOo3725Wq83h6rIAAN2EAAQAAADYJzLIR/NumKhfzBqstzIKdf5zK7W7otHVZQEAugEBCAAAAPA9HlaL7jo9Wa9cO15l9a0655kV+jiz5Kj7szmcemHZLt02f6MyC2u7sVIAQFcYrjruKz093czIyHDJ2AAAAEBnlNS26Lb5G7U+v0ZXT4rXb88eJm8Pa6fvX59frfvf36Lssgb5eVnV3O7Q+WkDdffsFEWH+PZg5Z3XbnfKw2LIYjFcXQoAHDPDMNabppl+0GsEIAAAAMCh2RxOPfZ5tl78drdGRQfruSvGKi7M77D31DXb9MhnOzR/XYEGBvvoD+eN1KTEUL2wbJf+tXyPJOn6qYN0y8wkBfp49sZjHMDucGp5TqXe31isL7eV6vy0aD1y0eherwMAuhsBCAAAAHCMvthaqrveyZQp6bGLUzV7ZP8ftTFNUx9lluiPn2xTTbNN156UoF/+ZKj8vT32tymubdHjn2dr4cZihQd46c5Th+ry8bHysPbs6nTTNJVVXKf3NxTrk80lqmxsV4ifpwaF+2tjQa3evmmyJgwK7dEaAKCnEYAAAAAA3aCwulm/eHODMovqdP3UQfrN7BR5eXQEF3mVTfrtB1u0IrdSqbEh+vMFIzViYPAh+8osrNWfFm3XurxqDYkM0P1nDtPM5AgZRvcuRSmqadaHm0r0/oYi7apokpfVolOGReqCMdGamRwpu9OpU/+2TEG+nvrktqk9HsQAQE8iAAEAAAC6SZvdob8s3qFXV+UpLTZET16Wpo8zS/TM0lx5Wy26e3ayrpwYL2sn9tQwTVOfby3VI5/uUF5Vs6YODteVE+M0KMJfcaF+8vPyOGIf39dudyqvqkk5ZY3KLW/Uyl2VWrenWpI0ISFUF4yN1pkjByjY78BlN59t2aub39ig3509XNdPHdSlMQGgLyEAAQAAALrZos179Zv3NquxzS5JOmv0AP3+7OGKCvLpcl/tdqdeX5Ovp5fkqK7Ftv/9qCBvxYf5KyHMb9+rv+LD/DQg2EfFtS3KLW884CO/ulkOZ8f394YhDY4I0LmpA3X+mGjFhh563xLTNPWzV77T+vwaLfn1jKN6BgDoCwhAAAAAgB6QV9mkp5fk6JzUgZqVEnnM/TW327WrvEl5VU3Kr2pSXlXz/teKhraD3uNhMZQQ7q8hkQEavO8jKaLjw9er8yfW5FU26bQnvtUZo/rrqcvHHPOzAIArEIAAAAAAx7mmNrvy9wUie+taNTDEV4MjAxQf5ifPbtq34+9fZOvpr3P15o0TdVJSeLf0ebSWbC/Tyyv26LFLUvvMkcEA+j4CEAAAAABH1Gpz6NS/L5OPp1Wf3jGt24KVrjBNUy+v2KM/Ld4u05QuGBOtJy5L6/U6AByfDheAsMUzAAAAAEmSj6dVD50zQrnljfr3ij29Pn673an73s/Sw4u2a/aI/vrZSQn6YFOxtpbU9XotANwPAQgAAACA/U4dHqVTh0XqqSU52lvX0mvj1ja365p/r9WC7wr1i1mD9dwVY/XLU4cqyMdTj3y6o9fqAOC+CEAAAAAAHODBc0bI4TT18Cfbe2W8XRWNOv+5ldqQX6snLkvVXacny2IxFOznqdtOHqzlOZVanlPRK7UAcF8EIAAAAAAOEBvqp1tnDdairL36dmfPBg8rcip1wXMr1dBq1/y5E3XBmJgDrl89OV7RIb565NMdcjpds38hAPdAAAIAAADgR+ZOT1RCmJ8e+mir2uyOTt2TX9WkVbsqVVbfqs4ctvDGmnz99JV16h/sow9unaJx8aE/auPtYdVdpw/V1pJ6fZRZ0uXnAID/8nB1AQAAAAD6Hh9Pqx46d4R+9sp3+tfyPbp11uCDtsurbNKirL1anLVXW0vq978f6OOhwZEBGhIZsO81UIMjAxQd4iunaerhRdv16qo8zUqO0NNzxijQx/OQtZyXGq2Xvt2jx7/I1hmj+svbw9rtzwvA/RGAAAAAADiomcmRmj2iv575OkfnpQ1UTD8/SdKeyiYtztqrRZv3atvejtBjTFyIfnvWMCX3D9SeyibllDUqt7xRX++o0NsZRfv79PG0KNTPSyV1rbpuyiA9cNYwWS3GYeuwWAzdd2aKrn55nV5fna8bpiX23EMDcFtGZ6am9YT09HQzIyPDJWMDAAAA6Jzi2had+rdlmpgYqvT4flqUVart+0KPsXEhOnPUAJ0xaoCiQ3wP2Udtc7tyyzsCkZzyRuVXNem0Ef11aXpsl2q5+uW1yiqu07K7ZynY99AzRgCcuAzDWG+aZvpBrxGAAAAAADicf3yTq0c/y5b0v9DjzFEDNPAwoUdP2FJcp7OfWaGbZyTp3jNSenVsAMeHwwUgLIEBAAAAcFhzpyUqMdxfo2NCej30+L6R0cG6YEy0Xlm5R9dMju90LTllDXrk0x0K8PHQySmRmjk0UsF+zCABTjQEIAAAAAAOy8Nq0eyRA1xdhiTpVz8ZqkWb9+qJL3fqsUtSD9vW6TT12uo8PfLpDvl6WWU1DH24qURWi6Fx8f10SkqkThkWqaSIABnGofchqW+1KauoTpsKa7W5qFaZhXUK9PHQzTOSdF7aQHlYOVwTOB6wBAYAAADAceXhT7bp3yv3aPEd05TSP+igbfbWtejudzZrRW6lTk6J1F8vGq0wfy9lFtVqyfZyLdlRvn8vk7hQP528LwxJiw1RbnmjNhfVKbOwVpuKarW7oml/v4PC/TU6Jlg7yxq1fW+94kL99ItZg3XB2Gh5EoQALsceIAAAAADcRk1Tu6Y/tlTp8f30yrUTfnT948wSPbAwSzaHqd+dPVxzJsQedIZHSW2Lvt5Rrq93lGtlbqXa7M4DrkcEeis1JkRpscFKjQ3R6OiQ/UtnTNPUV9vL9fSSHGUV1yk6xFc/n5Wki8fFcEwv4EIEIAAAAADcygvLdumRT3do/o2TNDkpTJJU12LT7z/cog83lSgtNkRPXJamQeH+neqvpd2hVbsqtbWkXkOjApQaG6L+QT6HXRojdQQh3+ys0FNf5WhTYa0GBPvolplJujQ9Vj6e3ReE7CxrkNViKCkioNv6BNwRAQgAAAAAt9Jqc2jW498oMtBbH9w6Rat3VenX72SqvKFNd5wyRD+fmdSre3OYpqkVuZV6ekmOvsurUWSgt26akaQrJsTJ1+vog5Cy+lY99nm23ttQpABvD71/y0kaEhXYjZUD7oUABAAAAIDbeSejUHe/u1kzhkZo2c4KJYb764nL0pQaG+KymkzT1Jrd1Xp6SY5W765SiJ+nrp4Ur2smJygi0LvT/bTaHHrp2916ftku2RxOXTUpXp9s3isvq0ULbz1JkYE+PfgUwPGLAAQAAACA23E4TZ319HLtKG3QNZPjdd8Zw45ptkV3y8ir1ovf7taX28vkabXowjHRumHaIA2OPPQMDtM09VFmif766Q6V1LVq9oj+uu/MFMWH+WtLcZ0u/edqJUUEaMHcSfL3PvpDPU3TPOLyHuB4RAACAAAAwC0V17aooqFNaS6c9XEkeyqb9PKK3Xono0htdqdOTonUjdMSNSkx9IAQYkNBjf74yTZtLKjViIFB+t3ZwzUpMeyAvpZsL9ON/8nQrORIvXhNuqyWroUYrTaH7l+YpcVZe3X6iP66ZnKCxsaFdDkMMU1TmUV1en11vj7fWqqHzh2hi8fFdKkPoCcQgAAAAACAi1U1tumNNQX6z+o8VTW1a1R0sG6cnqgxsSF6/ItsfbipRBGB3rr79GRdNDbmkOHG62vy9bsPtuiayfH6w7kjOh1elNS26KbX1yuruE6nDY/S6l1Vamiza8TAIF0zOV7npkYfcQZNS7tDH2eW6PU1+coqrpO/l1WRQT4qqW3R+z8/SSMGBnf1ywJ0KwIQAAAAAOgjWm0OLdxYrJeW79buiiZJkreHRTdOS9QtM5M6tbTlL4u365/f7tYDZw7TjdMTj9h+3Z5q/XzeerXanHrysjSdOjxKTW12LdxYrNdX5yu7rEHBvp66ND1GV02KV3zYgafn7K5o1Ly1BXono1D1rXYNjQrQ1ZPidf6YaLXZnTrr6eXy+X/27jxcz7q+8/jnl5yEnAMh5EAMAQIJCoisQsCVCNUqFre2WEFQ22Jp3WprFzvTjk6rM9c1Yzt1rIKiw1A3tCytC7YuRYWqqEGBgCggawiYkI0l+zn3/HECg0pywjnPyf08v/N6XVeu23DuPM83Xv7D2+/9u6dNzRfe9vzsOWPa2P6LgQ4QQAAAALrM8HCTK3+8ItcvW5szTjww++/V/6T+7Nsu/mGuWHpfzjvruPzaUfO2e+8nr7kr//XzN2X+4EA++vrjf+kMkqZp8t07VucT37kr/3bT/Rlumpx86Jy8/jkLsnloOJ+85q5cfesD6ZtS8tKj5uXsZx2YExf+/OM7379zdc644Jr86uFzc/7ZxzlfhNYIIAAAAJXZuGUoZ33su1l677pc/HvPyvEHDf7czzdvHc67P39TLv7e3Tn5sDn532c8M7P6d7ydcf+6jfn09+7Oxd+7Oysf2pQk2W/WjLz2WQfmt06Yv8O3z3z0qtvz3750c/7qtMPzxpNG30qBiSCAAAAAVGj1I5vzm+d/O2vXb84/v/l5WbDPyKMrKx/alDd98tosuWtN3nTyU/OnLz7sSR2YunnrcK788cjba15w6Jz0TZ0y6p9pmia//4lrc+WPV+Qz5z47ixYMjvpnoNMEEAAAgErd+cAj+fXzvpVZ/dNy+Zufl2Vr1ufcj1+btRs2532nH5OXH7PfLptl3YYtefk//Ec2bx3OFX/4/Oy9x2677Lsh2XEAGT3jAQAA0LUW7LN7PvaGRVm+bmNe85Hv5PQPfydTp5Rc9qbn7tL4kSSz+qflvLOOy+r1m/NHn70uQ8Pt/B/u8EQEEAAAgB53/EGDef9rjs1tKx/OcQfulc+/9XmtvZL2yP1n5W9ecUSuvvWBfODfb31Sf3bT1qFsGRqeoMmY7EZ/vxIAAABd79eOmper//yU7LvnjJ06s2MiveaE+fn+nWvygStvzXEHzc4LDp2z3XubpsmSu9bkn75/T65Yel+mlpIXHDYnLzp8bk4+bE72Gpi+CyenZs4AAQAAoOM2bB7Kqz70rax4aGOu+MOTst8vvOZ3xYMbc+kPluWSJctyxwOPZPfpU/Oyo/dLKcnXbl6RBx7elKlTSk5YMDsvOnxuXnT43McOeYXtcQgqAAAAu9xPVz6cV/zDf+TQfWfms+c+J0ly5Y9X5JIl9+Qbt6zM0HCTExcM5tWLDshpR8/LwPSRhxSGh5tcv2xt/v3mFfnazT/Lj+9/KEnytKfskRcdPje/8vSn5KC9BzJ7YHqm9znZgf9PAAEAAKAVX7xhed766R/mxAWD+enKh7Pqkc15yszdcvrxB+T04w/IwXP2GPUz7lm9Pl+7+Wf52s0/y3dvX52tjztcdeZufRncY3pmD0zP3rtPz+Djfh0+b88s3sHjN9RHAAEAAKA17/nij/KP374zLzp8bl5zwvycdMg+Yz6nZN2GLfnu7auy4qFNWf3I5u3+2rztMNWzn31g3vWyI8a1KbJxy1C+8ZMVOWK/WZk/ODDmz2HiCSAAAAC0pmmabNo6nBnTpu6y73t409Z88Mrb8pGrbs+ig2bnvLOPy1NmznjSn3XjvevyR5+9LreteDhJcswBs3La0fPy0iPniSFdSAABAABgUvr89cvz55den1n903L+2cfnuANn79Sf2zo0nI9cdXv+/qu3ZO89puddLzsi965dnytuuC/XL1uXJDlm/l552VHz8tKj9s0Bs8WQbiCAAAAAMGn9aPmD+f1PLsn96zbmb155ZM488cAd3n/Xqkfyx5+9Lj+4e21edvS8vPdVR/7c63jvWb0+Vyy9L1fccF+W3jsSQ46dv1dOO2peXnbMvMyb1b+9j2aCCSAAAABMamvXb87bLv5hrr71nKi+NAAAIABJREFUgZx54oH5r694Rnbr+/lHcpqmyWe+f0/e88UfZeqUkve+6si88tj9d/i5d6/aFkOWLs+N9z6Y6X1T8vYXHpLfO+lgb6hpgQACAADApDc03OTvvvKTnPeNn+aZB+6VD599fObuOXIuyMqHNuUvLrsh//7jFXne0/bO+04/Jvvt9eQ2Oe544JG878s/zpeW3p/D5s7Mf/+No3L8QTv3yA2dIYAAAADANl9ael/+9JLrs/tufTn/rOOy6pHN+c+XL81Dm7bmL059en77uQsyZUoZ8+d/9Uc/y7s+d2Puf3BjXvfsg/JnLzksM2dM6+DfgO0RQAAAAOBxfnL/Qzn3E0uybM2GDA03OWK/PfP+1xybQ+bO7MjnP7xpa/72yz/JP37nzsydOSN//coj8pIj9u3IZ7N9AggAAAD8gnXrt+Svv3BTDhgcyFtPedqEnNlx3T1r8xeX3ZAf3/9QXnLE3Pz1K47MvrOe/Ot42TkCCAAAALRky9BwPnb1HXn/127JtKlT8s5TD8tZzzpoXI/ZTITbVjycj3/nzvzVac/o2QNcdxRAevNvBAAAAD1i2tQpedPJT81X/nhxjp2/V/7L527K6y78blY/srnt0ZKMvPb3Hf90XV7899/Mpdcuy03L17U90oSwAQIAAAC7yKOv2n3352/KnD12y4fPPj5HHTCrlVnuXbshH7zy1lyyZFmmTil5/XMOyu+/4KnZZ4/dWpmnE3a0AdK3q4cBAACAyaqUkjNPPDDPmLdn3vTJa/ObH/52/turjsyrF83fZTOseHBjPvT123Lx9+5JkyZnPevAvPmUpz32SuBaCSAAAACwix0zf6984W3Pz9su/mH+7NIbcv2ytXnXy46Y0LM3Vj28KR+56vb847fvzNbhJr+16IC89VcOyf579U/Yd3YTAQQAAABasPceu+Xjv3ti3vfln+QjV92eHy1/MOefffxObWI0TZPrl63LFTcsz60rHk7flJKpU0r6pkzZdt32+6kj181bh/PFG+7Lxi1DedUz98/bX3hIDtp7913wt+wezgABAACAll1xw335s0uvz8D0vpx31nE5ceHgL93TNE1uWv5gvnDD8lxxw31ZtmZDpk0tOXTuzDRNMjTcZOvwcIabZOvwcIaGmmwdbjI03GSoafL8p+2TP3rRoXnaU/Zo4W+4azgDBAAAALrYaUfPyyFz98jvf+LavPaj1+SvTjs8b3jugiTJzfc9lCuWjkSPO1etT9+Ukuc9bZ+8/YWH5MXP2DezBqa1O3yPsAECAAAAXeLBjVvyjs9en6/d/LMsPnROlq1Zn9tXPpKpU0qe+9S9c9pR8/KSI/bN7N2ntz1qV7IBAgAAAD1gzxnTcsHrjs+Hvn5bzv/mT3PMAXvlnOcvzKlH7Ju9e/j1tN3ABggAAAB0oaZpUkppe4yesqMNkIl7vw4AAAAwZuJHZwkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUL1RA0gp5cJSyopSyo3b+fmsUsoXSinXl1JuKqX8TufHBAAAABi7ndkAuSjJqTv4+VuS/KhpmmOSnJzk70op08c/GgAAAEBnjBpAmqa5KsnqHd2SZGYppSTZY9u9WzszHgAAAMD4deIMkA8mOTzJ8iRLk7y9aZrhJ7qxlHJuKWVJKWXJypUrO/DVAAAAAKPrRAB5SZLrkuyX5NgkHyyl7PlENzZNc0HTNIuaplk0Z86cDnw1AAAAwOg6EUB+J8nlzYjbktyR5Okd+FwAAACAjuhEALk7yQuTpJQyN8lhSW7vwOcCAAAAdETfaDeUUi7OyNtd9imlLEvy7iTTkqRpmg8neU+Si0opS5OUJO9smuaBCZsYAAAA4EkaNYA0TXPmKD9fnuTFHZsIAAAAoMM68QgMAAAAQFcTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1Rs1gJRSLiylrCil3LiDe04upVxXSrmplPLNzo4IAAAAMD47swFyUZJTt/fDUspeSc5L8oqmaY5I8urOjAYAAADQGaMGkKZprkqyege3vDbJ5U3T3L3t/hUdmg0AAACgIzpxBsihSWaXUr5RSrm2lPL6DnwmAAAAQMf0degzjk/ywiT9Sb5TSrmmaZpbfvHGUsq5Sc5NkgMPPLADXw0AAAAwuk5sgCxL8m9N0zzSNM0DSa5KcswT3dg0zQVN0yxqmmbRnDlzOvDVAAAAAKPrRAD5XJKTSil9pZSBJM9KcnMHPhcAAACgI0Z9BKaUcnGSk5PsU0pZluTdSaYlSdM0H26a5uZSyr8luSHJcJKPNU2z3VfmAgAAAOxqowaQpmnO3Il73pfkfR2ZCAAAAKDDOvEIDAAAAEBXE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqjRpASikXllJWlFJuHOW+E0opQ6WU0zs3HgAAAMD47cwGyEVJTt3RDaWUqUn+R5Ivd2AmAAAAgI4aNYA0TXNVktWj3Pa2JJclWdGJoQAAAAA6adxngJRS9k/y60k+PP5xAAAAADqvE4egvj/JO5umGRrtxlLKuaWUJaWUJStXruzAVwMAAACMrq8Dn7EoyWdKKUmyT5JfK6VsbZrmX37xxqZpLkhyQZIsWrSo6cB3AwAAAIxq3AGkaZqFj/7nUspFSb74RPEDAAAAoC2jBpBSysVJTk6yTyllWZJ3J5mWJE3TOPcDAAAA6HqjBpCmac7c2Q9rmua3xzUNAAAAwAToxCGoAAAAAF1NAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QQQAAAAoHoCCAAAAFA9AQQAAACongACAAAAVE8AAQAAAKongAAAAADVE0AAAACA6gkgAAAAQPUEEAAAAKB6AggAAABQPQEEAAAAqJ4AAgAAAFRPAAEAAACqJ4AAAAAA1RNAAAAAgOoJIAAAAED1BBAAAACgegIIAAAAUD0BBAAAAKieAAIAAABUTwABAAAAqieAAAAAANUTQAAAAIDqCSAAAABA9QSQsXjo/mTdsranAAAAAHaSADIWF5+RfOHtbU8BAAAA7CQBZCz6B5P1q9ueAgAAANhJAshYDAwmGwQQAAAA6BUCyFj0Dybr17Q9BQAAALCTBJCxGBhMNq1Lhra2PQkAAACwEwSQsegfHLlusAUCAAAAvUAAGYuBRwOIc0AAAACgFwggY9E/e+TqTTAAAADQEwSQsbABAgAAAD1FABkLGyAAAADQUwSQsXAIKgAAAPQUAWQsdpuZTOnzCAwAAAD0CAFkLEoZ2QLxCAwAAAD0BAFkrAYGbYAAAABAjxBAxqp/MFnvDBAAAADoBQLIWNkAAQAAgJ4hgIxV/2xngAAAAECPEEDG6tENkKZpexIAAABgFALIWPUPJkObk82PtD0JAAAAMAoBZKwGBkeuzgEBAACArieAjFX/tgDiHBAAAADoegLIWNkAAQAAgJ4hgIyVDRAAAADoGQLIWD22AbKm3TkAAACAUQkgY9U/e+RqAwQAAAC6ngAyVlOnJdNnOgMEAAAAeoAAMh4Dsz0CAwAAAD1AABmP/kGPwAAAAEAPGDWAlFIuLKWsKKXcuJ2fn1VKuWHbr2+XUo7p/JhdamDQIzAAAADQA3ZmA+SiJKfu4Od3JHlB0zRHJ3lPkgs6MFdvsAECAAAAPaFvtBuaprmqlLJgBz//9uN+e02SA8Y/Vo+wAQIAAAA9odNngJyT5F+398NSyrmllCWllCUrV67s8Fe3oH8w2bguGdra9iQAAADADnQsgJRSTslIAHnn9u5pmuaCpmkWNU2zaM6cOZ366vYMDI5cN65tdw4AAABghzoSQEopRyf5WJJXNk2zqhOf2RP6twUQ54AAAABAVxt3ACmlHJjk8iSva5rmlvGP1EMGZo9cnQMCAAAAXW3UQ1BLKRcnOTnJPqWUZUnenWRakjRN8+Ek70qyd5LzSilJsrVpmkUTNXBXsQECAAAAPWFn3gJz5ig/f2OSN3Zsol7y6BkgNkAAAACgq3X6LTCTiw0QAAAA6AkCyHjsNjOZ0mcDBAAAALqcADIepYxsgdgAAQAAgK4mgIzXwKANEAAAAOhyAsh49c9O1q9pewoAAABgBwSQ8eofTDYIIAAAANDNBJDxGpjtERgAAADocgLIeD16CGrTtD0JAAAAsB0CyHgNDCZDm5It69ueBAAAANgOAWS8+gdHrl6FCwAAAF1LABmvgW0BxDkgAAAA0LUEkPGyAQIAAABdTwAZLxsgAAAA0PUEkPGyAQIAAABdTwAZr/7ZI9cNa9qdAwAAANguAWS8+qYn02faAAEAAIAuJoB0wsBsZ4AAAABAFxNAOqF/0AYIAAAAdDEBpBMGBm2AAAAAQBcTQDrBBggAAAB0NQGkE/qdAQIAAADdTADphIHBZOO6ZGhr25MAAAAAT0AA6YT+wZHrxnXtzgEAAAA8IQGkEwa2BRCPwQAAAEBXEkA64dENEAehAgAAQFcSQDphYPbI1QYIAAAAdCUBpBNsgAAAAEBXE0A6wRkgAAAA0NUEkE7Ybc9kSp8NEAAAAOhSAkgnlJL0z7YBAgAAAF1KAOmU/kEbIAAAANClBJBOGRhMNqxpewoAAADgCQggnWIDBAAAALqWANIpA84AAQAAgG4lgHTKoxsgTdP2JAAAAMAvEEA6pX92MrQp2bK+7UkAAACAXyCAdMrA4MjVOSAAAADQdQSQTunfFkCcAwIAAABdRwDplEc3QLwKFwAAALqOANIp/R6BAQAAgG4lgHTKgEdgAAAAoFsJIJ3y2AaIR2AAAACg2wggndI3PZm+hw0QAAAA6EICSCf1DzoDBAAAALqQANJJA7NtgAAAAEAXEkA6yQYIAAAAdCUBpJMGBm2AAAAAQBcSQDrJBggAAAB0JQGkkwYGk43rkuGhticBAAAAHkcA6aT+wSRNsmFt25MAAAAAjyOAdNLA4MjVOSAAAADQVQSQTuqfPXJ1DggAAAB0FQGkk/ptgAAAAEA3EkA6acAGCAAAAHQjAaSTHtsAWdPuHAAAAMDPEUA6acaspEz1CAwAAAB0GQGkk0oZOQjVIzAAAADQVQSQThsYtAECAAAAXUYA6bT+QRsgAAAA0GUEkE4bGHQIKgAAAHQZAaTTbIAAAABA1xFAOm1gtjNAAAAAoMsIIJ3WP5hs3ZhsXt/2JAAAAMA2AkinDQyOXG2BAAAAQNcQQDqtf1sAcQ4IAAAAdA0BpNNsgAAAAEDXEUA6zQYIAAAAdB0BpNP6Z49cbYAAAABA1xBAOu3RR2DWr2l3DgAAAOAxAkin9e2WTNvdBggAAAB0EQFkIgwMOgMEAAAAuogAMhH6ZycbPAIDAAAA3UIAmQgDgx6BAQAAgC4igEyEfo/AAAAAQDcRQCaCDRAAAADoKgLIROgfTDasTYaH2p4EAAAAiAAyMQYGkzTJxnVtTwIAAABEAJkY/YMjV+eAAAAAQFcQQCbCwLYA4hwQAAAA6AoCyESwAQIAAABdRQCZCAOzR642QAAAAKArCCATwQYIAAAAdBUBZCLMmJWUqTZAAAAAoEsIIBOhlKR/LxsgAAAA0CUEkInSP2gDBAAAALqEADJRBgZtgAAAAECXEEAmSv9gsmFN21MAAAAAEUAmzoAAAgAAAN1CAJko/bM9AgMAAABdQgCZKAODydYNyZYNbU8CAAAAk54AMlH6B0eutkAAAACgdQLIRBnYFkC8ChcAAABaJ4BMFBsgAAAA0DUEkIliAwQAAAC6hgAyUWbNT8qUZMXNbU8CAAAAk54AMlFm7JnMOza546q2JwEAAIBJTwCZSAsXJ8u+n2x+pO1JAAAAYFITQCbSwS9Ihrcmd3+n7UkAAABgUhNAJtL8ZydTpnkMBgAAAFomgEyk6QPJ/BMFEAAAAGiZADLRFi5Oll+XbFjT9iQAAAAwaQkgE23h4iRNcue32p4EAAAAJi0BZKLtvyjp6/cYDAAAALRIAJlofdOTg54jgAAAAECLBJBdYeHiZOXNycMr2p4EAAAAJiUBZFdYuHjkagsEAAAAWiGA7Arzjk12myWAAAAAQEsEkF1hytRkwfMFEAAAAGiJALKrLFycrLkjWXt325MAAADApCOA7CrOAQEAAIDWCCC7ylMOTwb2EUAAAACgBQLIrlLKyBbIHVclTdP2NAAAADCpCCC70sLFyUP3Jatua3sSAAAAmFRGDSCllAtLKStKKTdu5+ellPKBUsptpZQbSinHdX7MSjx2Dsg3250DAAAAJpmd2QC5KMmpO/j5S5Mcsu3XuUnOH/9YlRo8ONnzAOeAAAAAwC42agBpmuaqJKt3cMsrk3y8GXFNkr1KKfM6NWBVSkkOfkFyx9XJ8HDb0wAAAMCk0YkzQPZPcs/jfr9s2z/jiSxcnGxYnfzsCZ8oAgAAACZAJwJIeYJ/9oSvOSmlnFtKWVJKWbJy5coOfHUPWnDSyNVjMAAAALDLdCKALEsy/3G/PyDJ8ie6sWmaC5qmWdQ0zaI5c+Z04Kt70Kz9k72fJoAAAADALtSJAPL5JK/f9jaYZydZ1zTNfR343HotXJzc9a1kaEvbkwAAAMCksDOvwb04yXeSHFZKWVZKOaeU8gellD/YdsuXktye5LYkH03y5gmbthYLFyebH06WX9f2JAAAADAp9I12Q9M0Z47y8ybJWzo20WTw2Dkg30zmn9DuLAAAADAJdOIRGJ6s3fdJ5h7pHBAAAADYRQSQtixcnNzz3WTLxrYnAQAAgOoJIG1Z+IJk68Zk2ffangQAAACqJ4C05aDnJmWqx2AAAABgFxBA2jJjz2S/ZwogAAAAsAsIIG1auDi599pk00NtTwIAAABVE0DatHBxMrw1ufuaticBAACAqgkgbZr/rGTq9OSOb7Y9CQAAAFRNAGnT9IHkgBOT2wUQAAAAmEgCSNueekpy/w3JLV9pexIAAAColgDStme/OZl7VHLZG5NVP217GgAAAKiSANK26QPJGZ9MpkxJPnOWN8IAAADABBBAusHsBcnp/zd54CfJv7w5aZq2JwIAAICqCCDd4qmnJL/6N8nNn0+u/ru2pwEAAICqCCDd5DlvTY48PbnyvcmtX217GgAAAKiGANJNSkle8Q/J3COTy85xKCoAAAB0iADSbR49FLU4FBUAAAA6RQDpRg5FBQAAgI4SQLrV4w9F/Y//1fY0AAAA0NMEkG72nLcmR706+ff3OBQVAAAAxkEA6WalJC//gENRAQAAYJwEkG43fSA541Mjh6Je8Y62pwEAAICeJID0gtkHJc95S3L7N5IHbmt7GgAAAOg5AkiveObrkyl9yZIL254EAAAAeo4A0itmzk0Of3ly3aeSzevbngYAAAB6igDSS054Y7JxbXLT5W1PAgAAAD1FAOklBz0vmfP05Pv/p+1JAAAAoKcIIL2klGTR7ybLf5Dc+4O2pwEAAICeIYD0mmPOSKYNJEtsgQAAAMDOEkB6zYxZyVGvTpZelmxY0/Y0AAAA0BMEkF50whuTrRuS6z/T9iQAAADQEwSQXjTv6OSAE0YOQ22atqcBAACArieA9KpF5ySrbk3uuKrtSQAAAKDrCSC96ohfT/pnOwwVAAAAdoIA0qumzUieeXZy8xeTB+9rexoAAADoagJIL1v0u0kzlPzg421PAgAAAF1NAOllgwcnT31hcu1FydDWtqcBAACAriWA9LoTzkkeWp7c8q9tTwIAAABdSwDpdYe8JNnzgJFX4gIAAABPSADpdVP7kuN/O7n968mqn7Y9DQAAAHQlAaQGx70+mdKXLLmw7UkAAACgKwkgNZg5Nzn85ckPP5ls2dD2NAAAANB1BJBaLDon2bg2ufHyticBAACAriOA1GLB85N9DkuWOAwVAAAAfpEAUotSRl6Je++1yZ3fansaAAAA6CoCSE2OOTPZ66Dkkt9O1t7d9jQAAADQNQSQmszYMznrkmRoU/Kp30o2rmt7IgAAAOgKAkht5hyWvOaTyapbk396QzK0pe2JAAAAoHUCSI0WLk5e/oHk9q8nV/xJ0jRtTwQAAACt6mt7ACbIM89KVt+eXP23yd5PTZ739rYnAgAAgNYIIDU75S+TNXckX31XMntB8oxXtj0RAAAAtMIjMDWbMiV55XnJ/Gcll5+bLFvS9kQAAADQCgGkdtNmJGd8Opm5b3LxGcmau9qeCAAAAHY5AWQy2H2noamzAAAgAElEQVSf5LWXJEObk0//VrJhbdsTAQAAwC4lgEwWcw5NXvOpZNVPk0u8HhcAAIDJRQCZTBaelLziA8nt30g+95Zk00NtTwQAAAC7hAAy2Rz72uTk/5zc8Nnkfx+TfPuDyZaNbU8FAAAAE0oAmYxOfmfye19P5h2TfOUvk384Lrn2omRoa9uTAQAAwIQQQCar/Y9LXvfPyRu+mOy5X/KFtycfOjFZemkyPNz2dAAAANBRAshkt/Ck5JyvJmd+JumbkVx2TvKRxcktX06apu3pAAAAoCMEEJJSksNemvzBfyS/8bFk88Mjr8u98NTk/qVtTwcAAADjJoDw/02Zkhz96uSt309e9vfJ6tuTT706eWRV25MBAADAuAgg/LKp05JFv5ucfWmyflXyL2/yOAwAAAA9TQBh++Ydk7z4vcmtX06uOb/taQAAAGDMBBB27MRzk8N+Lfnqu5LlP2x7GgAAABgTAYQdKyV55YeSPZ6SXPI7ycYH254IAAAAnjQBhNENDCa/+bFk7V3JFe9wHggAAAA9RwBh5xz03OTk/5QsvSS57tNtTwMAAABPigDCzjvpT5IFJyVf+tNk5S1tTwMAAAA7TQBh502ZmvzGR5Np/cmlv5Ns2dj2RAAAALBTBBCenD3nJa86P/nZjclX/qrtaQAAAGCnCCA8eYe+JHnOW5PvfzS5+QttTwMAAACjEkAYmxe+O5l3bPK5tyRr7257GgAAANghAYSx6ZuevPr/JsPDyWVvTIa2tj0RAAAAbJcAwtgNHpy8/P3JPd91HggAAABdra/tAehxR52e3Httcs15ydxnJMe9vu2JAAAA4JfYAGH8fvU9ycGnJF98R3L3NW1PAwAAAL9EAGH8pvaNnAey1/zks2cna+9peyIAAAD4OQIIndE/OznzM8nWTclnXptsXt/2RAAAAPAYAYTOmXNY8pv/J7l/afK5NydN0/ZEAAAAkEQAodMOfXHyq3+d3PTPydV/2/Y0AAAAkMRbYJgIz/3D5Gc3JVe+N3nKM5Knn9b2RAAAAExyNkDovFKSl38g2f/45PJzR2IIAAAAtEgAYWJMm5G85lPJ9D2Si89MHlnV9kQAAABMYgIIE2fPeckZn0oeuj+55A3J0Ja2JwIAAGCSEkCYWAcsSl7xgeTOq5N/eXOy7t62JwIAAGAScggqE++YM5JVP02u+p/JjZcmh7w4Oe4NI9ep/icIAADAxPNvn+wav/KXybGvTX74ieSHn0pu+bdk5rzk2LOS416XzF7Q9oQAAABUrDRN08oXL1q0qFmyZEkr303LhrYmt345ufYfk9u+mjTDycGnJMe/ITnstKRvetsTAgAA0INKKdc2TbPo/7V35+FVVff+x98rAxAI8zyDCAjiAKIoirMgatU6j7VWbbWD2l7b297ee2vr7a+jtXqrdbpahyqOVZyqOCOOIDIIosyEeQoQCCQk+/fHCg0zSUg4ycn79Tz72efsc87e66TZ1nxc6/vd2WvOANG+l5kFB5wetzV5MPFR+PQReOqb0Lg1DLsJhlwLGZaokSRJkiRVD//CVGo17wLH/xRunAyXPg0dD4FXfwaPnA1rF6V6dJIkSZKkNGEAotohIxN6nwKXPQtfux3yPoG7joLPn0v1yCRJkiRJacAARLVLCHDYN+Ha96DVfvDUFbF97qZ1qR6ZJEmSJKkOMwBR7dS6F1z1Ghz7Y5j0ONx9DMz/KNWjkiRJkiTVUQYgqr0ys+HE/4Rvvhw7xTx4Krz1/2IXGUmSJEmSKsEARLVf96PikpiDL4R3fgcPjICVs1I9KkmSJElSHWIbXNUNjZrD1++G3sPhxRvhriOhRXdo2gFy20Fu+622dmXH20NOK9vpSpIkSZIMQFTHDDgHug6BD++CNXlQsAwWTYz7ooId39+ie+wq0+uEfT9WSZIkSVKtYQCiuqd5Zxjx6x2PbyqAgqUxDClYCuuWwCf3wSNnw2FXwvBboGHTfT9eSZIkSVLKGYAofTTMjVvrXuXHDrsC3vo1vP8XmPk6nPm/zgaRJEmSpHrI4ghKb9k5MPx/YkvdrEZxNsgLN8LGtakemSRJkiRpHzIAUf3Q9Qi4diwM/QF8+hD8dSjMeivVo5IkSZIk7SMGIKo/tswG+darW80GucHZIJIkSZJUDxiAqP7512yQ6+HTh+NskA/vhuUzIElSPTpJkiRJUg2wCKrqp+yc2BWm35nw4o3wz3+Px3M7wH7Hl23HQbNOqRujJEmSJKnaGICofut6OFw3DlbPhdnvwOy3YeYYmDwqvt6mT3kg0uMYaNQ8VSOVJEmSJO2FkKRoyv/gwYOT8ePHp+Ta0m6VlsLSqTCnLBCZ9z4Ub4DMBnDkd+HYm6Bh01SPUpIkSZK0nRDChCRJBu/0NQMQaQ82b4K8T2DiozDp8bhM5uSb4eALIcMyOpIkSZJUW+wuAPGvN2lPshrG5S9fvxuufiPWBXnuWnhgOCyckOrRSZIkSZIqwABEqowug2MIctZdsHoe3HcSPP89KFiW6pFJkiRJknbDAESqrIwMGHgp/GACDP0+TBoF/3sYvP8X2FyU6tFJkiRJknbCAESqqkbNYPj/wHc/hK5D4LWfw1+Hwqy3Uj0ySZIkSdJ2DECkvdWmN1z2NFzyJCQl8MjZ8PKPobgw1SOTJEmSJJUxAJGqS58RcN0HsVXux/fCPcfB4kmpHpUkSZIkiQoGICGEU0MIM0IIM0MIP93J681DCC+EECaFED4PIVxZ/UOV6oDsRnDqb+Dyf8CmtbFI6nu3QWlJqkcmSZIkSfXaHgOQEEImcCcwEugPXBxC6L/d274HTEuS5BDgeODWEEKDah6rVHf0OhGuex/6joTXb4aHzoT8BakelSRJkiTVWxWZAXIEMDNJktlJkhQBo4CztntPAjQNIQQgF1gFbK7WkUp1TeNWcMHDcPZfYfFn8NejYfJTqR6VJEmSJNVLFQlAOgNb/6frvLJjW/sL0A9YBEwBbkiSpLRaRijVZSHAoZfAte9BuwPg2avh6augMD/VI5MkSZKkeqUiAUjYybFku+cjgM+ATsChwF9CCM12OFEI3w4hjA8hjF++fHmlByvVWa16wjdfhhP/E6Y9F2eDfHAnLJkCpWaFkiRJklTTsirwnjyg61bPuxBnemztSuC3SZIkwMwQwhzgAODjrd+UJMm9wL0AgwcP3j5EkdJbZhYc++NYH2T0DfDqf8TjOa2g5zDoeSz0PA5a7x9njkiSJEmSqk1FApBPgN4hhJ7AQuAi4JLt3jMfOAkYG0JoD/QFZlfnQKW00fkwuO49WJMHc8bCnHdhzjsw7fn4etOOMQzpMQz2Ox5adN3d2SRJkiRJFbDHACRJks0hhO8DrwKZwANJknweQri27PW7gVuAv4UQphCXzPx7kiQranDcUt3XvAscenHckgRWzS4LQ96FmW/A5CeAAAecDsN+FIMTSZIkSVKVhLhqZd8bPHhwMn78+JRcW6r1kgSWTYfPn4WP74WNa+JskGN+FGeHuERGkiRJknYQQpiQJMngnb1WkSKokva1EKB9/1g09capcMqvYiDy8Jlw/0nwxUsWT5UkSZKkSjAAkWq7Rs3g6Bvghslw+p9g/QoYdQn89SiYNApKilM9QkmSJEmq9QxApLoiuxEcfhX84FM4534IGfCP78D/DoLJT6Z6dJIkSZJUqxmASHVNZhYcfD5cOw4uHgWN28Cz18Abv4q1QyRJkiRJOzAAkeqqjAzoOxKuGgODroCxt8Kz34bNm1I9MkmSJEmqdfbYBldSLZeZBV+7HVp2j7NA1i2GCx+FnBapHpkkSZIk1RrOAJHSQQgw7N/gnPtg/ofwwAjIX5DqUUmSJElSrWEAIqWTgy+Ay5+FtYvh/pNh8aRUj0iSJEmSagUDECnd9DwWrnoVMrPhgZHw1ZhUj0iSJEmSUs4AREpH7frB1a9D617w2IUw4W+pHpEkSZIkpZQBiJSumnaAK1+BXifCCzfAG7dAwXIozIei9VBSbNtcSZIkSfWGXWCkdNYwFy4eBS/9CMb+MW7by8iOy2UysyGzATRqAX1GwIHnQOdBscCqJEmSJNVxBiBSutvSJrfvSFiTF2d+lBRBaXH545KtHq9ZAB/dAx/8BZp3gwPPjlunCoYhG9fAos9g4QRY/gX0OgkGnBvHIUmSJEkpEpIUTYEfPHhwMn78+JRcW9IeFK6GL16Gz/8Bs9+C0s3Qohsc+HXofzZ0GhjDkM1FsHRqDDsWfhr3K74Eyv65ktMynqtVLzj2x3DQ+QYhkiRJkmpMCGFCkiSDd/qaAYik3dqwCmZsCUPeLgtDukOTNrBkSpw1AtCkLXQ+rGwbFGeMNGoBX7wI7/welk6Blj3h2Jvg4AvjkhtJkiRJqkYGIJKqx4ZV8MVLMO15KN4Qg44toUfzrrteIpMkMUR553eweFIMUI69CQ652CBEkiRJUrUxAJFUOyQJfPkqvPNbWDQx1hgZ9iM49FLIapDq0UmSJEmq4wxAJNUuSQIzX4e3fwsLx0PjNtD1iFhbpNNA6Hgo5LZN9SglSZIk1TG7C0CsRihp3wsBep8C+58Ms96EyU/EGSEzXuFfBVSbd4WOh5SHIp0GQuNWKR22JEmSpLrLAERS6oQA+58UN4CNa2HJ5NhGd9HEuH3xYvn7ux0FJ/03dB+amvFKkiRJqrMMQCTVHo2aQY9j4rZFYX4snJr3CXxyPzw4EnoPhxP/CzoeXLXrbFwDm9ZB8y7VM25JkiRJtV5GqgcgSbuV0wL2Oy52jbl+IpzyK1jwMdwzDJ6+ClbOqth5ijfCtNHwxOXwh95w2wB4/WbYXLR341s9N54nf/7enUeSJElSjbIIqqS6pzAf3r8DPvwrlBTBoG/AsT+BZh23fV9pCcx5F6Y8DdNHw6a10KQdDDgXitbBxEdjnZFz7oe2fSo3htIS+OhuePN/Ykvgpp3gsmegff/q+56SJEmSKsUuMJLS07ol8O4fYMLfICMbhnwHjr4BVs2BKU/B1Gdg/TJo2Az6nQkHnQc9hkFm2eq/6S/C6B9AcSGM+DUM/lasS7InS6bGzy36NC7HOeI7MPr7MQi5+AnoflSNfm1JkiRJO2cAIim9rZoNb/0mhh4hA5ISyGwIfYbDQedD7xGQ3Wjnn123BJ77Lsx6A/qcCmf+ZdcteIs3xsBl3J+hUQsY+bs4myQEWD0PHj0H1uTB+X+DviNr7OtKkiRJ2jkDEEn1w5KpMPER6HAQHHBGrB9SEaWl8PG9MOa/YyHWs+6EPiO2fc/ccfDC9bByJhxySZwxsn1b3vUr4O/nx6KtZ94BAy+rnu8lSZIkqUIMQCSpIpZOg2evgaVTYfBVMPx/oLQYxvwCJjwILbrD1/4MvU7c9Tk2FcCTl8OsN+GkX8AxP6zYspot1i6CovWQ0xIaNYfM7L3/XpIkSVI9sbsAxDa4krRF+/5wzZvwxq/gg7/EAqpFBVCwFI76PpzwH9Cgye7P0TA31gF57jp445ewfjkM/zVk7KbpVsEy+PwfsVhr3sfbvtagaQxDclqUbS3jlts+zjBp0W3vv7ckSZJUDxiASNLWshrG5S29T4F/XAeN28BFj0HnQZU4RwM45z5o0hY+vCuGIGfdFY9vUZgP01+AqU/HoCUphXYHwon/FWeaFK6O28b88seF+bDsi/h4w0p478+x8OuwH8VQRJIkSdIuuQRGknalpBgysiq3hGVrSQLv3RZngvQ6Cb5+D8x9F6Y8AzPHxBa+LXvAgPNih5p2/Sp+7jV58OavYdLjcanMsT+GI66JAU5FrZoTWwFPHw09j4URv9k2pJEkSZLqGGuASFIqTXwURl8fu9MANO0IB54TO8h0HlT1gAVgyZRYo2TWG3E5zEm/iOfe1ZKb4kKYNjoWi507NnbN6TQIFo6H7sfAhY/sWNxVkiRJqiMMQCQp1Wa9GbfeI6D7UMjIrP7zj/nvGIh0PBSG3xJndUCcibJoYgxipjwNm9bEmScDL4sdbZp3hslPwfPfg2ad4JInoG3f6h2fJEmStA8YgEhSfVBaClOehDdugbV50Ht4DEEmjYqdbbIaQf+zYvDR/ZgdZ4ks+ARGXQKbN8L5D8L+J6fme0iSJElVZAAiSfVJ8Ub4+B5499Y426PjoTDo8lhrJKfF7j+bvwAevwiWTYNTfwtHfHvvluhIkiRJ+5ABiCTVR4X5sVtM616V+9ymAnj2GpjxMgy+Ckb+DjKza2aMu7N6Hiz/Is5kMYSRJElSBewuALENriSlq5wWe57xsTMNc+HCR2P3mnG3w8qZcMFD+6bV7vIvY1ea6aNh8aR4bOj1saaJJEmStBcMQCRJO8rIhFN+BW36wgs3wP0nwyVPVn42yZ4kCSyZHDvTTH8BVsyIx7scHq+/cha8fwc0aQNH31C915YkSVK9YgAiSdq1gZdCq54w6lK47wQYch0cfhXktqv6OZME8j6Bac/HmR758yFkQo+j4Yhr4IDTYzcaiIVdN62LHW4at4njkSRJkqrAGiCSpD1bNQde+Xf46lXIbBALqh55LXQ8pOLnyF8QO9JMegxWzY7n2e8E6H8m9BkJTVrv/HObi+CxC2DOu3DR36HvyOr5TpIkSUo7FkGVJFWPFTPho7vhs8egeD10PxqOvA76nhaXzWyvaH1c2vLZ32HOWCCBHsPg0EvggDOgUbOKXXfTOnjozNid5vLnoPtRFR9zksDkJ+D1X8KAc+LSmp2NVZIkSXWeAYgkqXoV5sPER+Cje2HNfGjRDYZcCwMvgwZNYf778NnjMO05KCqAlj3g0Evh4AuhZfeqXXP9CnjgVChYBle+DB0G7Pkzq+fCCzfC7LfiGPPnx+DlnPugQeOqjUOSJEm1lgGIJKlmlGyGGS/Bh3fH0KNBLuS0iqFIg6Zw4Nkx+Oh2ZPW0ss2fD/83ApJSuOrVGKzsalwf3Q1v/RpCBpx8c2zp+/E98M+fQefD4OJRkNt278ckSZKkWsMARJJU8xZ9Bh/dAxtWwkHnxZkWNTHLYtn0OBOkcSv41ms7hhhLpsDoH8CiidDnVDj9Vmjepfz16S/AM1dD0w5w6TPQZv/qH6MkSZJSwgBEkpReFnwca4K07QNXvBhriRQXwju/g3F3xHBk5O/gwHN2PvMkbzw8diEkJXDR45WrKSJJkqRaa3cBSMa+HowkSXut6xFw4SOw9HMYdQnMfB3+OhTeuw0OuRi+9zEMOHfXy266DIarx0Dj1vDwWTD1mX07fkmSJO1zBiCSpLqp9ylw1l0wdyw8em6sC3L5c3D2nXEGyJ602g+uGgOdB8HT34L3/hw7xkiSJCktZaV6AJIkVdkhF8bgI38eDL2+8jVHGreKoclz18Lrv4jnGfkHyCz7v8ckid1n1syHNXlbbQvi7JEB58VWwBk19N8TSktjF51N6+K+SduKhTv7UpLAii+hde+a+zlIkiRVAwMQSVLddujFe/f57EZw7gOxTe6422HxZGjQpDzsKNm03fubxKKqaxfChL9Bs85xuc3BF1asNe8WxYWQ9wnMHQdLp8KmtTHo2LRV4FFUsO1nQgZ0Hgy9h8cZMB0OTm3osHoevHwTfPVaWXvhe+PPTpIkqRayCKokSVuMf6CsiGpraNE1Bh3Nu5ZtXeKW0zLWFinaAF++ApOfjDVISjdDu/5w0Plxa9F123MXrY/FW+eNi6HHwvFQUhRDjda948yOBrnQMBcaNo1thBs23ep5Lqz4KoYNiz6N52zSLgYh+58MvU6EnBb75udUUgwf3gVv/QYyMqH/2TDpsRjIXDwKmnXcN+OQJEnajl1gJEmqSetXwrR/xDBkwUfxWLehcODZsG5JDD0WToghSciEjodAj6OhxzDodiQ0al656xUsh1lvxDBk5huwMT+et+sQ2P/EOCslu3GcjZHdOC4Nym5Sti/bshruukjs7uSNhxduiLNW+p4Op/0+BkMz/hlrqeS0gEuegA4HVf7ckiRJe8kARJKkfWX1XJjyVAxDVnwJGVnQaWCsFdLjmBhSNGpWfdcr2RzDla9ei9uSyRX7XMNmsN/x5ctpmnbY/fs3roE3boFP7oemHeG0P0C/M7Z9z+LJ8PhF8b3nPQB9RlTlG0mSJFWZAYgkSftaksCq2ZDbPi5j2VcKV0NhPhRviMt0itfHeiNF67c9tnoufPU6rFsUP9fxkLIwZDh0PiwubdnyPaaPhlf+Pc5mGfIdOOHnuw5x1i6OIciSyTDiN/H9VZlpIkmSVAUGIJIkaUdJAks/h69eha/GxOU7SSnktIL9T4p1RaY9D1/+My5p+drtMRzZk6L18Oy34YsX4fBr4NTflnfW2d1YVs6Eee/HJTy9TigPYSRJkirIAESSJO3ZhlUw+y348jWYOQY2rIz1Qk74OQy5ds8hxtZKS2Nr4ffviEVaz3tw21kjSQKr58CcsTB3LMx9D9YtLn+9WWc49BIYeBm07FG171OwHEqLoVmnqn1ekiTVOQYgkiSpckpL4zKWph32XB9kdyb8DV76N2jTB752R6yLMndsDD7W5sX3NGkHPYfForDdj4bl0+HTR2Kh16QUeh4Hg74RW+1mN9r1tQrz4wySOe/AnHdh2bRYg+XoG+G4n8TCr5IkKa0ZgEiSpNSZ9RY8eQVsWhOfN24dC8L2GAY9j43hyM7qhKzJg88eg4mPQP58aNQCDr4QBl0el+QUbYAFH8awY867sGhiDEyycmJ3nZ7HxsBl0uPQpi+cdSd0Pbxmv+vmovhdMrNr9jqSJGmnDEAkSVJqrZwVl7l0GQxt+0FGRsU/W1oKc9+FTx+G6S9ASRG02i8GJCVFcZZHl8Nj4NHz2Ph469keX42BF26EtQvhyOvgxP+MLYKrYuMayF8Qr71mQQxm/vV4ARQsja2Ah90Eh1+9+xkrkiSp2hmASJKk9LBhVWwz/NUYaHcA9Dw+zvbYU6edTevg9ZtjG9+WPeJynP2O2/P1CvPjtWa8BLPfjl12tpbZINYradEVmneD5l0g75O4fKd511g/5eALLOgqSdI+YgAiSZIEMHccjP4BrJoFg66A4bdAo+bbvid/Acx4JYYec9+D0s2xTknv4dC2Tww5mneLoUeTdjufzTL7bRjzC1j8GbQ7EE6+GXqfYktgSZJqmAGIJEnSFsWF8PZv4P3/hdwOcMafYqjxxcuxde+SyfF9bfpA39PggNOh8+DKLduBuHRn2nPwxq9ix5vux8Apv4zLgPZW0Ya4pGfL0puSImjSFnLbQ267uN/TrBhJktKQAYgkSdL2Fn4Kz38fln1ediBA1yPKQ482vavnOpuL4NOH4J3fwfrl0O9MOOm/y89fWgrFG+JWVBDDjaL1ULweNq4tCzrytqo3kgcbVuz5utmNy8OQLfsB50L3odXzvSRJqoUMQCRJknZmc1HsMpOZDX1OjUFBTdlUAB/cCe/fEWeh5LQsDz72JLtJWZ2RLltt3cofZzWC9cugYMu2NIYtBUvLj63Jg6J1MYA55VfQqmfNfVdJklLEAESSJKm2KFgOH90NhaviLI0GudCg8baPGzSJoUfD3FhkNafl3tcPKdoAH/wF3rst1jUZci0ce9OONVAkSarDDEAkSZIUrV0Mb94Cn/0dGreBE38OA78BmVmpHpkkSXttdwFIJat5SZIkqU5r1hHOvgu+/XYs9PriD+GeYTDrzVSPTJKkGmUAIkmSVB91GghXvgwXPByLrj7ydfj7BbD8y1SPTJKkGmEAIkmSVF+FAP3Pgu99DCf/Eua9D3cNgccuhBn/hNKSqp03SWDBx/D272DRxOodsyRJVWQNEEmSJEUFy+HDu2Dio7GrTLPOMOgbMPByaN55z59fOg2mPAVTn4H8efFYRhYc/zM45oeQkVmz45ck1XsWQZUkSVLFlRTDjJdhwt9ibZCQEdsEH/ZN2P/kbYOM1XNj4DHlaVg2DUIm7Hc8HHQ+9DgaxvwCPn8Wug2Fc+6BFt2qb5xJApvWwrqlULAk7jfmQ7+vQdMO1XcdSVKdYQAiSZKkqlk1Bz59eKtZIV3irJCcFjH0yPs4vq/rkXDQedD/bMhtW/75JIHJT8BLN8UlN6ffCgdfULkxbCqA6aNh0WflQceW/ebCHd+f0xJO/xMMOKfq31uSVCcZgEiSJGnvbC4qnxUy+614rP2AGHoMOHfPMztWz4VnvwMLPoQB58UgJKfFrt+fJLBwQgxfpj4DRQXQoGmc2dG0A+S23+pxB2jaPu43b4QXboBFn8ZZKKf9IQYi6aK0FL58Jf5v0e9M6D08BkuSJMAARJIkSdVp9TwoKYI2vSv3uZLN8N5t8PZvoFkn+Prd0OOYbd+zfmWcMfLpw7B8OmQ3hgPPibNOuh5RsT/2S4ph7K3wzu9jUHL2XdDrhMqNtbYpWg+fPRZrtKyaDZkN4v8G3YbCKb+MPxtJkgGIJEmSapG8CfDs1XF5zTE3wnE/hXnjYugx4+X4h33nwTDo8hh+NGpWtessnBBnnaz8Co74Dpx8MzRovHdjT5IYQCyaCAs/jfsVM6DjIdBnJPQ9tXrrnKxdDJ/cB+MfgMLV0PkwOOr70HdkXJb0zu/j0qQDzoCTfgFt+1TftSWpDjIAkSRJUu2yqQBe/VkMPbJyYi2PnJZwyMWx60z7/tVznaIN8PrN8PE90KYPfP0e6DyoYp9NEli7sDzoWFS237gmvp7VCDocFM+74OMYtEBcGtTn1BhSdBoEGRmVH/eSKfDBnbHOSulm6HdGDD66Dtl2FsymgjgrZNwdULweBl4Wu+4061T5a0pSGjAAkSRJUu00/UWY/gL0GQEHnA5ZDWvmOrPehOe+F2dLHPsTGPZvkJkFhfmQPx/WLIj7f23z4n5L2JGRBe36Q6eBMUDpNAja9YPM7PJrrJwFM16J2/wPICmBJu3id+s7MhaKLd0MxRtirZLiwh33RQUw9VmY8w5kN4mBxpHXQqv9dv/91q+Ad/8In8mzMfQAABFfSURBVNwfu/QMuTbOrkmn+ieSVAEGIJIkSVLh6tiNZurT0LRjnB2yac2278luHJewbNna9IlhR4cBkJ1T8WttWAUz34hLema+seN1dqdpRxjyndh2uLIBxuq58Nb/g8lPQqPmMQjZ7/gY3GQ3qty5JKkOMgCRJEmStpj6LHz+bAwaWnSD5l3LAo/u0LhV9XdVKSmGee/D0qlxhktWTgxTsnPiMprt9806bTuzpCqWTIHXfwkzx8TnmQ1iCNLtyDgTpesQaNJ677+bJNUyBiCSJElSfbR+BSz4KC7Jmf9RrGFSWhxfa9OnPBBp3jku88nILttnxhAmI6t8CyEuCSpcHWe4FK6GwrL9htXlz0uK4+yTnBbQqEX5fptjLeOynoa5qf35SEo7BiCSJEmSYp2RRRNh/odxW/ARbMzfu3Nm5cRAo3GruM/IikHJxvyywCQ/1kPZXsiA9gfG2ShdjoCuh0PLntU/AwdiN52Jj8aOQt2HQrsDq1acVlKtt7sAJGtfD0aSJElSimTnxACg+9D4vLQ0dq/ZsDIWaC0phtKSOEukdHPZsbJ9Ulo2i2OrsCOn5Z5royRJLO5amB9DkcL8OFNkyVTI+xgmjYrFWwGatC0PQ7ocEZft7E3r4tVzYdztMfwoKSo/3qg5dBsKPY6OP4sOh8SiuBVRshnWL4cGTareonmbMc6DZdNi56CaCH8k/YsBiCRJklRfZWRA2741e40QoGHTuNG1/Hj/s+K+tASWTY+zUfI+ifsZL5WNLxv2Ow4OOCN2CcptV7FrLv8S3vtTLAabkQmHXgJH3xgfz3sf5o2DuePgy1fi+xvkxpko3YdCx0Nj0dqCZbBuSdwXLC3f1q8AEshsGMd06KXQ64R47ooq2Qxf/hMmPBiL5JLAKb+Co2+o+DkkVZpLYCRJkiTVLutXxDBkzlj44sXYlpgQQ4p+Z8RApFXPHT+3eBKMvRWmjY4FZQdfCUN/EAvL7sy6JeVhyLz3Yfn0bV/PyIbc9jF4adoh7nPbx5kqK76CKU/G2idNO8IhF8UwpE3vXX+v/AXw6cMw8RFYtzh+btA34gyQ6S/CxaOg76lV/rHVOqWlcbbM2jxYszAue+ozYu+L/Eq7YQ0QSZIkSXVTksDSz2MQMv1FWDolHm8/IAYh/c6AovXw7h9j15uGzeCIa+DI70KTNpW71vqVsPyLuMQnt31c4rO7ZSmbN8WZHJ89Bl+NibVOuhwRZ5wMOCcutSktga9eg/EPxvElCex/cgxneo+IS2+KNsCDp8LK2XD1GGjXr+o/r6INcVnSvlpOU7IZ5o6FVbNhTR6sXRjDjrV5sHbRtkuPIHZcOvrGGBbZmlk1wABEkiRJUnpYNQe+eCkGIvM/BMr+nmncOoYeR1wTg4d9bd2SuOTms7/HECWrUQw6Fk2MoUBuexh4GQy6Alp23/HzaxbCfSfE8OLqN6vWpnjK0/Dcd2Nx2WN+GJfoVGZpTmWsWxJns4x/ENYtiscysqBpp9hVqFnnsn2XuG/eJX7HsbfCwvFx9svQH8Bh34z1VKRqYgAiSZIkKf0ULIcZL8eZFwdfWDv+kE4SWPRpnBUy/QVo1z/O9uh72p6XfuSNhwdPgy6Hw+X/gKwGFb/m2FvhzVug06C4LGf1HGi9Pwy9Pi7PyWpYPd9t7nuxaO0XL8biuL1Oit+v82Ex5NlT4JIkMOedOGNn7tjUB1dKOwYgkiRJklQXTHoC/vFtOOxKOOO2PS9lKSmGF38Y64ocdD6cdWeciTHteRj351gXJbcDHPXdeM6qdK7ZuKasW8//wYoZcWnQoZfC4G9B615V+54QZ/D8a+lScxjybRhyXdVmv0hlDEAkSZIkqa54/WZ47zY47Y9xZsSubFwLT34DZr8Fx/4YTvj5toFJksTX3vtznHXRsDkcfhUced3OO+okSQw7ClfBhtWxPfKMl2DyU1C8Ps7yOPxqOPDre25/XBmLJsYZLNNfgOwmsP9JcfZK6/1jwNJ6/zhTxDbBqgADEEmSJEmqK0pLYdQlsXjqZc/ENrvbW5MHf78gzsg4488w6PLdn3PhhBiETH8BMhvEbiylm2HDqrLAY1VcOpOUbPu5rBw46LwYnHQaWH3fcWeWTYdxd8RWyPnz4vi2aNQcWvXaNhRptV98XJWlM5sK4vWWTo37zYXxu2Y3KtuXbVmNtto3hgaNy/ZNyp83yLWzTS1iACJJkiRJdcmmdfB/w2MB1Wve2napyeJJMfwo3gAXPAS9Tqz4eVfMhPdvh1lvx+UwOS1j15ucVjvft+kDOS2q/evtUUkx5M+HlbNg5UxYVbZfORvWLOBfxW8htiVuvX9ZQLJf+eNW+8WwZ9XssqBjGiydFh/nzyv/fINcaNg0/jyLN0LJpsqPNyO7LBxpEjvdDDg3dgKqbCci7TUDEEmSJEmqa1bPhftOjGHE1a/HIOLL1+Cpb8bg4tInY8eX+qZ4Yww1Vs3aKiCZHfcFS7d9b2aD8la8ITOGI+0PhPb9od2B8XGLbtsurykthc0bobgwzgwp3lgWjhSW7TfE1stF68seb4CigvLHiyfFds0ZWbET0MEXQt+R1btsSLtkACJJkiRJddHccfDwmdDzuPhH9Cs/gQ4HwcVPQLOOqR5d7bNpXXkYsnI2FK2Dtv1i0NGmT1zisi8s/RwmPxHrp6xbBA2bQf8z4eCLoPvRkJGx42eSBAqWxdkpq+fFfeFq6D0cegzb+We0AwMQSZIkSaqrJjwEL1wfH/ceAec9AA1zUzsmVUxpSWwdPPkJmDY6BjLNusS6Ko1blQUd82PYkT8/zjzZWkY2lBZD866xnfEhF+9d552K2LAqjq2OMgCRJEmSpLrsvdti4c7jfwaZWakejaqiaAPMeBkmPwkzX48FZ3NaxiU4LbrHfcse2z4PAb54CT57LHb0SUqh21Fw6CXQ/+yqtTXelTUL4d3fx5bH146DNvtX37n3IQMQSZIkSZJqi8J8CBmVCzDWLoozST57DFZ8GbvV9D8zzgrpeVzVl8gULIOxf4LxD8SAZfCVsa3yzlol1wEGIJIkSZIkpYMkiW2NP3sMpj4NG9dA046xRkzf06HnMMhquOfzbFgF426Hj++FzZvirJLjfhJnntRhBiCSJEmSJKWb4o0w4yX4/DmY+QYUr4cGTWH/k+CA06H3KXGZzdY2roEP7oIP7ozdaw46H47/ac3XFtlHdheAuHhMkiRJkqS6KLsRDDg3bsUbYc678MWLMOMVmPZcbMXb/egYhvQ6Mb427vbYXabfmXDCf0C7fqn+FvuMAYgkSZIkSXVddiPoMzxupaVxmcyMl+CLl2P75C16D4/BR6eBqRtrihiASJIkSZKUTjIyoOvhcTv5ZlgxM3aR6XAwdBuS6tGljAGIJEmSJEnprM3+dbatbXWqYp8cSZIkSZKkusMARJIkSZIkpT0DEEmSJEmSlPYMQCRJkiRJUtozAJEkSZIkSWnPAESSJEmSJKU9AxBJkiRJkpT2DEAkSZIkSVLaMwCRJEmSJElpzwBEkiRJkiSlPQMQSZIkSZKU9gxAJEmSJElS2jMAkSRJkiRJac8ARJIkSZIkpb0KBSAhhFNDCDNCCDNDCD/dxXuODyF8FkL4PITwTvUOU5IkSZIkqeqy9vSGEEImcCdwCpAHfBJCGJ0kybSt3tMCuAs4NUmS+SGEdjU1YEmSJEmSpMqqyAyQI4CZSZLMTpKkCBgFnLXdey4Bnk2SZD5AkiTLqneYkiRJkiRJVVeRAKQzsGCr53llx7bWB2gZQng7hDAhhPCNnZ0ohPDtEML4EML45cuXV23EkiRJkiRJlVSRACTs5Fiy3fMs4DDgdGAE8F8hhD47fChJ7k2SZHCSJIPbtm1b6cFKkiRJkiRVxR5rgBBnfHTd6nkXYNFO3rMiSZL1wPoQwrvAIcCX1TJKSZIkSZKkvVCRGSCfAL1DCD1DCA2Ai4DR273neWBYCCErhNAYGAJMr96hSpIkSZIkVc0eZ4AkSbI5hPB94FUgE3ggSZLPQwjXlr1+d5Ik00MI/wQmA6XA/UmSTK3JgUuSJEmSJFVUSJLty3nsG4MHD07Gjx+fkmtLkiRJkqT0E0KYkCTJ4J29VpElMJIkSZIkSXWaAYgkSZIkSUp7BiCSJEmSJCntGYBIkiRJkqS0ZwAiSZIkSZLSngGIJEmSJElKewYgkiRJkiQp7RmASJIkSZKktGcAIkmSJEmS0p4BiCRJkiRJSnsGIJIkSZIkKe0ZgEiSJEmSpLRnACJJkiRJktKeAYgkSZIkSUp7BiCSJEmSJCntGYBIkiRJkqS0ZwAiSZIkSZLSngGIJEmSJElKewYgkiRJkiQp7RmASJIkSZKktGcAIkmSJEmS0p4BiCRJkiRJSnsGIJIkSZIkKe2FJElSc+EQlgPzUnLx6tEGWJHqQUgp5D2g+s57QPWd94DqO+8B1Xe19R7oniRJ2529kLIApK4LIYxPkmRwqschpYr3gOo77wHVd94Dqu+8B1Tf1cV7wCUwkiRJkiQp7RmASJIkSZKktGcAUnX3pnoAUop5D6i+8x5Qfec9oPrOe0D1XZ27B6wBIkmSJEmS0p4zQCRJkiRJUtozAKmkEMKpIYQZIYSZIYSfpno8Uk0LIXQNIbwVQpgeQvg8hHBD2fFWIYQxIYSvyvYtUz1WqSaFEDJDCBNDCC+WPfceUL0RQmgRQng6hPBF2f8fHOU9oPokhPDDsn8PmhpCeDyE0Mh7QOkuhPBACGFZCGHqVsd2+XsfQvhZ2d/JM0III1Iz6t0zAKmEEEImcCcwEugPXBxC6J/aUUk1bjPwb0mS9AOOBL5X9nv/U+CNJEl6A2+UPZfS2Q3A9K2eew+oPrkd+GeSJAcAhxDvBe8B1QshhM7A9cDgJEkGAJnARXgPKP39DTh1u2M7/b0v+/vgIuDAss/cVfb3c61iAFI5RwAzkySZnSRJETAKOCvFY5JqVJIki5Mk+bTs8Triv/R2Jv7uP1T2toeAs1MzQqnmhRC6AKcD92912HtA9UIIoRlwLPB/AEmSFCVJko/3gOqXLCAnhJAFNAYW4T2gNJckybvAqu0O7+r3/ixgVJIkm5IkmQPMJP79XKsYgFROZ2DBVs/zyo5J9UIIoQcwEPgIaJ8kyWKIIQnQLnUjk2rcn4GfAKVbHfMeUH2xH7AceLBsGdj9IYQmeA+onkiSZCHwR2A+sBhYkyTJa3gPqH7a1e99nfhb2QCkcsJOjtlGR/VCCCEXeAa4MUmStakej7SvhBDOAJYlSTIh1WORUiQLGAT8NUmSgcB6nOqveqSsxsFZQE+gE9AkhHBZakcl1Tp14m9lA5DKyQO6bvW8C3H6m5TWQgjZxPDj70mSPFt2eGkIoWPZ6x2BZakan1TDjgbODCHMJS59PDGE8CjeA6o/8oC8JEk+Knv+NDEQ8R5QfXEyMCdJkuVJkhQDzwJD8R5Q/bSr3/s68beyAUjlfAL0DiH0DCE0IBZ5GZ3iMUk1KoQQiOu+pydJ8qetXhoNXFH2+Arg+X09NmlfSJLkZ0mSdEmSpAfxn/tvJklyGd4DqieSJFkCLAgh9C07dBIwDe8B1R/zgSNDCI3L/r3oJGJNNO8B1Ue7+r0fDVwUQmgYQugJ9AY+TsH4diskSa2blVKrhRBOI64FzwQeSJLk1ykeklSjQgjHAGOBKZTXP/gPYh2QJ4FuxH8xOD9Jku2LJElpJYRwPHBTkiRnhBBa4z2geiKEcCixCHADYDZwJfE/pHkPqF4IIfwSuJDYHW8icDWQi/eA0lgI4XHgeKANsBT4BfAcu/i9DyH8HPgW8T65MUmSV1Iw7N0yAJEkSZIkSWnPJTCSJEmSJCntGYBIkiRJkqS0ZwAiSZIkSZLSngGIJEmSJElKewYgkiRJkiQp7RmASJIkSZKktGcAIkmSJEmS0p4BiCRJkiRJSnv/HzyxwtELmjouAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_val.history['mean_squared_logarithmic_error'])\n",
    "plt.plot(history_train.history['mean_squared_logarithmic_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:23:35.933634Z",
     "start_time": "2021-05-10T21:17:03.759534Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.77287256 0.75611395 0.75767496]\n",
      "CV accuracy: 0.762 +/- 0.008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n",
    "                         X=X_train_pca,\n",
    "                         y=y_train,\n",
    "                         cv=3,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:39:09.952954Z",
     "start_time": "2021-05-10T21:23:36.971524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.81833149 0.79541575 0.77822127 0.7775064  0.7816467 ]\n",
      "CV accuracy: 0.790 +/- 0.015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n",
    "                         X=X_train_pca,\n",
    "                         y=y_train,\n",
    "                         cv=5,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation curve vs learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:44:14.704462Z",
     "start_time": "2021-05-10T21:39:10.452298Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-2e5e1d59944f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                 learning_curve(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n\u001b[0m\u001b[0;32m      6\u001b[0m                                \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[1;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times)\u001b[0m\n\u001b[0;32m   1277\u001b[0m                 \u001b[0mtrain_test_proportions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_train_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1279\u001b[1;33m         out = parallel(delayed(_fit_and_score)(\n\u001b[0m\u001b[0;32m   1280\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1281\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    387\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \"\"\"\n\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores =\\\n",
    "                learning_curve(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n",
    "                               X=X_train_pca,\n",
    "                               y=y_train,\n",
    "                               train_sizes=np.linspace(0.1, 1.0, 4),\n",
    "                               cv=None,\n",
    "                               n_jobs=1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/06_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:44:14.709448Z",
     "start_time": "2021-05-10T21:17:11.097Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "                estimator=RandomForestRegressor(max_depth=None, random_state=42), \n",
    "                X=X_train, \n",
    "                y=y_train, \n",
    "                cv=None)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, \n",
    "         color='blue', marker='o', \n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(param_range, train_mean + train_std,\n",
    "                 train_mean - train_std, alpha=0.15,\n",
    "                 color='blue')\n",
    "\n",
    "plt.plot(param_range, test_mean, \n",
    "         color='green', linestyle='--', \n",
    "         marker='s', markersize=5, \n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(param_range, \n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std, \n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/06_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make it pipeline and apply to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "430.219px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
