{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**final** <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:32.652659Z",
     "start_time": "2021-05-10T14:31:32.644655Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\lzowe\\OneDrive - The City College of New York\\CCNY_Course\\Applied_Machine_Learning_and_Data_Mining\\codes\\project-product-price-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:35.734059Z",
     "start_time": "2021-05-10T14:31:33.520569Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from final.feature_extraction.vectorization import text_vectorizaion\n",
    "from final.dimension_reduction.feature_reduction import dimension_reduction\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.rcParams['figure.constrained_layout.use'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data processed using Tokenizing and tf-idf algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:44.630868Z",
     "start_time": "2021-05-10T14:31:35.766979Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/DSEI21000-S21/project-product-price-prediction/main/data/random_samples/stratified_sampling_clean_text_data_by_price_whigh_sz50000_1619835594.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:44.724597Z",
     "start_time": "2021-05-10T14:31:44.710637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 34)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:44.940978Z",
     "start_time": "2021-05-10T14:31:44.820188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_upper_char_count</th>\n",
       "      <th>item_name_stopword_count</th>\n",
       "      <th>item_name_punctuation_count</th>\n",
       "      <th>item_name_number_count</th>\n",
       "      <th>item_name_after_word_count</th>\n",
       "      <th>item_name_after_char_count</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.373508e+05</td>\n",
       "      <td>26.583180</td>\n",
       "      <td>150.390920</td>\n",
       "      <td>5.667798</td>\n",
       "      <td>1.876040</td>\n",
       "      <td>12.577260</td>\n",
       "      <td>7.67970</td>\n",
       "      <td>5.850200</td>\n",
       "      <td>0.499880</td>\n",
       "      <td>18.323300</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794540</td>\n",
       "      <td>0.192960</td>\n",
       "      <td>0.414340</td>\n",
       "      <td>0.177680</td>\n",
       "      <td>4.236300</td>\n",
       "      <td>24.381740</td>\n",
       "      <td>5.845573</td>\n",
       "      <td>1.991820</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>108.41749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.251891e+05</td>\n",
       "      <td>28.205148</td>\n",
       "      <td>161.300927</td>\n",
       "      <td>0.782677</td>\n",
       "      <td>5.826971</td>\n",
       "      <td>28.114883</td>\n",
       "      <td>10.36772</td>\n",
       "      <td>8.336725</td>\n",
       "      <td>1.229061</td>\n",
       "      <td>18.691275</td>\n",
       "      <td>...</td>\n",
       "      <td>5.226287</td>\n",
       "      <td>0.463088</td>\n",
       "      <td>0.828128</td>\n",
       "      <td>0.422508</td>\n",
       "      <td>1.535705</td>\n",
       "      <td>8.740065</td>\n",
       "      <td>1.210724</td>\n",
       "      <td>0.896911</td>\n",
       "      <td>0.484564</td>\n",
       "      <td>198.75487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.726685e+05</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>5.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.353620e+05</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>5.642857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.102881e+06</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>6.020944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482519e+06</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>761.000000</td>\n",
       "      <td>104.00000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_id  item_description_bef_word_count  \\\n",
       "count  5.000000e+04                     50000.000000   \n",
       "mean   7.373508e+05                        26.583180   \n",
       "std    4.251891e+05                        28.205148   \n",
       "min    1.900000e+01                         1.000000   \n",
       "25%    3.726685e+05                         8.000000   \n",
       "50%    7.353620e+05                        17.000000   \n",
       "75%    1.102881e+06                        34.000000   \n",
       "max    1.482519e+06                       206.000000   \n",
       "\n",
       "       item_description_bef_char_count  item_description_bef_avg_word_len  \\\n",
       "count                     50000.000000                       50000.000000   \n",
       "mean                        150.390920                           5.667798   \n",
       "std                         161.300927                           0.782677   \n",
       "min                           1.000000                           1.000000   \n",
       "25%                          46.000000                           5.210526   \n",
       "50%                          97.000000                           5.642857   \n",
       "75%                         191.000000                           6.020944   \n",
       "max                        1007.000000                          19.600000   \n",
       "\n",
       "       item_description_upper_word_count  item_description_upper_char_count  \\\n",
       "count                       50000.000000                       50000.000000   \n",
       "mean                            1.876040                          12.577260   \n",
       "std                             5.826971                          28.114883   \n",
       "min                             0.000000                           0.000000   \n",
       "25%                             0.000000                           2.000000   \n",
       "50%                             0.000000                           5.000000   \n",
       "75%                             1.000000                          12.000000   \n",
       "max                           178.000000                         761.000000   \n",
       "\n",
       "       item_description_stopword_count  item_description_punctuation_count  \\\n",
       "count                      50000.00000                        50000.000000   \n",
       "mean                           7.67970                            5.850200   \n",
       "std                           10.36772                            8.336725   \n",
       "min                            0.00000                            0.000000   \n",
       "25%                            1.00000                            1.000000   \n",
       "50%                            4.00000                            3.000000   \n",
       "75%                           10.00000                            8.000000   \n",
       "max                          104.00000                          308.000000   \n",
       "\n",
       "       item_description_number_count  item_description_after_word_count  ...  \\\n",
       "count                   50000.000000                       50000.000000  ...   \n",
       "mean                        0.499880                          18.323300  ...   \n",
       "std                         1.229061                          18.691275  ...   \n",
       "min                         0.000000                           1.000000  ...   \n",
       "25%                         0.000000                           7.000000  ...   \n",
       "50%                         0.000000                          12.000000  ...   \n",
       "75%                         1.000000                          23.000000  ...   \n",
       "max                        57.000000                         175.000000  ...   \n",
       "\n",
       "       item_name_upper_char_count  item_name_stopword_count  \\\n",
       "count                50000.000000              50000.000000   \n",
       "mean                     4.794540                  0.192960   \n",
       "std                      5.226287                  0.463088   \n",
       "min                      0.000000                  0.000000   \n",
       "25%                      2.000000                  0.000000   \n",
       "50%                      3.000000                  0.000000   \n",
       "75%                      6.000000                  0.000000   \n",
       "max                     37.000000                  6.000000   \n",
       "\n",
       "       item_name_punctuation_count  item_name_number_count  \\\n",
       "count                 50000.000000            50000.000000   \n",
       "mean                      0.414340                0.177680   \n",
       "std                       0.828128                0.422508   \n",
       "min                       0.000000                0.000000   \n",
       "25%                       0.000000                0.000000   \n",
       "50%                       0.000000                0.000000   \n",
       "75%                       1.000000                0.000000   \n",
       "max                      12.000000                9.000000   \n",
       "\n",
       "       item_name_after_word_count  item_name_after_char_count  \\\n",
       "count                50000.000000                50000.000000   \n",
       "mean                     4.236300                   24.381740   \n",
       "std                      1.535705                    8.740065   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      3.000000                   18.000000   \n",
       "50%                      4.000000                   25.000000   \n",
       "75%                      5.000000                   32.000000   \n",
       "max                     13.000000                   42.000000   \n",
       "\n",
       "       item_name_after_avg_word_len  item_condition_id      shipping  \\\n",
       "count                  50000.000000       50000.000000  50000.000000   \n",
       "mean                       5.845573           1.991820      0.376700   \n",
       "std                        1.210724           0.896911      0.484564   \n",
       "min                        1.000000           1.000000      0.000000   \n",
       "25%                        5.000000           1.000000      0.000000   \n",
       "50%                        5.750000           2.000000      0.000000   \n",
       "75%                        6.500000           3.000000      1.000000   \n",
       "max                       26.000000           5.000000      1.000000   \n",
       "\n",
       "             price  \n",
       "count  50000.00000  \n",
       "mean     108.41749  \n",
       "std      198.75487  \n",
       "min        3.00000  \n",
       "25%       20.00000  \n",
       "50%       50.00000  \n",
       "75%       90.00000  \n",
       "max     2009.00000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:45.082895Z",
     "start_time": "2021-05-10T14:31:45.038176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 34 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   train_id                             50000 non-null  int64  \n",
      " 1   clean_item_description               50000 non-null  object \n",
      " 2   item_description_bef_word_count      50000 non-null  float64\n",
      " 3   item_description_bef_char_count      50000 non-null  float64\n",
      " 4   item_description_bef_avg_word_len    50000 non-null  float64\n",
      " 5   item_description_upper_word_count    50000 non-null  float64\n",
      " 6   item_description_upper_char_count    50000 non-null  float64\n",
      " 7   item_description_stopword_count      50000 non-null  float64\n",
      " 8   item_description_punctuation_count   50000 non-null  float64\n",
      " 9   item_description_number_count        50000 non-null  float64\n",
      " 10  item_description_after_word_count    50000 non-null  float64\n",
      " 11  item_description_after_char_count    50000 non-null  float64\n",
      " 12  item_description_after_avg_word_len  50000 non-null  float64\n",
      " 13  clean_item_name                      50000 non-null  object \n",
      " 14  item_name_bef_word_count             50000 non-null  float64\n",
      " 15  item_name_bef_char_count             50000 non-null  float64\n",
      " 16  item_name_bef_avg_word_len           50000 non-null  float64\n",
      " 17  item_name_upper_word_count           50000 non-null  float64\n",
      " 18  item_name_upper_char_count           50000 non-null  float64\n",
      " 19  item_name_stopword_count             50000 non-null  float64\n",
      " 20  item_name_punctuation_count          50000 non-null  float64\n",
      " 21  item_name_number_count               50000 non-null  float64\n",
      " 22  item_name_after_word_count           50000 non-null  float64\n",
      " 23  item_name_after_char_count           50000 non-null  float64\n",
      " 24  item_name_after_avg_word_len         50000 non-null  float64\n",
      " 25  item_condition_id                    50000 non-null  int64  \n",
      " 26  category_name                        50000 non-null  object \n",
      " 27  brand_name                           50000 non-null  object \n",
      " 28  shipping                             50000 non-null  int64  \n",
      " 29  price                                50000 non-null  float64\n",
      " 30  c1                                   50000 non-null  object \n",
      " 31  c2                                   50000 non-null  object \n",
      " 32  c3                                   50000 non-null  object \n",
      " 33  price_bin                            50000 non-null  object \n",
      "dtypes: float64(23), int64(3), object(8)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:45.193430Z",
     "start_time": "2021-05-10T14:31:45.179478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42039,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean_item_name.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:45.303704Z",
     "start_time": "2021-05-10T14:31:45.273752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>clean_item_description</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>new tags</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Athletic Apparel/Shirts &amp; Tops</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>women</td>\n",
       "      <td>athletic apparel</td>\n",
       "      <td>shirts &amp; tops</td>\n",
       "      <td>(10, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>nastasya every hills lipstick fashion</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Lips</td>\n",
       "      <td>Anastasia Beverly Hills</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>beauty</td>\n",
       "      <td>makeup</td>\n",
       "      <td>lips</td>\n",
       "      <td>(20, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>brand new tags taken bag pictures</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jeans/Leggings</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>women</td>\n",
       "      <td>jeans</td>\n",
       "      <td>leggings</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>bought calves bit large frowned good condition...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>boots</td>\n",
       "      <td>(80, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>brand new box size 7youth859womens</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>athletic</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                             clean_item_description  \\\n",
       "0    806824                                           new tags   \n",
       "1    772820              nastasya every hills lipstick fashion   \n",
       "2   1423115                  brand new tags taken bag pictures   \n",
       "3    405853  bought calves bit large frowned good condition...   \n",
       "4   1172086                 brand new box size 7youth859womens   \n",
       "\n",
       "   item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0                              3.0                             13.0   \n",
       "1                              6.0                             42.0   \n",
       "2                             11.0                             54.0   \n",
       "3                             35.0                            188.0   \n",
       "4                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  ...  \\\n",
       "0                                 0.0                            0.0  ...   \n",
       "1                                 0.0                            0.0  ...   \n",
       "2                                 0.0                            0.0  ...   \n",
       "3                                 7.0                            1.0  ...   \n",
       "4                                 3.0                            0.0  ...   \n",
       "\n",
       "   item_name_after_avg_word_len  item_condition_id  \\\n",
       "0                      5.250000                  1   \n",
       "1                     10.000000                  1   \n",
       "2                      6.166667                  1   \n",
       "3                      5.333333                  3   \n",
       "4                      4.000000                  1   \n",
       "\n",
       "                          category_name               brand_name  shipping  \\\n",
       "0  Women/Athletic Apparel/Shirts & Tops                     Nike         1   \n",
       "1                    Beauty/Makeup/Lips  Anastasia Beverly Hills         0   \n",
       "2                  Women/Jeans/Leggings                  LuLaRoe         0   \n",
       "3                     Women/Shoes/Boots                   Hunter         0   \n",
       "4                  Women/Shoes/Athletic                     Nike         0   \n",
       "\n",
       "   price      c1                c2             c3  price_bin  \n",
       "0   15.0   women  athletic apparel  shirts & tops   (10, 15]  \n",
       "1   22.0  beauty            makeup           lips   (20, 25]  \n",
       "2   54.0   women             jeans       leggings   (50, 60]  \n",
       "3   84.0   women             shoes          boots   (80, 90]  \n",
       "4   56.0   women             shoes       athletic   (50, 60]  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Feature extraction and dimension selection\n",
    " \n",
    " For Item-discription feature: <br>\n",
    " using Jin's function to, firstly, do feature-extraction, increasing up to 14230 new few features <br>\n",
    " secondly, do dimenstion-reduction <br>\n",
    " finally, left 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:45.413177Z",
     "start_time": "2021-05-10T14:31:45.399806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corners bottom great shape lips smells markings inside cleanthere small water mark indicated third photo comes dusting'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean_item_description[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:47.516654Z",
     "start_time": "2021-05-10T14:31:45.510772Z"
    }
   },
   "outputs": [],
   "source": [
    "description_feature,  description_feature_name = text_vectorizaion(df, text_col = \"clean_item_description\", \n",
    "                                                                   tfidf = True, min_df=10, max_features=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:31:47.655663Z",
     "start_time": "2021-05-10T14:31:47.642680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 14230)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:35:22.233616Z",
     "start_time": "2021-05-10T14:33:11.591329Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dimension_reduction(description_feature.toarray(), method = 'SVD', n_comp = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:35:22.809401Z",
     "start_time": "2021-05-10T14:35:22.780067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:35:22.950013Z",
     "start_time": "2021-05-10T14:35:22.904725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.316579</td>\n",
       "      <td>0.226464</td>\n",
       "      <td>-0.093895</td>\n",
       "      <td>-0.145726</td>\n",
       "      <td>-0.160603</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>-0.018076</td>\n",
       "      <td>0.090894</td>\n",
       "      <td>0.191936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006317</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>-0.005581</td>\n",
       "      <td>-0.010842</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.003891</td>\n",
       "      <td>-0.001106</td>\n",
       "      <td>-0.005983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>-0.001485</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.003073</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-0.001260</td>\n",
       "      <td>-0.002306</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004840</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>-0.012678</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.033451</td>\n",
       "      <td>-0.009159</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.010452</td>\n",
       "      <td>-0.009743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.282559</td>\n",
       "      <td>0.198734</td>\n",
       "      <td>-0.108194</td>\n",
       "      <td>-0.022314</td>\n",
       "      <td>-0.049008</td>\n",
       "      <td>-0.093222</td>\n",
       "      <td>0.013353</td>\n",
       "      <td>-0.023766</td>\n",
       "      <td>0.027215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022179</td>\n",
       "      <td>-0.021409</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>-0.005660</td>\n",
       "      <td>-0.031209</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>0.012904</td>\n",
       "      <td>-0.023262</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>-0.006134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.087350</td>\n",
       "      <td>-0.138583</td>\n",
       "      <td>-0.028884</td>\n",
       "      <td>-0.007240</td>\n",
       "      <td>-0.041193</td>\n",
       "      <td>-0.030503</td>\n",
       "      <td>0.157927</td>\n",
       "      <td>0.007502</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>0.020494</td>\n",
       "      <td>-0.005764</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>-0.008580</td>\n",
       "      <td>-0.004911</td>\n",
       "      <td>-0.012527</td>\n",
       "      <td>0.038012</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>0.004574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.407447</td>\n",
       "      <td>0.230953</td>\n",
       "      <td>-0.090665</td>\n",
       "      <td>-0.028014</td>\n",
       "      <td>-0.120191</td>\n",
       "      <td>-0.079089</td>\n",
       "      <td>0.052898</td>\n",
       "      <td>-0.152951</td>\n",
       "      <td>-0.178787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017751</td>\n",
       "      <td>-0.007499</td>\n",
       "      <td>-0.010177</td>\n",
       "      <td>-0.002043</td>\n",
       "      <td>-0.025282</td>\n",
       "      <td>0.023945</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.029525</td>\n",
       "      <td>-0.005772</td>\n",
       "      <td>0.026614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000323  0.316579  0.226464 -0.093895 -0.145726 -0.160603 -0.003325   \n",
       "1  0.000036  0.006363 -0.001485 -0.000309 -0.003073  0.008711  0.000231   \n",
       "2  0.000307  0.282559  0.198734 -0.108194 -0.022314 -0.049008 -0.093222   \n",
       "3  0.000196  0.087350 -0.138583 -0.028884 -0.007240 -0.041193 -0.030503   \n",
       "4  0.000409  0.407447  0.230953 -0.090665 -0.028014 -0.120191 -0.079089   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0 -0.018076  0.090894  0.191936  ... -0.006317  0.006542  0.010669 -0.005581   \n",
       "1 -0.001260 -0.002306  0.001750  ... -0.004840  0.004459  0.002455 -0.012678   \n",
       "2  0.013353 -0.023766  0.027215  ...  0.022179 -0.021409  0.011562 -0.005660   \n",
       "3  0.157927  0.007502  0.001830  ...  0.007247  0.020494 -0.005764  0.011212   \n",
       "4  0.052898 -0.152951 -0.178787  ... -0.017751 -0.007499 -0.010177 -0.002043   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.010842  0.003553  0.007595 -0.003891 -0.001106 -0.005983  \n",
       "1  0.002716  0.033451 -0.009159  0.001912  0.010452 -0.009743  \n",
       "2 -0.031209  0.015808  0.012904 -0.023262 -0.005586 -0.006134  \n",
       "3 -0.008580 -0.004911 -0.012527  0.038012  0.017483  0.004574  \n",
       "4 -0.025282  0.023945  0.000360  0.029525 -0.005772  0.026614  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cid = pd.DataFrame(data.copy()) #df for cleaned item description transforming to new features\n",
    "df_cid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating new features df_cid and previous df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:35:23.199076Z",
     "start_time": "2021-05-10T14:35:23.093164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_after_avg_word_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>price</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Athletic Apparel/Shirts &amp; Tops</td>\n",
       "      <td>Nike</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>women</td>\n",
       "      <td>athletic apparel</td>\n",
       "      <td>shirts &amp; tops</td>\n",
       "      <td>(10, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Lips</td>\n",
       "      <td>Anastasia Beverly Hills</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>beauty</td>\n",
       "      <td>makeup</td>\n",
       "      <td>lips</td>\n",
       "      <td>(20, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jeans/Leggings</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>women</td>\n",
       "      <td>jeans</td>\n",
       "      <td>leggings</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>boots</td>\n",
       "      <td>(80, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>women</td>\n",
       "      <td>shoes</td>\n",
       "      <td>athletic</td>\n",
       "      <td>(50, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0    806824                              3.0                             13.0   \n",
       "1    772820                              6.0                             42.0   \n",
       "2   1423115                             11.0                             54.0   \n",
       "3    405853                             35.0                            188.0   \n",
       "4   1172086                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  \\\n",
       "0                                 0.0                            0.0   \n",
       "1                                 0.0                            0.0   \n",
       "2                                 0.0                            0.0   \n",
       "3                                 7.0                            1.0   \n",
       "4                                 3.0                            0.0   \n",
       "\n",
       "   item_description_after_word_count  ...  item_name_after_avg_word_len  \\\n",
       "0                                2.0  ...                      5.250000   \n",
       "1                                5.0  ...                     10.000000   \n",
       "2                                6.0  ...                      6.166667   \n",
       "3                               17.0  ...                      5.333333   \n",
       "4                                5.0  ...                      4.000000   \n",
       "\n",
       "   item_condition_id                         category_name  \\\n",
       "0                  1  Women/Athletic Apparel/Shirts & Tops   \n",
       "1                  1                    Beauty/Makeup/Lips   \n",
       "2                  1                  Women/Jeans/Leggings   \n",
       "3                  3                     Women/Shoes/Boots   \n",
       "4                  1                  Women/Shoes/Athletic   \n",
       "\n",
       "                brand_name  shipping  price      c1                c2  \\\n",
       "0                     Nike         1   15.0   women  athletic apparel   \n",
       "1  Anastasia Beverly Hills         0   22.0  beauty            makeup   \n",
       "2                  LuLaRoe         0   54.0   women             jeans   \n",
       "3                   Hunter         0   84.0   women             shoes   \n",
       "4                     Nike         0   56.0   women             shoes   \n",
       "\n",
       "              c3  price_bin  \n",
       "0  shirts & tops   (10, 15]  \n",
       "1           lips   (20, 25]  \n",
       "2       leggings   (50, 60]  \n",
       "3          boots   (80, 90]  \n",
       "4       athletic   (50, 60]  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.copy()\n",
    "df1.drop(\"clean_item_description\", inplace=True,axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:35:23.400005Z",
     "start_time": "2021-05-10T14:35:23.370388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 33 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   train_id                             50000 non-null  int64  \n",
      " 1   item_description_bef_word_count      50000 non-null  float64\n",
      " 2   item_description_bef_char_count      50000 non-null  float64\n",
      " 3   item_description_bef_avg_word_len    50000 non-null  float64\n",
      " 4   item_description_upper_word_count    50000 non-null  float64\n",
      " 5   item_description_upper_char_count    50000 non-null  float64\n",
      " 6   item_description_stopword_count      50000 non-null  float64\n",
      " 7   item_description_punctuation_count   50000 non-null  float64\n",
      " 8   item_description_number_count        50000 non-null  float64\n",
      " 9   item_description_after_word_count    50000 non-null  float64\n",
      " 10  item_description_after_char_count    50000 non-null  float64\n",
      " 11  item_description_after_avg_word_len  50000 non-null  float64\n",
      " 12  clean_item_name                      50000 non-null  object \n",
      " 13  item_name_bef_word_count             50000 non-null  float64\n",
      " 14  item_name_bef_char_count             50000 non-null  float64\n",
      " 15  item_name_bef_avg_word_len           50000 non-null  float64\n",
      " 16  item_name_upper_word_count           50000 non-null  float64\n",
      " 17  item_name_upper_char_count           50000 non-null  float64\n",
      " 18  item_name_stopword_count             50000 non-null  float64\n",
      " 19  item_name_punctuation_count          50000 non-null  float64\n",
      " 20  item_name_number_count               50000 non-null  float64\n",
      " 21  item_name_after_word_count           50000 non-null  float64\n",
      " 22  item_name_after_char_count           50000 non-null  float64\n",
      " 23  item_name_after_avg_word_len         50000 non-null  float64\n",
      " 24  item_condition_id                    50000 non-null  int64  \n",
      " 25  category_name                        50000 non-null  object \n",
      " 26  brand_name                           50000 non-null  object \n",
      " 27  shipping                             50000 non-null  int64  \n",
      " 28  price                                50000 non-null  float64\n",
      " 29  c1                                   50000 non-null  object \n",
      " 30  c2                                   50000 non-null  object \n",
      " 31  c3                                   50000 non-null  object \n",
      " 32  price_bin                            50000 non-null  object \n",
      "dtypes: float64(23), int64(3), object(7)\n",
      "memory usage: 12.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:35:23.588385Z",
     "start_time": "2021-05-10T14:35:23.576207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 33), (50000, 100))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape,df_cid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:35:23.794846Z",
     "start_time": "2021-05-10T14:35:23.749263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 133)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat=pd.concat([df1,df_cid],axis=1)\n",
    "df_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using one-hot encoding for category and nominal features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete price bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:35:24.015326Z",
     "start_time": "2021-05-10T14:35:24.001664Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_catNnom = ['category_name','brand_name', 'c1', 'c2', 'c3'] # columns of category and nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:35:26.280723Z",
     "start_time": "2021-05-10T14:35:24.207325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3028)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from final.feature_encoding.one_hot_encoding import one_hot_encode_feature\n",
    "df_encode = df_concat\n",
    "for col in cols_catNnom:\n",
    "    df_encode, col_encode = one_hot_encode_feature(df_encode, encode_column=col,drop_first=False)\n",
    "df_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:35:27.362838Z",
     "start_time": "2021-05-10T14:35:27.333061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 3028 entries, train_id to c3_yoga & pilates\n",
      "dtypes: float64(123), int64(3), object(2), uint8(2900)\n",
      "memory usage: 187.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_encode.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:43:39.677865Z",
     "start_time": "2021-05-10T14:43:39.648943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_description_bef_word_count</th>\n",
       "      <th>item_description_bef_char_count</th>\n",
       "      <th>item_description_bef_avg_word_len</th>\n",
       "      <th>item_description_upper_word_count</th>\n",
       "      <th>item_description_upper_char_count</th>\n",
       "      <th>item_description_stopword_count</th>\n",
       "      <th>item_description_punctuation_count</th>\n",
       "      <th>item_description_number_count</th>\n",
       "      <th>item_description_after_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>c3_window treatments</th>\n",
       "      <th>c3_wine, beer &amp; beverage coolers</th>\n",
       "      <th>c3_wipes &amp; holders</th>\n",
       "      <th>c3_women</th>\n",
       "      <th>c3_women's golf clubs</th>\n",
       "      <th>c3_wool</th>\n",
       "      <th>c3_work &amp; safety</th>\n",
       "      <th>c3_wrap</th>\n",
       "      <th>c3_writing</th>\n",
       "      <th>c3_yoga &amp; pilates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>806824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423115</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405853</td>\n",
       "      <td>35.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  item_description_bef_word_count  item_description_bef_char_count  \\\n",
       "0    806824                              3.0                             13.0   \n",
       "1    772820                              6.0                             42.0   \n",
       "2   1423115                             11.0                             54.0   \n",
       "3    405853                             35.0                            188.0   \n",
       "4   1172086                              6.0                             40.0   \n",
       "\n",
       "   item_description_bef_avg_word_len  item_description_upper_word_count  \\\n",
       "0                           4.333333                                0.0   \n",
       "1                           7.000000                                0.0   \n",
       "2                           4.909091                                0.0   \n",
       "3                           5.371429                                1.0   \n",
       "4                           6.666667                                0.0   \n",
       "\n",
       "   item_description_upper_char_count  item_description_stopword_count  \\\n",
       "0                                1.0                              1.0   \n",
       "1                                4.0                              1.0   \n",
       "2                                1.0                              5.0   \n",
       "3                                4.0                             17.0   \n",
       "4                                3.0                              1.0   \n",
       "\n",
       "   item_description_punctuation_count  item_description_number_count  \\\n",
       "0                                 0.0                            0.0   \n",
       "1                                 0.0                            0.0   \n",
       "2                                 0.0                            0.0   \n",
       "3                                 7.0                            1.0   \n",
       "4                                 3.0                            0.0   \n",
       "\n",
       "   item_description_after_word_count  ...  c3_window treatments  \\\n",
       "0                                2.0  ...                     0   \n",
       "1                                5.0  ...                     0   \n",
       "2                                6.0  ...                     0   \n",
       "3                               17.0  ...                     0   \n",
       "4                                5.0  ...                     0   \n",
       "\n",
       "   c3_wine, beer & beverage coolers c3_wipes & holders  c3_women  \\\n",
       "0                                 0                  0         0   \n",
       "1                                 0                  0         0   \n",
       "2                                 0                  0         0   \n",
       "3                                 0                  0         0   \n",
       "4                                 0                  0         0   \n",
       "\n",
       "   c3_women's golf clubs  c3_wool  c3_work & safety  c3_wrap  c3_writing  \\\n",
       "0                      0        0                 0        0           0   \n",
       "1                      0        0                 0        0           0   \n",
       "2                      0        0                 0        0           0   \n",
       "3                      0        0                 0        0           0   \n",
       "4                      0        0                 0        0           0   \n",
       "\n",
       "   c3_yoga & pilates  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 3028 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:43:41.155993Z",
     "start_time": "2021-05-10T14:43:41.145062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price\n",
       "0        15.0\n",
       "1        22.0\n",
       "2        54.0\n",
       "3        84.0\n",
       "4        56.0\n",
       "...       ...\n",
       "49995  1609.0\n",
       "49996   205.0\n",
       "49997    36.0\n",
       "49998    20.0\n",
       "49999    72.0\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encode[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:43:44.138880Z",
     "start_time": "2021-05-10T14:43:43.928840Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare input X, y\n",
    "X, y = df_encode.copy().drop([\"clean_item_name\",\"train_id\",\"price\",\"price_bin\"],axis=1), df_encode[[\"price\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:43:44.607673Z",
     "start_time": "2021-05-10T14:43:44.577850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 3024 entries, item_description_bef_word_count to c3_yoga & pilates\n",
      "dtypes: float64(122), int64(2), uint8(2900)\n",
      "memory usage: 185.6 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:43:45.333250Z",
     "start_time": "2021-05-10T14:43:44.954806Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct dimension reduction on the dateframe processed by one-hot encoding\n",
    "skip this step in the first place. <br>\n",
    "let us see how the regression result looks like. and then determine if the dimension reduction on whole dataset needed, or if use other techniques to avoid overfitting(e.g. adding penalty, using RobustScaler, conducting cross validation).<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 1: actually can't skip this step, the dimension is too large to run, Exception was raised: MemoryError: Unable to allocate 11.8 GiB for an array with shape (45079, 35000) and data type float64.\n",
    "Therefore, try conduct PCA again before regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 2: even can't not run PCA due to the large number of features. Try drop clean_item_name instead of encoding it, as it is has very less duplicated items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 3: Since log2 works, skip this step( e.i. 1.5) for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* log 4: features are too much later, have to reduce dimension at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:43:49.270071Z",
     "start_time": "2021-05-10T14:43:46.246142Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:44:04.649993Z",
     "start_time": "2021-05-10T14:43:49.726264Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00290274, 0.00227727, 0.00214539, 0.00197284, 0.00188353,\n",
       "       0.00186426, 0.0018058 , 0.00178313, 0.00174866, 0.00167442,\n",
       "       0.00162627, 0.00160712, 0.00155192, 0.00154925, 0.00147124,\n",
       "       0.00146199, 0.00145777, 0.00145602, 0.00145047, 0.00143985,\n",
       "       0.0014337 , 0.00142884, 0.00142507, 0.00142105, 0.00141873,\n",
       "       0.00141648, 0.00140887, 0.00140064, 0.00139436, 0.00139284,\n",
       "       0.00139024, 0.00138276, 0.00138131, 0.00136757, 0.00136051,\n",
       "       0.00135188, 0.00134316, 0.00133635, 0.00132348, 0.00132175,\n",
       "       0.0013068 , 0.00129997, 0.00129449, 0.00129199, 0.00128497,\n",
       "       0.00128115, 0.00127661, 0.00127131, 0.00127024, 0.00126755,\n",
       "       0.00125911, 0.00124846, 0.00124468, 0.00123624, 0.00121846,\n",
       "       0.00120892, 0.00120211, 0.00119847, 0.0011941 , 0.00119169,\n",
       "       0.0011836 , 0.00117939, 0.00117742, 0.00116425, 0.00115631,\n",
       "       0.0011543 , 0.00115258, 0.0011523 , 0.00114899, 0.00113173,\n",
       "       0.0011285 , 0.00112591, 0.00112223, 0.00111238, 0.00110563,\n",
       "       0.00110086, 0.00110019, 0.00109884, 0.00109746, 0.00109701,\n",
       "       0.00109632, 0.00109617, 0.00109596, 0.0010958 , 0.00109548,\n",
       "       0.00109542, 0.00109515, 0.00109492, 0.00109468, 0.00109454,\n",
       "       0.00109374, 0.00109343, 0.00109259, 0.00109192, 0.00109127,\n",
       "       0.00109099, 0.00109009, 0.00108894, 0.00108809, 0.00108501,\n",
       "       0.00108294, 0.00108161, 0.00107927, 0.00107441, 0.00106997,\n",
       "       0.00106465, 0.00105971, 0.00105492, 0.00105256, 0.00105039,\n",
       "       0.00104587, 0.00104454, 0.00104216, 0.0010382 , 0.00103804,\n",
       "       0.00103454, 0.00102411, 0.00101991, 0.00101863, 0.00101588,\n",
       "       0.00101379, 0.0010109 , 0.00100872, 0.0010069 , 0.00100497,\n",
       "       0.00100438, 0.00100271, 0.00099909, 0.0009973 , 0.00099563,\n",
       "       0.00099308, 0.00099234, 0.00099138, 0.00098684, 0.00098645,\n",
       "       0.00098291, 0.00098198, 0.00098118, 0.00097927, 0.0009775 ,\n",
       "       0.00097691, 0.00097576, 0.00097537, 0.00097417, 0.0009736 ,\n",
       "       0.00097032, 0.00096844, 0.0009667 , 0.00096597, 0.0009626 ,\n",
       "       0.00096084, 0.00095998, 0.00095591, 0.00095449, 0.00095321,\n",
       "       0.00095276, 0.0009522 , 0.00095069, 0.00094854, 0.00094781,\n",
       "       0.0009464 , 0.00094104, 0.00093988, 0.00093789, 0.00093752,\n",
       "       0.00093504, 0.000931  , 0.00093003, 0.00092717, 0.00092622,\n",
       "       0.00092391, 0.00092147, 0.00091907, 0.00091599, 0.0009118 ,\n",
       "       0.00091078, 0.00090944, 0.00090633, 0.00090577, 0.00090535,\n",
       "       0.00090332, 0.00090123, 0.00089969, 0.00089697, 0.00089538,\n",
       "       0.00089287, 0.00089113, 0.00089059, 0.00088843, 0.00088583,\n",
       "       0.00088435, 0.00088131, 0.0008808 , 0.00087959, 0.00087818,\n",
       "       0.00087737, 0.00087659, 0.00087603, 0.00087286, 0.00087143,\n",
       "       0.00086893, 0.00086857, 0.00086781, 0.00086742, 0.00086627,\n",
       "       0.0008646 , 0.00086421, 0.00086307, 0.00086252, 0.00086159,\n",
       "       0.00086076, 0.00085956, 0.00085814, 0.00085787, 0.00085683,\n",
       "       0.00085564, 0.0008546 , 0.00085339, 0.00085288, 0.00085185,\n",
       "       0.0008516 , 0.00084958, 0.00084815, 0.00084721, 0.0008462 ,\n",
       "       0.00084515, 0.00084393, 0.0008417 , 0.0008393 , 0.00083883,\n",
       "       0.00083774, 0.00083568, 0.00083444, 0.00083347, 0.00083222,\n",
       "       0.00083081, 0.00082825, 0.00082697, 0.0008264 , 0.00082525,\n",
       "       0.00082392, 0.00082254, 0.00082192, 0.00082084, 0.00082028,\n",
       "       0.00081839, 0.00081803, 0.00081724, 0.00081671, 0.00081475,\n",
       "       0.00081335, 0.00081269, 0.00081156, 0.00080873, 0.00080849,\n",
       "       0.00080734, 0.00080617, 0.00080539, 0.00080364, 0.00080338,\n",
       "       0.00080325, 0.00080176, 0.00080103, 0.0008006 , 0.00079946,\n",
       "       0.00079926, 0.0007978 , 0.00079764, 0.0007975 , 0.0007967 ,\n",
       "       0.00079603, 0.00079544, 0.00079356, 0.00079297, 0.00079235,\n",
       "       0.00079093, 0.00079055, 0.00079034, 0.00078913, 0.00078871,\n",
       "       0.00078852, 0.00078774, 0.00078632, 0.00078556, 0.0007851 ,\n",
       "       0.00078401, 0.00078309, 0.00078207, 0.00078107, 0.00078054,\n",
       "       0.00078028, 0.00077949, 0.00077836, 0.000778  , 0.00077689,\n",
       "       0.00077532, 0.00077447, 0.00077381, 0.00077338, 0.0007728 ,\n",
       "       0.00077188, 0.00077125, 0.00077084, 0.00076958, 0.0007691 ,\n",
       "       0.00076855, 0.00076742, 0.00076734, 0.00076663, 0.00076571,\n",
       "       0.00076505, 0.00076407, 0.00076364, 0.00076328, 0.00076246,\n",
       "       0.00076162, 0.00076111, 0.00076012, 0.00075962, 0.00075783,\n",
       "       0.00075753, 0.00075703, 0.00075648, 0.00075611, 0.00075488,\n",
       "       0.00075421, 0.00075398, 0.00075313, 0.00075259, 0.00075186,\n",
       "       0.00075107, 0.00075066, 0.00075014, 0.00074975, 0.00074958,\n",
       "       0.00074904, 0.00074868, 0.00074777, 0.00074701, 0.00074688,\n",
       "       0.00074636, 0.00074578, 0.00074564, 0.00074534, 0.00074426,\n",
       "       0.00074409, 0.00074351, 0.00074305, 0.00074245, 0.00074179,\n",
       "       0.00074089, 0.00074054, 0.00074047, 0.00074014, 0.00073975,\n",
       "       0.00073898, 0.00073873, 0.00073785, 0.00073753, 0.00073713,\n",
       "       0.00073688, 0.00073628, 0.00073608, 0.00073578, 0.00073508,\n",
       "       0.00073432, 0.00073412, 0.0007339 , 0.00073357, 0.00073298,\n",
       "       0.00073262, 0.00073246, 0.00073213, 0.00073183, 0.00073144,\n",
       "       0.00073058, 0.0007304 , 0.00072973, 0.00072951, 0.00072941,\n",
       "       0.00072914, 0.00072871, 0.00072849, 0.00072787, 0.0007277 ,\n",
       "       0.00072754, 0.00072701, 0.00072678, 0.00072658, 0.00072646,\n",
       "       0.0007261 , 0.00072587, 0.00072513, 0.00072504, 0.00072472,\n",
       "       0.0007243 , 0.00072398, 0.00072317, 0.00072301, 0.00072273,\n",
       "       0.00072227, 0.00072187, 0.00072126, 0.00072083, 0.00072024,\n",
       "       0.00071997, 0.00071865, 0.0007184 , 0.00071831, 0.00071671,\n",
       "       0.0007164 , 0.00071618, 0.00071481, 0.00071429, 0.00071377,\n",
       "       0.00071305, 0.00071179, 0.00071111, 0.00070976, 0.00070956,\n",
       "       0.00070903, 0.00070835, 0.00070611, 0.00070508, 0.00070377,\n",
       "       0.00070212, 0.00070055, 0.00069755, 0.00069608, 0.00069453,\n",
       "       0.00069243, 0.00069159, 0.00069092, 0.00068719, 0.00068423,\n",
       "       0.00068122, 0.0006772 , 0.00067554, 0.00067379, 0.00067077,\n",
       "       0.00066347, 0.00066046, 0.00065863, 0.00065542, 0.00064975,\n",
       "       0.00064457, 0.00064086, 0.00063182, 0.00062614, 0.00061701,\n",
       "       0.00060817, 0.00060416, 0.00059899, 0.00059284, 0.00059016,\n",
       "       0.00058076, 0.00057194, 0.00056983, 0.0005609 , 0.000556  ,\n",
       "       0.00054939, 0.00053966, 0.00053194, 0.00053127, 0.0005134 ,\n",
       "       0.00051118, 0.00050693, 0.00049753, 0.00049105, 0.00048574,\n",
       "       0.00047731, 0.00047293, 0.00046797, 0.00046654, 0.00046127,\n",
       "       0.00045227, 0.00045192, 0.00044696, 0.00044457, 0.00044035,\n",
       "       0.00043752, 0.0004346 , 0.0004318 , 0.00043011, 0.00042704,\n",
       "       0.00042473, 0.00042231, 0.00042063, 0.00041655, 0.00041421,\n",
       "       0.00041221, 0.00041144, 0.00040929, 0.00040601, 0.00040472,\n",
       "       0.0004023 , 0.00040212, 0.00040154, 0.00039877, 0.00039675])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=500)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:44:05.140709Z",
     "start_time": "2021-05-10T14:44:05.126747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 500), (15000, 500))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape, X_test_pca.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Selection\n",
    "Proposal:\n",
    "1. try different regression techniques, and select the best one;\n",
    "      - DT regressor\n",
    "      * Ensemble method\n",
    "      - Adding polynomial items to multiple linear regression? \n",
    "      - Tensorflow.Keras\n",
    "2. focus on the selected one and tuning modelling.(Guessing propably would use Ensemble learning or Keras in the end)<br>\n",
    "**Based on the our previous experiment so far, our results have both large bias and variance.** Probably need to use more powerful algorithm to improve the bias, and then considering solve overfitting issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:31:26.661239Z",
     "start_time": "2021-05-10T15:31:26.641292Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score,r2_score, mean_squared_log_error\n",
    "def evaluate_dt_regressor(X_train, X_test, y_train, y_test,n_iter,max_depth):\n",
    "    # the maximum depth of the tree. If None, then nodes are expanded until all leaves are pure\n",
    "    MSE_test=[]\n",
    "    MSLE_test=[]\n",
    "    EVS_test=[]\n",
    "    R2_test=[]\n",
    "    MSE_train=[]\n",
    "    MSLE_train=[]\n",
    "    EVS_train=[]\n",
    "    R2_train=[]\n",
    "    for i in range(n_iter):\n",
    "        rg = tree.DecisionTreeRegressor(max_depth=max_depth)\n",
    "        rg.fit(X_train, y_train)\n",
    "        y_train_pred = rg.predict(X_train)\n",
    "        y_pred = rg.predict(X_test)\n",
    "        MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "        MSLE_train.append(mean_squared_log_error(y_train, y_train_pred))\n",
    "        EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "        R2_train.append(r2_score(y_train, y_train_pred))\n",
    "        \n",
    "        MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "        MSLE_test.append(mean_squared_log_error(y_test, y_pred))\n",
    "        EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "        R2_test.append(r2_score(y_test, y_pred))\n",
    "    print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"MSLE: {}\".format(sum(MSLE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "    print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"MSLE: {}\".format(sum(MSLE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:32:12.487738Z",
     "start_time": "2021-05-10T15:31:30.243638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 1.4285714285714285e-05 MSLE: 4.75857431427549e-07 EVS: 0.9999999996453222 R2: 0.9999999996453222\n",
      "Test score: MSE: 23956.95273333333 MSLE: 1.1139345633215292 EVS: 0.3643934816602217 R2: 0.36438495807567317\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca, y_train, y_test,1,max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:41:10.337050Z",
     "start_time": "2021-05-03T20:41:04.250048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 27414.984394562318 EVS: 0.3193558770393383 R2: 0.3193558770393383\n",
      "Test score: MSE: 24911.631535077548 EVS: 0.3390785961873015 R2: 0.3390558516008496\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,y_train, y_test,1,max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T20:41:20.191480Z",
     "start_time": "2021-05-03T20:41:10.575341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 21470.693098680924 EVS: 0.46693746517660495 R2: 0.46693746517660484\n",
      "Test score: MSE: 21338.688174806877 EVS: 0.4338543263328638 R2: 0.4338515699466069\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,  y_train, y_test,1,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:52:12.881362Z",
     "start_time": "2021-05-10T14:45:08.654305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 1.4285714285714289e-05 EVS: 0.9999999996453222 R2: 0.9999999996453222\n",
      "Test score: MSE: 23756.189338333334 EVS: 0.3697531583214731 R2: 0.3697115217313355\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_regressor(X_train_pca, X_test_pca,  y_train, y_test,10,max_depth=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:52:14.134380Z",
     "start_time": "2021-05-10T14:52:13.311749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.01457693e+01,  3.79483760e+00, -1.21846062e+01,\n",
       "         3.83522622e-02, -6.89252911e+00,  1.06208183e+01,\n",
       "        -6.76103236e-01,  8.07412340e+00, -2.33055534e+01,\n",
       "        -6.25583421e+00, -5.43767940e+00, -6.57436948e+00,\n",
       "         2.05360571e+00, -3.92812667e+00, -5.36560875e+00,\n",
       "         9.44755096e-02,  3.74832111e+00,  5.70137620e-01,\n",
       "         1.36729208e+00,  1.61591168e-02,  8.86912194e-01,\n",
       "         6.45903302e+00,  5.33896362e+00, -1.34617912e-02,\n",
       "         1.35817032e+01, -6.96856776e+00,  7.68541058e-01,\n",
       "        -8.59002318e-01,  2.56203106e+00, -3.78958936e+00,\n",
       "        -6.31941811e+00, -1.48926437e+00, -3.74152179e+00,\n",
       "        -6.05237681e+00,  1.39390741e+01,  1.07435909e+00,\n",
       "        -1.36661164e+00, -2.84038150e+00, -1.45975261e-01,\n",
       "         2.43540844e-01, -2.79782356e+00, -6.89709669e+00,\n",
       "         4.51055949e+00, -2.53089855e+00, -3.30131110e+00,\n",
       "        -1.94547070e-01, -4.87675938e+00,  8.09418157e+00,\n",
       "        -6.10207293e+00,  7.39742913e-01,  5.33883456e+00,\n",
       "        -2.07303272e-01,  2.44437106e+00, -3.14758511e-01,\n",
       "         2.20541311e+00, -5.42468893e+00,  7.67913772e-03,\n",
       "         1.48348220e+00, -3.63299364e-01, -9.33727160e-01,\n",
       "        -6.47143591e-01, -7.66118390e-01, -2.30179341e+00,\n",
       "        -3.41782196e-01,  1.67441757e+00, -1.29921982e+00,\n",
       "        -2.31772089e+00, -3.15878679e+00, -2.06953151e+00,\n",
       "        -2.00849707e+00, -7.16629056e-02, -4.77408089e+00,\n",
       "         4.29847757e+00,  8.91223922e-01, -9.59185488e-01,\n",
       "         7.71797638e-01, -7.31314751e-01, -6.55751579e-01,\n",
       "        -1.34846498e-01, -5.21449836e-01, -1.66439202e-01,\n",
       "         3.67980360e-01, -3.42574717e-01,  2.67965430e-01,\n",
       "        -7.22850303e-01,  7.49343047e-02,  3.61636445e-01,\n",
       "        -6.10376731e-01,  7.44724743e-01, -6.23655826e-01,\n",
       "         2.96363833e-01,  3.50594670e-01, -5.50489024e-01,\n",
       "        -1.01234911e+00, -4.38086762e-01, -6.19348040e-01,\n",
       "         1.42526515e+00, -7.13722825e-01, -4.96442546e-01,\n",
       "        -5.96180999e-01, -2.41669117e+00,  1.75250152e+00,\n",
       "        -4.82830963e-01, -4.70910540e-01, -2.58862558e+00,\n",
       "         1.83682852e+00, -1.66805382e+00, -1.61007173e-02,\n",
       "        -7.11791727e-01,  1.91474797e+00,  3.70145059e+00,\n",
       "         1.04106747e+00, -5.43455933e-01,  3.21616074e+00,\n",
       "        -2.39298843e+00, -1.16676295e+00, -4.55526544e+00,\n",
       "        -1.04477075e+00,  4.89435752e-01, -1.24870813e+00,\n",
       "         2.65678977e-01, -4.14173394e-01, -8.13616938e-01,\n",
       "        -2.28828102e-01,  1.20302603e+00, -9.40320674e-01,\n",
       "        -3.56483455e-01, -2.72208367e-01,  3.49366847e-03,\n",
       "        -2.91607219e+00,  2.15150747e+00,  1.14917505e+00,\n",
       "        -3.02882500e+00,  2.13380583e+00,  5.54994978e-01,\n",
       "         5.24531538e-01, -2.17371261e+00, -2.53092357e+00,\n",
       "        -2.81463689e+00,  2.07004503e-01, -1.67742549e+00,\n",
       "         1.19674334e+00,  2.53196420e+00, -1.14761527e+00,\n",
       "        -3.85957380e+00,  3.37951871e+00, -5.91465176e-01,\n",
       "         3.36664179e-01, -2.76245726e-01,  8.44181843e-01,\n",
       "        -7.53773549e-02,  6.74705087e-01,  9.11213729e-01,\n",
       "        -1.11494602e+00,  1.56736973e+00,  8.25176118e-02,\n",
       "        -2.47254670e+00,  3.29885498e-01,  2.50447653e+00,\n",
       "        -7.81177952e-01, -9.53116740e-01,  1.73855082e+00,\n",
       "        -3.03578510e-01, -5.26800892e-01, -1.75165130e+00,\n",
       "        -3.27351814e+00, -1.53144242e+00,  1.56782105e+00,\n",
       "        -1.09959817e+00,  2.04450968e+00, -2.50839453e+00,\n",
       "         1.56943624e+00, -2.54859307e-02, -3.15083410e+00,\n",
       "        -3.00571109e+00,  3.14447890e+00,  1.28169569e+00,\n",
       "        -2.25725052e+00,  1.25490239e+00, -5.60534939e-01,\n",
       "         1.35539996e-01,  2.33567760e+00, -7.76602363e-01,\n",
       "         1.57666958e+00,  1.10036341e+00, -4.16120045e+00,\n",
       "         2.51455624e+00,  3.64423865e-01,  1.15824486e+00,\n",
       "        -5.84596369e-01,  1.82138757e+00,  1.07876218e+00,\n",
       "        -3.38553146e+00,  3.76707975e+00, -9.62222070e-01,\n",
       "        -1.88705844e+00, -3.74793084e+00,  8.11674674e-01,\n",
       "        -1.13233869e+00,  2.11623336e+00,  2.43663372e+00,\n",
       "         1.21096044e+00,  1.27896846e+00, -6.21713838e-01,\n",
       "         2.23280818e+00,  3.30135010e+00,  3.10429514e+00,\n",
       "         3.09342488e+00, -1.58347647e+00, -2.57153224e-01,\n",
       "        -3.27517177e+00, -1.96177099e+00,  3.83207264e-01,\n",
       "        -2.42495966e+00, -2.29586367e+00, -1.34657757e-01,\n",
       "        -1.83442352e+00,  1.49319596e+00, -1.63892430e+00,\n",
       "         7.97108435e-01, -1.25833042e+00,  3.83026549e+00,\n",
       "         6.33924694e-01, -2.76539856e+00, -3.94342231e+00,\n",
       "        -1.17443477e+00, -1.02801058e-01, -1.54486924e+00,\n",
       "        -1.70478712e+00,  2.00824077e+00, -3.08518181e+00,\n",
       "         1.85299582e+00, -2.31427889e+00,  6.15104009e-01,\n",
       "         2.70509162e+00, -6.06529392e+00, -8.01373418e-01,\n",
       "         7.50813636e-01, -1.84335172e-01, -3.35709294e-01,\n",
       "        -1.03603066e+00,  1.85144922e+00, -1.29324357e+00,\n",
       "         2.46538535e+00, -2.82277386e-01, -1.27507961e+00,\n",
       "         5.41080231e+00, -1.50289074e+00, -1.37437315e+00,\n",
       "        -1.24310537e+00, -1.48990991e+00, -3.22600996e+00,\n",
       "        -1.35497109e+00,  2.47888317e+00, -1.18804692e+00,\n",
       "        -1.27331557e+00, -8.60700301e-01, -5.02055671e+00,\n",
       "        -4.65857918e-01, -1.16332690e+00, -1.01796903e+00,\n",
       "         4.17313068e+00, -3.73395562e+00, -6.99823599e-01,\n",
       "        -5.27902834e-01, -9.04600931e-01,  3.21279469e+00,\n",
       "         2.26610639e-01, -1.05317540e-01, -4.19488818e+00,\n",
       "        -6.35324209e-01, -3.20446871e+00, -6.73296441e-01,\n",
       "        -2.38172970e+00,  1.61300194e-01,  1.41314535e+00,\n",
       "        -2.77565417e+00,  2.23677494e+00,  3.04855665e+00,\n",
       "        -1.44691525e+00,  1.10342243e+00, -5.96788438e+00,\n",
       "         7.58599528e+00, -1.08907991e+00, -1.09375073e+00,\n",
       "         1.83314458e+00, -7.42924437e-01, -4.56058369e+00,\n",
       "         8.32150075e-01,  8.18185225e-01,  7.18898476e-01,\n",
       "         1.54183659e-01, -6.80166291e+00, -1.67331495e-01,\n",
       "        -3.59801920e+00,  9.61806062e-01,  1.04358248e+00,\n",
       "        -1.40737606e+00, -1.44823831e+00,  1.92875079e+00,\n",
       "         2.54703369e+00, -4.66514748e+00,  1.54639065e-01,\n",
       "        -7.22807875e-01, -5.37342122e+00, -5.00978230e+00,\n",
       "         1.34109196e+00, -1.90581092e+00,  2.00611790e+00,\n",
       "        -4.36759543e-01, -1.22897653e+00,  1.35756380e+00,\n",
       "         2.71154445e+00,  9.59559226e-01,  5.44459321e-01,\n",
       "         7.45763272e-01, -1.38407813e+00,  2.20169544e-01,\n",
       "        -2.20893646e+00, -3.89821475e-01,  1.57926271e+00,\n",
       "         2.67709138e+00, -5.79694646e+00, -2.71574521e+00,\n",
       "         4.08244177e+00, -1.81826251e-01, -2.13932476e+00,\n",
       "        -1.02541352e+00, -3.44075762e+00,  6.32014246e-02,\n",
       "        -1.58382507e+00, -1.36933588e+00, -6.04307684e-01,\n",
       "        -1.50522876e-01, -1.71220739e+00,  1.42264106e-02,\n",
       "        -1.02199706e-01,  1.30322770e+00,  3.13963650e-01,\n",
       "         7.28119952e-01,  2.62998704e+00,  3.36494890e+00,\n",
       "        -1.04326552e+00, -1.38915903e+00, -1.68078090e+00,\n",
       "         7.91468961e-01,  5.73460051e-01,  1.15145584e+00,\n",
       "         2.03830431e+00, -7.58625588e-01, -1.58277391e+00,\n",
       "        -1.74603305e+00, -1.20803138e+00,  6.97666401e-01,\n",
       "         1.76168206e+00,  3.47482052e-01, -6.48688600e-01,\n",
       "        -2.04194747e-01,  1.21973214e-01,  4.34715888e-01,\n",
       "         9.10726478e-01,  1.85203199e+00,  2.58309388e-01,\n",
       "         7.19608817e-01,  2.15485693e-01,  4.54838921e-01,\n",
       "        -5.31711368e-01, -3.51438267e-01, -1.50258067e+00,\n",
       "         9.31232511e-01,  2.48220593e-01,  8.41431488e-01,\n",
       "        -4.71452693e-01,  7.70362923e-01,  1.65264604e-01,\n",
       "        -1.84636094e-01,  1.25116199e+00, -1.33301572e+00,\n",
       "         6.36856670e-01,  5.25811183e-01, -1.08360714e+00,\n",
       "         7.96866024e-02, -1.00635236e+00,  1.51371603e+00,\n",
       "         1.84909725e-01, -1.10373526e+00,  5.68549586e-01,\n",
       "         5.28935426e-01, -1.19442410e+00,  4.10893024e-01,\n",
       "         8.58228847e-01, -6.03097600e-01,  2.03280719e+00,\n",
       "         4.87707029e-02, -2.56436799e-02, -3.19028452e-01,\n",
       "         1.00316806e+00,  8.69437917e-01,  3.37535223e-01,\n",
       "         9.80027934e-01,  8.78786781e-01, -2.47890132e-01,\n",
       "         4.62564097e-01, -1.77037732e-01,  3.43344933e-01,\n",
       "         3.89711338e-01,  6.29720849e-01,  4.93532316e-01,\n",
       "         8.57267424e-02, -1.31170492e+00,  5.02199516e-01,\n",
       "         6.46691678e-01, -1.44649835e+00,  4.93972957e-01,\n",
       "        -2.36649972e+00,  1.79244651e+00,  9.04770233e-01,\n",
       "        -3.08780460e-01, -2.01771270e+00, -2.19254561e+00,\n",
       "        -1.07242122e+00, -1.18781926e+00, -3.93945176e-02,\n",
       "         1.21505813e+00, -6.21121362e-01,  7.00805839e-01,\n",
       "         1.68974064e+00,  1.99777249e+00,  2.04379687e-01,\n",
       "        -9.39585162e-01, -1.44707181e+00, -3.31965930e-01,\n",
       "         2.39457685e+00,  6.20457455e-01,  8.64590513e-02,\n",
       "         1.34840254e-01,  1.97164353e+00,  8.67279218e-01,\n",
       "        -9.35754562e-02,  3.57498266e-01, -7.91952431e-02,\n",
       "         3.19453404e+00,  1.30934311e+00, -1.22072074e+00,\n",
       "         2.70765374e+00, -3.98778872e+00, -4.08007244e+00,\n",
       "         4.16031219e-01,  2.96417350e-01,  3.51778178e+00,\n",
       "         2.21052474e+00, -1.27265086e+00,  9.61178397e-01,\n",
       "        -3.47555817e+00,  2.00415764e+00, -4.60627073e-01,\n",
       "        -3.21958855e+00, -6.17887593e+00,  3.29986458e+00,\n",
       "        -2.85828977e+00, -1.05780331e+00, -1.71282698e+00,\n",
       "         4.94747263e+00,  1.73485545e+00,  3.33275574e+00,\n",
       "         3.16512855e+00,  4.97288138e+00,  3.93158100e+00,\n",
       "         2.37055222e+00,  1.24975449e+00, -5.60056342e+00,\n",
       "         1.71880220e+00,  5.87072630e+00, -5.96325920e+00,\n",
       "        -4.13108465e+00,  2.18113023e+00,  2.70863627e-01,\n",
       "         7.15324744e+00, -5.20116995e+00, -2.39260253e+00,\n",
       "         1.30163417e+00,  3.50305759e+00, -4.06357898e+00,\n",
       "         8.16795810e+00,  3.90437543e+00, -2.61963191e+00,\n",
       "         1.41740995e+00,  4.18058660e+00,  1.06980639e+01,\n",
       "        -2.64368481e+00, -2.12529867e+00,  5.17147399e-02,\n",
       "         1.25228689e+00, -9.78498554e-01, -3.31393114e+00,\n",
       "         4.96190272e-01, -2.92006725e+00,  2.96522851e+00,\n",
       "        -5.44969432e-01, -1.73253520e-01]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train_pca, y_train)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why linear regression is so slow. after 1 and harf hour, not completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:32:56.980304Z",
     "start_time": "2021-05-10T15:32:56.974364Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, explained_variance_score,r2_score,mean_squared_log_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:35:02.732062Z",
     "start_time": "2021-05-10T15:35:01.804545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'MSE': 23970.402286349345, 'EVS': 0.40487606316337776, 'R2': 0.40487606316337776}\n",
      "test: {'MSE': 22117.779819300107, 'EVS': 0.4132381916034543, 'R2': 0.4131810625665744}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train_pca, y_train)\n",
    "y_train_pred = reg.predict(X_train_pca)\n",
    "y_pred = reg.predict(X_test_pca)\n",
    "\n",
    "print(\"train:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_train, y_train_pred), \n",
    "    #\"MSLE\": mean_squared_log_error(y_train, y_train_pred), \n",
    "    \"EVS\": explained_variance_score(y_train, y_train_pred), \n",
    "    \"R2\": r2_score(y_train, y_train_pred)\n",
    "})\n",
    "\n",
    "print(\"test:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred), \n",
    "   # \"MSLE\": mean_squared_log_error(y_test, y_pred), \n",
    "    \"EVS\": explained_variance_score(y_test, y_pred), \n",
    "    \"R2\": r2_score(y_test, y_pred)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T14:25:52.091877Z",
     "start_time": "2021-05-04T14:25:50.222920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'MSE': 990.2144264683332, 'EVS': 0.9762126689873514, 'R2': 0.9754155019697835}\n",
      "test: {'MSE': 22210.444955510124, 'EVS': 0.41079200166941765, 'R2': 0.41072251305517926}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha=.5) # tuning alpha does not help\n",
    "reg.fit(X_train_pca, y_train)\n",
    "y_train_pred = rg.predict(X_train_pca)\n",
    "y_pred = reg.predict(X_test_pca)\n",
    "\n",
    "print(\"train:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_train, y_train_pred), \n",
    "    \"EVS\": explained_variance_score(y_train, y_train_pred), \n",
    "    \"R2\": r2_score(y_train, y_train_pred)\n",
    "})\n",
    "\n",
    "print(\"test:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred), \n",
    "    \"EVS\": explained_variance_score(y_test, y_pred), \n",
    "    \"R2\": r2_score(y_test, y_pred)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T14:27:37.862666Z",
     "start_time": "2021-05-04T14:27:35.849092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'MSE': 990.2144264683332, 'EVS': 0.9762126689873514, 'R2': 0.9754155019697835}\n",
      "test: {'MSE': 22252.94906638174, 'EVS': 0.4096624179206132, 'R2': 0.40959481319642266}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso(alpha=0.8) # tuning alpha does not help\n",
    "reg.fit(X_train_pca, y_train)\n",
    "y_train_pred = rg.predict(X_train_pca)\n",
    "y_pred = reg.predict(X_test_pca)\n",
    "\n",
    "print(\"train:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_train, y_train_pred), \n",
    "    \"EVS\": explained_variance_score(y_train, y_train_pred), \n",
    "    \"R2\": r2_score(y_train, y_train_pred)\n",
    "})\n",
    "\n",
    "print(\"test:\",\n",
    "{\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred), \n",
    "    \"EVS\": explained_variance_score(y_test, y_pred), \n",
    "    \"R2\": r2_score(y_test, y_pred)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Bagging) for classification, also for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:37:06.995136Z",
     "start_time": "2021-05-10T15:37:06.972137Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def evaluate_rf_regressor(X_train, X_test, y_train, y_test,n_iter,max_depth,random_state):\n",
    "    MSE_test=[]\n",
    "    MSLE_test=[]\n",
    "    EVS_test=[]\n",
    "    R2_test=[]\n",
    "    MSE_train=[]\n",
    "    MSLE_train=[]\n",
    "    EVS_train=[]\n",
    "    R2_train=[]\n",
    "    for i in range(n_iter):\n",
    "        rg = RandomForestRegressor(max_depth=max_depth, random_state=random_state)\n",
    "        rg.fit(X_train, y_train)\n",
    "        y_train_pred = rg.predict(X_train)\n",
    "        y_pred = rg.predict(X_test)\n",
    "        MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "        MSLE_train.append(mean_squared_log_error(y_train, y_train_pred))\n",
    "        EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "        R2_train.append(r2_score(y_train, y_train_pred))\n",
    "        \n",
    "        MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "        MSLE_test.append(mean_squared_log_error(y_test, y_pred))\n",
    "        EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "        R2_test.append(r2_score(y_test, y_pred))\n",
    "        \n",
    "    print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"MSLE: {}\".format(sum(MSLE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "    print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"MSLE: {}\".format(sum(MSLE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_regressor turns out very very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:17:51.896484Z",
     "start_time": "2021-05-10T15:37:11.667391Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-b34c0079e6db>:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rg.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: MSE: 992.3911161765984 MSLE: 0.2578898012375516 EVS: 0.976156501825445 R2: 0.9753614603173748\n",
      "Test score: MSE: 9146.281379356567 MSLE: 0.7492737186709889 EVS: 0.7580576719844276 R2: 0.7573349963535813\n"
     ]
    }
   ],
   "source": [
    "evaluate_rf_regressor(X_train_pca, X_test_pca, y_train, y_test,1,max_depth=None,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T00:15:53.531190Z",
     "start_time": "2021-05-03T23:33:57.194172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-558030b727bd>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rg.fit(X_train_pca, y_train)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MSE_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-558030b727bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mMSE_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mEVS_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexplained_variance_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mR2_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MSE_train' is not defined"
     ]
    }
   ],
   "source": [
    "rg = RandomForestRegressor(max_depth=None, random_state=42)\n",
    "rg.fit(X_train_pca, y_train)\n",
    "y_train_pred = rg.predict(X_train_pca)\n",
    "y_pred = rg.predict(X_test_pca)\n",
    "MSE_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "EVS_train.append(explained_variance_score(y_train, y_train_pred))\n",
    "R2_train.append(r2_score(y_train, y_train_pred))\n",
    "\n",
    "MSE_test.append(mean_squared_error(y_test, y_pred))\n",
    "EVS_test.append(explained_variance_score(y_test, y_pred))\n",
    "R2_test.append(r2_score(y_test, y_pred))\n",
    "print(\"Train score:\",\"MSE: {}\".format(sum(MSE_train)/n_iter),\"EVS: {}\".format(sum(EVS_train)/n_iter),\"R2: {}\".format(sum(R2_train)/n_iter),)\n",
    "print(\"Test score:\",\"MSE: {}\".format(sum(MSE_test)/n_iter),\"EVS: {}\".format(sum(EVS_test)/n_iter),\"R2: {}\".format(sum(R2_test)/n_iter),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:09:48.005739Z",
     "start_time": "2021-05-04T13:09:47.465304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rg.feature_importances_\n",
    "importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:09:49.846589Z",
     "start_time": "2021-05-04T13:09:49.835306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3024)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T13:14:07.663612Z",
     "start_time": "2021-05-04T13:14:07.573550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 7                              0.105877\n",
      " 2) 24                             0.063736\n",
      " 3) 33                             0.055135\n",
      " 4) 288                            0.033101\n",
      " 5) 1                              0.030501\n",
      " 6) 10                             0.025732\n",
      " 7) 316                            0.017765\n",
      " 8) 89                             0.014740\n",
      " 9) 48                             0.012854\n",
      "10) 469                            0.012297\n",
      "11) 11                             0.010544\n",
      "12) 262                            0.009389\n",
      "13) 2                              0.008283\n",
      "14) 0                              0.007948\n",
      "15) 14                             0.007850\n",
      "16) 491                            0.007349\n",
      "17) 57                             0.006804\n",
      "18) 6                              0.006769\n",
      "19) 34                             0.006605\n",
      "20) 46                             0.006498\n",
      "21) 261                            0.005871\n",
      "22) 476                            0.005158\n",
      "23) 483                            0.004931\n",
      "24) 192                            0.004860\n",
      "25) 252                            0.004593\n",
      "26) 8                              0.004519\n",
      "27) 285                            0.004433\n",
      "28) 273                            0.004364\n",
      "29) 216                            0.004305\n",
      "30) 467                            0.004116\n",
      "31) 116                            0.003915\n",
      "32) 27                             0.003776\n",
      "33) 323                            0.003739\n",
      "34) 175                            0.003534\n",
      "35) 242                            0.003235\n",
      "36) 299                            0.003226\n",
      "37) 399                            0.003218\n",
      "38) 32                             0.003109\n",
      "39) 470                            0.002954\n",
      "40) 25                             0.002944\n",
      "41) 70                             0.002937\n",
      "42) 167                            0.002923\n",
      "43) 455                            0.002843\n",
      "44) 5                              0.002751\n",
      "45) 235                            0.002579\n",
      "46) 477                            0.002554\n",
      "47) 3                              0.002538\n",
      "48) 20                             0.002510\n",
      "49) 39                             0.002465\n",
      "50) 208                            0.002452\n",
      "51) 493                            0.002441\n",
      "52) 269                            0.002374\n",
      "53) 80                             0.002358\n",
      "54) 170                            0.002353\n",
      "55) 321                            0.002326\n",
      "56) 120                            0.002315\n",
      "57) 174                            0.002315\n",
      "58) 484                            0.002294\n",
      "59) 318                            0.002258\n",
      "60) 472                            0.002208\n",
      "61) 26                             0.002193\n",
      "62) 125                            0.002192\n",
      "63) 495                            0.002172\n",
      "64) 274                            0.002160\n",
      "65) 103                            0.002083\n",
      "66) 38                             0.002052\n",
      "67) 222                            0.002014\n",
      "68) 437                            0.001982\n",
      "69) 129                            0.001977\n",
      "70) 15                             0.001932\n",
      "71) 489                            0.001922\n",
      "72) 180                            0.001899\n",
      "73) 390                            0.001878\n",
      "74) 259                            0.001860\n",
      "75) 209                            0.001827\n",
      "76) 91                             0.001807\n",
      "77) 99                             0.001794\n",
      "78) 84                             0.001762\n",
      "79) 479                            0.001747\n",
      "80) 492                            0.001742\n",
      "81) 376                            0.001733\n",
      "82) 12                             0.001718\n",
      "83) 402                            0.001680\n",
      "84) 189                            0.001679\n",
      "85) 355                            0.001668\n",
      "86) 218                            0.001644\n",
      "87) 104                            0.001614\n",
      "88) 71                             0.001593\n",
      "89) 113                            0.001578\n",
      "90) 450                            0.001569\n",
      "91) 409                            0.001556\n",
      "92) 223                            0.001526\n",
      "93) 72                             0.001523\n",
      "94) 298                            0.001514\n",
      "95) 217                            0.001507\n",
      "96) 327                            0.001496\n",
      "97) 154                            0.001495\n",
      "98) 244                            0.001493\n",
      "99) 40                             0.001477\n",
      "100) 162                            0.001472\n",
      "101) 443                            0.001471\n",
      "102) 254                            0.001451\n",
      "103) 258                            0.001448\n",
      "104) 58                             0.001448\n",
      "105) 419                            0.001445\n",
      "106) 311                            0.001441\n",
      "107) 90                             0.001437\n",
      "108) 148                            0.001434\n",
      "109) 291                            0.001429\n",
      "110) 434                            0.001424\n",
      "111) 105                            0.001421\n",
      "112) 28                             0.001421\n",
      "113) 9                              0.001420\n",
      "114) 485                            0.001408\n",
      "115) 52                             0.001407\n",
      "116) 315                            0.001406\n",
      "117) 94                             0.001392\n",
      "118) 13                             0.001392\n",
      "119) 23                             0.001391\n",
      "120) 176                            0.001376\n",
      "121) 418                            0.001368\n",
      "122) 386                            0.001367\n",
      "123) 303                            0.001366\n",
      "124) 268                            0.001365\n",
      "125) 30                             0.001357\n",
      "126) 119                            0.001347\n",
      "127) 356                            0.001347\n",
      "128) 87                             0.001345\n",
      "129) 49                             0.001341\n",
      "130) 73                             0.001339\n",
      "131) 276                            0.001336\n",
      "132) 481                            0.001335\n",
      "133) 42                             0.001318\n",
      "134) 461                            0.001309\n",
      "135) 230                            0.001309\n",
      "136) 100                            0.001309\n",
      "137) 111                            0.001304\n",
      "138) 494                            0.001299\n",
      "139) 382                            0.001298\n",
      "140) 295                            0.001288\n",
      "141) 92                             0.001279\n",
      "142) 83                             0.001278\n",
      "143) 385                            0.001275\n",
      "144) 248                            0.001273\n",
      "145) 465                            0.001262\n",
      "146) 499                            0.001251\n",
      "147) 131                            0.001248\n",
      "148) 183                            0.001246\n",
      "149) 279                            0.001242\n",
      "150) 50                             0.001236\n",
      "151) 246                            0.001232\n",
      "152) 79                             0.001230\n",
      "153) 220                            0.001230\n",
      "154) 411                            0.001228\n",
      "155) 159                            0.001227\n",
      "156) 96                             0.001226\n",
      "157) 497                            0.001223\n",
      "158) 294                            0.001212\n",
      "159) 236                            0.001210\n",
      "160) 102                            0.001204\n",
      "161) 460                            0.001184\n",
      "162) 77                             0.001182\n",
      "163) 18                             0.001176\n",
      "164) 41                             0.001174\n",
      "165) 47                             0.001172\n",
      "166) 452                            0.001158\n",
      "167) 212                            0.001147\n",
      "168) 283                            0.001138\n",
      "169) 496                            0.001135\n",
      "170) 108                            0.001127\n",
      "171) 107                            0.001126\n",
      "172) 146                            0.001125\n",
      "173) 381                            0.001123\n",
      "174) 449                            0.001115\n",
      "175) 413                            0.001109\n",
      "176) 51                             0.001106\n",
      "177) 158                            0.001103\n",
      "178) 98                             0.001100\n",
      "179) 426                            0.001099\n",
      "180) 31                             0.001098\n",
      "181) 63                             0.001096\n",
      "182) 150                            0.001091\n",
      "183) 439                            0.001089\n",
      "184) 21                             0.001088\n",
      "185) 344                            0.001086\n",
      "186) 482                            0.001083\n",
      "187) 458                            0.001081\n",
      "188) 78                             0.001080\n",
      "189) 332                            0.001070\n",
      "190) 16                             0.001064\n",
      "191) 238                            0.001063\n",
      "192) 416                            0.001059\n",
      "193) 322                            0.001058\n",
      "194) 290                            0.001055\n",
      "195) 320                            0.001054\n",
      "196) 287                            0.001052\n",
      "197) 374                            0.001044\n",
      "198) 166                            0.001040\n",
      "199) 474                            0.001031\n",
      "200) 66                             0.001031\n",
      "201) 369                            0.001027\n",
      "202) 312                            0.001026\n",
      "203) 463                            0.001023\n",
      "204) 251                            0.001019\n",
      "205) 114                            0.001019\n",
      "206) 112                            0.001017\n",
      "207) 4                              0.001013\n",
      "208) 420                            0.001012\n",
      "209) 35                             0.001010\n",
      "210) 117                            0.001004\n",
      "211) 227                            0.001004\n",
      "212) 115                            0.001001\n",
      "213) 490                            0.001000\n",
      "214) 86                             0.000999\n",
      "215) 234                            0.000995\n",
      "216) 328                            0.000995\n",
      "217) 68                             0.000992\n",
      "218) 186                            0.000990\n",
      "219) 53                             0.000989\n",
      "220) 142                            0.000986\n",
      "221) 178                            0.000986\n",
      "222) 448                            0.000985\n",
      "223) 237                            0.000982\n",
      "224) 301                            0.000982\n",
      "225) 256                            0.000979\n",
      "226) 267                            0.000969\n",
      "227) 309                            0.000968\n",
      "228) 128                            0.000967\n",
      "229) 67                             0.000964\n",
      "230) 134                            0.000962\n",
      "231) 480                            0.000959\n",
      "232) 181                            0.000957\n",
      "233) 36                             0.000957\n",
      "234) 135                            0.000954\n",
      "235) 253                            0.000953\n",
      "236) 410                            0.000951\n",
      "237) 471                            0.000945\n",
      "238) 106                            0.000945\n",
      "239) 165                            0.000942\n",
      "240) 200                            0.000942\n",
      "241) 468                            0.000942\n",
      "242) 171                            0.000941\n",
      "243) 398                            0.000941\n",
      "244) 286                            0.000940\n",
      "245) 475                            0.000940\n",
      "246) 144                            0.000939\n",
      "247) 199                            0.000938\n",
      "248) 407                            0.000936\n",
      "249) 93                             0.000934\n",
      "250) 394                            0.000934\n",
      "251) 447                            0.000930\n",
      "252) 488                            0.000929\n",
      "253) 423                            0.000928\n",
      "254) 61                             0.000924\n",
      "255) 330                            0.000923\n",
      "256) 215                            0.000921\n",
      "257) 155                            0.000920\n",
      "258) 55                             0.000913\n",
      "259) 457                            0.000909\n",
      "260) 352                            0.000909\n",
      "261) 179                            0.000906\n",
      "262) 388                            0.000905\n",
      "263) 335                            0.000904\n",
      "264) 319                            0.000899\n",
      "265) 195                            0.000898\n",
      "266) 459                            0.000897\n",
      "267) 76                             0.000894\n",
      "268) 44                             0.000891\n",
      "269) 375                            0.000890\n",
      "270) 438                            0.000890\n",
      "271) 453                            0.000887\n",
      "272) 313                            0.000886\n",
      "273) 22                             0.000885\n",
      "274) 271                            0.000883\n",
      "275) 266                            0.000882\n",
      "276) 451                            0.000881\n",
      "277) 60                             0.000881\n",
      "278) 349                            0.000881\n",
      "279) 264                            0.000880\n",
      "280) 121                            0.000877\n",
      "281) 370                            0.000876\n",
      "282) 153                            0.000876\n",
      "283) 314                            0.000868\n",
      "284) 280                            0.000867\n",
      "285) 401                            0.000867\n",
      "286) 29                             0.000866\n",
      "287) 184                            0.000860\n",
      "288) 387                            0.000860\n",
      "289) 126                            0.000859\n",
      "290) 19                             0.000853\n",
      "291) 211                            0.000852\n",
      "292) 110                            0.000852\n",
      "293) 431                            0.000851\n",
      "294) 182                            0.000847\n",
      "295) 289                            0.000843\n",
      "296) 446                            0.000841\n",
      "297) 62                             0.000837\n",
      "298) 337                            0.000835\n",
      "299) 462                            0.000835\n",
      "300) 417                            0.000833\n",
      "301) 231                            0.000831\n",
      "302) 270                            0.000827\n",
      "303) 168                            0.000826\n",
      "304) 338                            0.000826\n",
      "305) 172                            0.000825\n",
      "306) 308                            0.000823\n",
      "307) 132                            0.000821\n",
      "308) 265                            0.000818\n",
      "309) 421                            0.000817\n",
      "310) 45                             0.000817\n",
      "311) 487                            0.000815\n",
      "312) 198                            0.000809\n",
      "313) 436                            0.000808\n",
      "314) 228                            0.000807\n",
      "315) 341                            0.000806\n",
      "316) 161                            0.000805\n",
      "317) 428                            0.000802\n",
      "318) 293                            0.000802\n",
      "319) 151                            0.000801\n",
      "320) 361                            0.000799\n",
      "321) 359                            0.000798\n",
      "322) 464                            0.000794\n",
      "323) 353                            0.000791\n",
      "324) 367                            0.000791\n",
      "325) 284                            0.000790\n",
      "326) 122                            0.000789\n",
      "327) 37                             0.000788\n",
      "328) 194                            0.000787\n",
      "329) 240                            0.000783\n",
      "330) 354                            0.000778\n",
      "331) 221                            0.000776\n",
      "332) 430                            0.000776\n",
      "333) 101                            0.000776\n",
      "334) 203                            0.000775\n",
      "335) 404                            0.000772\n",
      "336) 249                            0.000772\n",
      "337) 81                             0.000769\n",
      "338) 56                             0.000765\n",
      "339) 396                            0.000765\n",
      "340) 444                            0.000763\n",
      "341) 331                            0.000760\n",
      "342) 445                            0.000760\n",
      "343) 325                            0.000757\n",
      "344) 306                            0.000756\n",
      "345) 435                            0.000755\n",
      "346) 362                            0.000754\n",
      "347) 219                            0.000753\n",
      "348) 351                            0.000753\n",
      "349) 124                            0.000750\n",
      "350) 422                            0.000748\n",
      "351) 17                             0.000748\n",
      "352) 147                            0.000746\n",
      "353) 282                            0.000746\n",
      "354) 160                            0.000746\n",
      "355) 202                            0.000745\n",
      "356) 272                            0.000744\n",
      "357) 406                            0.000740\n",
      "358) 43                             0.000738\n",
      "359) 281                            0.000738\n",
      "360) 123                            0.000737\n",
      "361) 345                            0.000735\n",
      "362) 185                            0.000733\n",
      "363) 74                             0.000733\n",
      "364) 133                            0.000731\n",
      "365) 145                            0.000730\n",
      "366) 383                            0.000726\n",
      "367) 339                            0.000726\n",
      "368) 310                            0.000722\n",
      "369) 486                            0.000721\n",
      "370) 164                            0.000717\n",
      "371) 454                            0.000714\n",
      "372) 173                            0.000711\n",
      "373) 75                             0.000708\n",
      "374) 317                            0.000706\n",
      "375) 141                            0.000705\n",
      "376) 427                            0.000704\n",
      "377) 363                            0.000703\n",
      "378) 278                            0.000702\n",
      "379) 69                             0.000702\n",
      "380) 263                            0.000701\n",
      "381) 229                            0.000701\n",
      "382) 54                             0.000698\n",
      "383) 210                            0.000698\n",
      "384) 441                            0.000693\n",
      "385) 241                            0.000691\n",
      "386) 243                            0.000689\n",
      "387) 478                            0.000686\n",
      "388) 473                            0.000683\n",
      "389) 204                            0.000682\n",
      "390) 371                            0.000681\n",
      "391) 187                            0.000679\n",
      "392) 257                            0.000676\n",
      "393) 225                            0.000674\n",
      "394) 296                            0.000672\n",
      "395) 350                            0.000671\n",
      "396) 156                            0.000670\n",
      "397) 95                             0.000670\n",
      "398) 177                            0.000670\n",
      "399) 82                             0.000669\n",
      "400) 336                            0.000666\n",
      "401) 429                            0.000665\n",
      "402) 307                            0.000665\n",
      "403) 346                            0.000663\n",
      "404) 233                            0.000663\n",
      "405) 140                            0.000662\n",
      "406) 403                            0.000660\n",
      "407) 456                            0.000659\n",
      "408) 188                            0.000658\n",
      "409) 127                            0.000657\n",
      "410) 405                            0.000656\n",
      "411) 152                            0.000654\n",
      "412) 466                            0.000652\n",
      "413) 138                            0.000648\n",
      "414) 373                            0.000648\n",
      "415) 224                            0.000647\n",
      "416) 408                            0.000643\n",
      "417) 232                            0.000639\n",
      "418) 137                            0.000637\n",
      "419) 326                            0.000635\n",
      "420) 143                            0.000632\n",
      "421) 292                            0.000631\n",
      "422) 277                            0.000629\n",
      "423) 136                            0.000627\n",
      "424) 85                             0.000624\n",
      "425) 88                             0.000624\n",
      "426) 414                            0.000623\n",
      "427) 364                            0.000622\n",
      "428) 365                            0.000620\n",
      "429) 226                            0.000619\n",
      "430) 360                            0.000617\n",
      "431) 300                            0.000616\n",
      "432) 118                            0.000612\n",
      "433) 206                            0.000612\n",
      "434) 302                            0.000612\n",
      "435) 368                            0.000607\n",
      "436) 432                            0.000604\n",
      "437) 149                            0.000603\n",
      "438) 329                            0.000594\n",
      "439) 297                            0.000593\n",
      "440) 348                            0.000593\n",
      "441) 392                            0.000592\n",
      "442) 377                            0.000592\n",
      "443) 415                            0.000590\n",
      "444) 139                            0.000589\n",
      "445) 190                            0.000588\n",
      "446) 201                            0.000586\n",
      "447) 498                            0.000586\n",
      "448) 191                            0.000584\n",
      "449) 340                            0.000582\n",
      "450) 197                            0.000580\n",
      "451) 247                            0.000580\n",
      "452) 333                            0.000580\n",
      "453) 347                            0.000577\n",
      "454) 260                            0.000577\n",
      "455) 59                             0.000576\n",
      "456) 130                            0.000573\n",
      "457) 196                            0.000571\n",
      "458) 357                            0.000567\n",
      "459) 245                            0.000565\n",
      "460) 433                            0.000563\n",
      "461) 275                            0.000561\n",
      "462) 412                            0.000561\n",
      "463) 255                            0.000561\n",
      "464) 97                             0.000559\n",
      "465) 442                            0.000554\n",
      "466) 372                            0.000553\n",
      "467) 378                            0.000551\n",
      "468) 250                            0.000550\n",
      "469) 64                             0.000550\n",
      "470) 109                            0.000548\n",
      "471) 393                            0.000548\n",
      "472) 213                            0.000547\n",
      "473) 440                            0.000539\n",
      "474) 343                            0.000538\n",
      "475) 395                            0.000537\n",
      "476) 305                            0.000536\n",
      "477) 342                            0.000533\n",
      "478) 324                            0.000531\n",
      "479) 397                            0.000526\n",
      "480) 214                            0.000522\n",
      "481) 205                            0.000521\n",
      "482) 379                            0.000520\n",
      "483) 391                            0.000517\n",
      "484) 65                             0.000515\n",
      "485) 389                            0.000515\n",
      "486) 384                            0.000515\n",
      "487) 163                            0.000507\n",
      "488) 304                            0.000497\n",
      "489) 366                            0.000495\n",
      "490) 424                            0.000494\n",
      "491) 193                            0.000486\n",
      "492) 207                            0.000483\n",
      "493) 358                            0.000476\n",
      "494) 169                            0.000476\n",
      "495) 425                            0.000473\n",
      "496) 239                            0.000469\n",
      "497) 334                            0.000453\n",
      "498) 157                            0.000446\n",
      "499) 380                            0.000433\n",
      "500) 400                            0.000413\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 500 is out of bounds for axis 0 with size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-665614754bd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     print(\"%2d) %-*s %f\" % (f + 1, 30, \n\u001b[1;32m----> 6\u001b[1;33m                             \u001b[0mfeat_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                             importances[indices[f]]))\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 500 is out of bounds for axis 0 with size 500"
     ]
    }
   ],
   "source": [
    "feat_labels = range(X_train_pca.shape[1])\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train_pca.shape[1]), \n",
    "        importances[indices],\n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train_pca.shape[1]), \n",
    "           feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train_pca.shape[1]])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/04_09.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning multiple linear regression with polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:23:29.389982Z",
     "start_time": "2021-05-10T15:23:23.499858Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:23:47.374805Z",
     "start_time": "2021-05-10T15:23:46.225777Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"sigmoid\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"sigmoid\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus on Random Forest and ANN, do hypyparameter tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV is useful to solve overfitting, but especially for small dataset. Here our dataset is large, maybe not very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:33:07.040882Z",
     "start_time": "2021-05-10T16:33:00.226Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n",
    "                         X=X_train_pca,\n",
    "                         y=y_train,\n",
    "                         cv=3,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation curve vs learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:33:07.026483Z",
     "start_time": "2021-05-10T16:19:27.356523Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lzowe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-5070116829e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                 learning_curve(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n\u001b[0m\u001b[0;32m      6\u001b[0m                                \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[1;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times)\u001b[0m\n\u001b[0;32m   1277\u001b[0m                 \u001b[0mtrain_test_proportions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_train_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1279\u001b[1;33m         out = parallel(delayed(_fit_and_score)(\n\u001b[0m\u001b[0;32m   1280\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1281\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    387\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \"\"\"\n\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores =\\\n",
    "                learning_curve(estimator=RandomForestRegressor(max_depth=None, random_state=42),\n",
    "                               X=X_train_pca,\n",
    "                               y=y_train,\n",
    "                               train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                               cv=None,\n",
    "                               n_jobs=1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/06_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:33:07.036892Z",
     "start_time": "2021-05-10T16:19:30.034Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "                estimator=RandomForestRegressor(max_depth=None, random_state=42), \n",
    "                X=X_train, \n",
    "                y=y_train, \n",
    "                cv=None)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, \n",
    "         color='blue', marker='o', \n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(param_range, train_mean + train_std,\n",
    "                 train_mean - train_std, alpha=0.15,\n",
    "                 color='blue')\n",
    "\n",
    "plt.plot(param_range, test_mean, \n",
    "         color='green', linestyle='--', \n",
    "         marker='s', markersize=5, \n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(param_range, \n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std, \n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/06_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make it pipeline and apply to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T19:33:23.665809Z",
     "start_time": "2021-05-10T19:33:20.419497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  C:\\Users\\lzowe\\anaconda3\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  C:\\Users\\lzowe\\anaconda3\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  C:\\Users\\lzowe\\anaconda3\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  C:\\Users\\lzowe\\anaconda3\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  C:\\Users\\lzowe\\anaconda3\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -g\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow -gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "449.208px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
